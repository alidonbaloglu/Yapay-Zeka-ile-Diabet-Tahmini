{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bizim veri setimizde en iyi model hangi olduğunu bulablimek için her modeli deneyip en sonda \n",
    "#karşılaştırdık"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sınıflandırma Problemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"diabetes2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6.0    148.0             72           35.0        0  33.6   \n",
       "1            1.0     85.0             66           29.0        0  26.6   \n",
       "2            8.0    183.0             64            0.0        0  23.3   \n",
       "3            1.0     89.0             66           23.0       94  28.1   \n",
       "4            0.0    137.0             40           35.0      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763         10.0    101.0             76           48.0      180  32.9   \n",
       "764          2.0    122.0             70           27.0        0  36.8   \n",
       "765          5.0    121.0             72           23.0      112  26.2   \n",
       "766          1.0    126.0             60            0.0        0  30.1   \n",
       "767          1.0     93.0             70           31.0        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[762 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lojistik Regresyon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0          6.0    148.0             72           35.0        0  33.6   \n",
       "1          1.0     85.0             66           29.0        0  26.6   \n",
       "2          8.0    183.0             64            0.0        0  23.3   \n",
       "3          1.0     89.0             66           23.0       94  28.1   \n",
       "4          0.0    137.0             40           35.0      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    float64\n",
      " 1   Glucose                   763 non-null    float64\n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             767 non-null    float64\n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Outcome\"].value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.837240</td>\n",
       "      <td>3.344157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>763.0</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>44.000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>768.0</td>\n",
       "      <td>70.727865</td>\n",
       "      <td>14.320604</td>\n",
       "      <td>35.000</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>767.0</td>\n",
       "      <td>20.434159</td>\n",
       "      <td>15.708524</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>768.0</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>127.25000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>768.0</td>\n",
       "      <td>32.183789</td>\n",
       "      <td>7.240770</td>\n",
       "      <td>13.350</td>\n",
       "      <td>27.30000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>36.60000</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count        mean         std     min       25%  \\\n",
       "Pregnancies               768.0    3.837240    3.344157   0.000   1.00000   \n",
       "Glucose                   763.0  121.686763   30.535641  44.000  99.00000   \n",
       "BloodPressure             768.0   70.727865   14.320604  35.000  62.00000   \n",
       "SkinThickness             767.0   20.434159   15.708524   0.000   0.00000   \n",
       "Insulin                   768.0   79.799479  115.244002   0.000   0.00000   \n",
       "BMI                       768.0   32.183789    7.240770  13.350  27.30000   \n",
       "DiabetesPedigreeFunction  768.0    0.471876    0.331329   0.078   0.24375   \n",
       "Age                       768.0   33.240885   11.760232  21.000  24.00000   \n",
       "Outcome                   768.0    0.348958    0.476951   0.000   0.00000   \n",
       "\n",
       "                               50%        75%     max  \n",
       "Pregnancies                 3.0000    6.00000   13.50  \n",
       "Glucose                   117.0000  141.00000  199.00  \n",
       "BloodPressure              72.0000   80.00000  122.00  \n",
       "SkinThickness              23.0000   32.00000   63.00  \n",
       "Insulin                    30.5000  127.25000  846.00  \n",
       "BMI                        32.0000   36.60000   67.10  \n",
       "DiabetesPedigreeFunction    0.3725    0.62625    2.42  \n",
       "Age                        29.0000   41.00000   81.00  \n",
       "Outcome                     0.0000    1.00000    1.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop([\"Outcome\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585134\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Outcome</td>     <th>  No. Observations:  </th>  <td>   762</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   754</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 18 Sep 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.09430</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:38:08</td>     <th>  Log-Likelihood:    </th> <td> -445.87</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -492.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.223e-17</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pregnancies</th>              <td>    0.1328</td> <td>    0.030</td> <td>    4.491</td> <td> 0.000</td> <td>    0.075</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Glucose</th>                  <td>    0.0191</td> <td>    0.003</td> <td>    6.290</td> <td> 0.000</td> <td>    0.013</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BloodPressure</th>            <td>   -0.0494</td> <td>    0.006</td> <td>   -7.999</td> <td> 0.000</td> <td>   -0.061</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SkinThickness</th>            <td>   -0.0007</td> <td>    0.006</td> <td>   -0.105</td> <td> 0.916</td> <td>   -0.013</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Insulin</th>                  <td>    0.0003</td> <td>    0.001</td> <td>    0.356</td> <td> 0.722</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>                      <td>    0.0061</td> <td>    0.012</td> <td>    0.494</td> <td> 0.621</td> <td>   -0.018</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DiabetesPedigreeFunction</th> <td>    0.3727</td> <td>    0.249</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.115</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>                      <td>   -0.0087</td> <td>    0.009</td> <td>   -0.989</td> <td> 0.323</td> <td>   -0.026</td> <td>    0.009</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                Outcome   No. Observations:                  762\n",
       "Model:                          Logit   Df Residuals:                      754\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Sat, 18 Sep 2021   Pseudo R-squ.:                 0.09430\n",
       "Time:                        17:38:08   Log-Likelihood:                -445.87\n",
       "converged:                       True   LL-Null:                       -492.29\n",
       "Covariance Type:            nonrobust   LLR p-value:                 3.223e-17\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Pregnancies                  0.1328      0.030      4.491      0.000       0.075       0.191\n",
       "Glucose                      0.0191      0.003      6.290      0.000       0.013       0.025\n",
       "BloodPressure               -0.0494      0.006     -7.999      0.000      -0.061      -0.037\n",
       "SkinThickness               -0.0007      0.006     -0.105      0.916      -0.013       0.012\n",
       "Insulin                      0.0003      0.001      0.356      0.722      -0.001       0.002\n",
       "BMI                          0.0061      0.012      0.494      0.621      -0.018       0.030\n",
       "DiabetesPedigreeFunction     0.3727      0.249      1.499      0.134      -0.115       0.860\n",
       "Age                         -0.0087      0.009     -0.989      0.323      -0.026       0.009\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj = sm.Logit(y, X)\n",
    "loj_model= loj.fit()\n",
    "loj_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "loj = LogisticRegression(solver = \"liblinear\")\n",
    "loj_model = loj.fit(X,y)\n",
    "loj_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.85921938])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11953155,  0.03142499, -0.0244457 , -0.00163061, -0.00077667,\n",
       "         0.06602503,  0.66615332,  0.00661661]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin & Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loj_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[442,  55],\n",
       "       [116, 149]], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755905511811023"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       497\n",
      "           1       0.73      0.56      0.64       265\n",
      "\n",
      "    accuracy                           0.78       762\n",
      "   macro avg       0.76      0.73      0.74       762\n",
      "weighted avg       0.77      0.78      0.77       762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.predict(X)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34104143, 0.65895857],\n",
       "       [0.92649578, 0.07350422],\n",
       "       [0.18526865, 0.81473135],\n",
       "       [0.92832837, 0.07167163],\n",
       "       [0.13367936, 0.86632064],\n",
       "       [0.80259747, 0.19740253],\n",
       "       [0.88166291, 0.11833709],\n",
       "       [0.33043892, 0.66956108],\n",
       "       [0.30280907, 0.69719093],\n",
       "       [0.87306684, 0.12693316]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.predict_proba(X)[0:10][:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "5    0\n",
       "6    1\n",
       "7    0\n",
       "8    1\n",
       "9    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = loj_model.predict_proba(X)\n",
    "y_probs = y_probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65895857, 0.07350422, 0.81473135, 0.07167163, 0.86632064,\n",
       "       0.19740253, 0.11833709, 0.66956108, 0.69719093, 0.12693316])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if i > 0.5 else 0 for i in y_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[442,  55],\n",
       "       [116, 149]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755905511811023"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       497\n",
      "           1       0.73      0.56      0.64       265\n",
      "\n",
      "    accuracy                           0.78       762\n",
      "   macro avg       0.76      0.73      0.74       762\n",
      "weighted avg       0.77      0.78      0.77       762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65895857, 0.07350422, 0.81473135, 0.07167163, 0.86632064])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj_model.predict_proba(X)[:,1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Oranı')\n",
    "plt.ylabel('True Positive Oranı')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.30, \n",
    "                                                    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj = LogisticRegression(solver = \"liblinear\")\n",
    "loj_model = loj.fit(X_train,y_train)\n",
    "loj_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685589519650655"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, loj_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733201581027667"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(loj_model, X_test, y_test, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb_model = nb.fit(X_train, y_train)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.52833563e-01, 1.47166437e-01],\n",
       "       [9.65702786e-01, 3.42972142e-02],\n",
       "       [1.13442497e-01, 8.86557503e-01],\n",
       "       [6.52810382e-01, 3.47189618e-01],\n",
       "       [9.45153246e-01, 5.48467542e-02],\n",
       "       [5.55117791e-04, 9.99444882e-01],\n",
       "       [9.68891124e-01, 3.11088762e-02],\n",
       "       [9.85358155e-01, 1.46418455e-02],\n",
       "       [8.46374648e-01, 1.53625352e-01],\n",
       "       [4.19064627e-01, 5.80935373e-01]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.predict_proba(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729257641921398"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733201581027668"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_model, X_test, y_test, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729257641921398"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6943231441048034"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77       155\n",
      "           1       0.52      0.59      0.56        74\n",
      "\n",
      "    accuracy                           0.69       229\n",
      "   macro avg       0.66      0.67      0.66       229\n",
      "weighted avg       0.71      0.69      0.70       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6943231441048034"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(1,50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, knn_params, cv=10)\n",
    "knn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi skor:0.7411250873515025\n",
      "En iyi parametreler: {'n_neighbors': 42}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi skor:\" + str(knn_cv.best_score_))\n",
    "print(\"En iyi parametreler: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(42)\n",
    "knn_tuned = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74235807860262"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_tuned.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74235807860262"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel = \"linear\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685589519650655"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(kernel='linear'), n_jobs=-1,\n",
       "             param_grid={'C': array([1, 2, 3, 4, 5, 6, 7, 8, 9])}, verbose=2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {\"C\": np.arange(1,10)}\n",
    "\n",
    "svc = SVC(kernel = \"linear\")\n",
    "\n",
    "svc_cv_model = GridSearchCV(svc,svc_params, \n",
    "                            cv = 10, \n",
    "                            n_jobs = -1, \n",
    "                            verbose = 2 )\n",
    "\n",
    "svc_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'C': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametreler: \" + str(svc_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tuned = SVC(kernel = \"linear\", C = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729257641921398"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel = \"rbf\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685589519650655"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_params = {\"C\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100],\n",
    "             \"gamma\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.1, 1, 5, 10, 50, 100],\n",
       "                         'gamma': [0.0001, 0.001, 0.1, 1, 5, 10, 50, 100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc_cv_model = GridSearchCV(svc, svc_params, \n",
    "                         cv = 10, \n",
    "                         n_jobs = -1,\n",
    "                         verbose = 2)\n",
    "\n",
    "svc_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'C': 5, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametreler: \" + str(svc_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tuned = SVC(C = 5, gamma = 0.0001).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554585152838428"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yapay Sinir Ağları"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03244072, -0.40010541, -0.51531501,  1.48125462,  0.16467199,\n",
       "         0.32571888,  1.21534844, -0.64444212],\n",
       "       [ 0.03244072, -0.85815796, -0.0739713 ,  0.72483909, -0.69556432,\n",
       "        -0.04595938,  0.37070534, -0.8130664 ],\n",
       "       [ 0.03244072, -0.33466933,  0.07314327,  1.67035851,  1.10311161,\n",
       "         0.64233369,  2.61347781,  1.88492203],\n",
       "       [-0.56379741, -0.07292501, -2.64847625, -1.292269  , -0.69556432,\n",
       "        -1.76669206,  1.00490835,  3.23391624],\n",
       "       [ 0.62867886, -0.82543992, -2.64847625, -1.292269  , -0.69556432,\n",
       "        -1.20229174, -0.84581134, -0.47581785]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510917030567685"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlpc.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        MLPClassifier\n",
       "\u001b[1;31mString form:\u001b[0m MLPClassifier()\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\donba\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Multi-layer Perceptron classifier.\n",
       "\n",
       "This model optimizes the log-loss function using LBFGS or stochastic\n",
       "gradient descent.\n",
       "\n",
       ".. versionadded:: 0.18\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
       "    The ith element represents the number of neurons in the ith\n",
       "    hidden layer.\n",
       "\n",
       "activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
       "    Activation function for the hidden layer.\n",
       "\n",
       "    - 'identity', no-op activation, useful to implement linear bottleneck,\n",
       "      returns f(x) = x\n",
       "\n",
       "    - 'logistic', the logistic sigmoid function,\n",
       "      returns f(x) = 1 / (1 + exp(-x)).\n",
       "\n",
       "    - 'tanh', the hyperbolic tan function,\n",
       "      returns f(x) = tanh(x).\n",
       "\n",
       "    - 'relu', the rectified linear unit function,\n",
       "      returns f(x) = max(0, x)\n",
       "\n",
       "solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
       "    The solver for weight optimization.\n",
       "\n",
       "    - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
       "\n",
       "    - 'sgd' refers to stochastic gradient descent.\n",
       "\n",
       "    - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
       "      by Kingma, Diederik, and Jimmy Ba\n",
       "\n",
       "    Note: The default solver 'adam' works pretty well on relatively\n",
       "    large datasets (with thousands of training samples or more) in terms of\n",
       "    both training time and validation score.\n",
       "    For small datasets, however, 'lbfgs' can converge faster and perform\n",
       "    better.\n",
       "\n",
       "alpha : float, default=0.0001\n",
       "    L2 penalty (regularization term) parameter.\n",
       "\n",
       "batch_size : int, default='auto'\n",
       "    Size of minibatches for stochastic optimizers.\n",
       "    If the solver is 'lbfgs', the classifier will not use minibatch.\n",
       "    When set to \"auto\", `batch_size=min(200, n_samples)`\n",
       "\n",
       "learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
       "    Learning rate schedule for weight updates.\n",
       "\n",
       "    - 'constant' is a constant learning rate given by\n",
       "      'learning_rate_init'.\n",
       "\n",
       "    - 'invscaling' gradually decreases the learning rate at each\n",
       "      time step 't' using an inverse scaling exponent of 'power_t'.\n",
       "      effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
       "\n",
       "    - 'adaptive' keeps the learning rate constant to\n",
       "      'learning_rate_init' as long as training loss keeps decreasing.\n",
       "      Each time two consecutive epochs fail to decrease training loss by at\n",
       "      least tol, or fail to increase validation score by at least tol if\n",
       "      'early_stopping' is on, the current learning rate is divided by 5.\n",
       "\n",
       "    Only used when ``solver='sgd'``.\n",
       "\n",
       "learning_rate_init : double, default=0.001\n",
       "    The initial learning rate used. It controls the step-size\n",
       "    in updating the weights. Only used when solver='sgd' or 'adam'.\n",
       "\n",
       "power_t : double, default=0.5\n",
       "    The exponent for inverse scaling learning rate.\n",
       "    It is used in updating effective learning rate when the learning_rate\n",
       "    is set to 'invscaling'. Only used when solver='sgd'.\n",
       "\n",
       "max_iter : int, default=200\n",
       "    Maximum number of iterations. The solver iterates until convergence\n",
       "    (determined by 'tol') or this number of iterations. For stochastic\n",
       "    solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
       "    (how many times each data point will be used), not the number of\n",
       "    gradient steps.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Whether to shuffle samples in each iteration. Only used when\n",
       "    solver='sgd' or 'adam'.\n",
       "\n",
       "random_state : int, RandomState instance, default=None\n",
       "    Determines random number generation for weights and bias\n",
       "    initialization, train-test split if early stopping is used, and batch\n",
       "    sampling when solver='sgd' or 'adam'.\n",
       "    Pass an int for reproducible results across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    Tolerance for the optimization. When the loss or score is not improving\n",
       "    by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
       "    unless ``learning_rate`` is set to 'adaptive', convergence is\n",
       "    considered to be reached and training stops.\n",
       "\n",
       "verbose : bool, default=False\n",
       "    Whether to print progress messages to stdout.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to True, reuse the solution of the previous\n",
       "    call to fit as initialization, otherwise, just erase the\n",
       "    previous solution. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "momentum : float, default=0.9\n",
       "    Momentum for gradient descent update. Should be between 0 and 1. Only\n",
       "    used when solver='sgd'.\n",
       "\n",
       "nesterovs_momentum : bool, default=True\n",
       "    Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
       "    momentum > 0.\n",
       "\n",
       "early_stopping : bool, default=False\n",
       "    Whether to use early stopping to terminate training when validation\n",
       "    score is not improving. If set to true, it will automatically set\n",
       "    aside 10% of training data as validation and terminate training when\n",
       "    validation score is not improving by at least tol for\n",
       "    ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
       "    except in a multilabel setting.\n",
       "    Only effective when solver='sgd' or 'adam'\n",
       "\n",
       "validation_fraction : float, default=0.1\n",
       "    The proportion of training data to set aside as validation set for\n",
       "    early stopping. Must be between 0 and 1.\n",
       "    Only used if early_stopping is True\n",
       "\n",
       "beta_1 : float, default=0.9\n",
       "    Exponential decay rate for estimates of first moment vector in adam,\n",
       "    should be in [0, 1). Only used when solver='adam'\n",
       "\n",
       "beta_2 : float, default=0.999\n",
       "    Exponential decay rate for estimates of second moment vector in adam,\n",
       "    should be in [0, 1). Only used when solver='adam'\n",
       "\n",
       "epsilon : float, default=1e-8\n",
       "    Value for numerical stability in adam. Only used when solver='adam'\n",
       "\n",
       "n_iter_no_change : int, default=10\n",
       "    Maximum number of epochs to not meet ``tol`` improvement.\n",
       "    Only effective when solver='sgd' or 'adam'\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "max_fun : int, default=15000\n",
       "    Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
       "    The solver iterates until convergence (determined by 'tol'), number\n",
       "    of iterations reaches max_iter, or this number of loss function calls.\n",
       "    Note that number of loss function calls will be greater than or equal\n",
       "    to the number of iterations for the `MLPClassifier`.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
       "    Class labels for each output.\n",
       "\n",
       "loss_ : float\n",
       "    The current loss computed with the loss function.\n",
       "\n",
       "best_loss_ : float\n",
       "    The minimum loss reached by the solver throughout fitting.\n",
       "\n",
       "loss_curve_ : list of shape (`n_iter_`,)\n",
       "    The ith element in the list represents the loss at the ith iteration.\n",
       "\n",
       "t_ : int\n",
       "    The number of training samples seen by the solver during fitting.\n",
       "\n",
       "coefs_ : list of shape (n_layers - 1,)\n",
       "    The ith element in the list represents the weight matrix corresponding\n",
       "    to layer i.\n",
       "\n",
       "intercepts_ : list of shape (n_layers - 1,)\n",
       "    The ith element in the list represents the bias vector corresponding to\n",
       "    layer i + 1.\n",
       "\n",
       "n_iter_ : int\n",
       "    The number of iterations the solver has ran.\n",
       "\n",
       "n_layers_ : int\n",
       "    Number of layers.\n",
       "\n",
       "n_outputs_ : int\n",
       "    Number of outputs.\n",
       "\n",
       "out_activation_ : str\n",
       "    Name of the output activation function.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.neural_network import MLPClassifier\n",
       ">>> from sklearn.datasets import make_classification\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X, y = make_classification(n_samples=100, random_state=1)\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
       "...                                                     random_state=1)\n",
       ">>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
       ">>> clf.predict_proba(X_test[:1])\n",
       "array([[0.038..., 0.961...]])\n",
       ">>> clf.predict(X_test[:5, :])\n",
       "array([1, 0, 1, 0, 1])\n",
       ">>> clf.score(X_test, y_test)\n",
       "0.8...\n",
       "\n",
       "Notes\n",
       "-----\n",
       "MLPClassifier trains iteratively since at each time step\n",
       "the partial derivatives of the loss function with respect to the model\n",
       "parameters are computed to update the parameters.\n",
       "\n",
       "It can also have a regularization term added to the loss function\n",
       "that shrinks model parameters to prevent overfitting.\n",
       "\n",
       "This implementation works with data represented as dense numpy arrays or\n",
       "sparse scipy arrays of floating point values.\n",
       "\n",
       "References\n",
       "----------\n",
       "Hinton, Geoffrey E.\n",
       "    \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
       "    (1989): 185-234.\n",
       "\n",
       "Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
       "    training deep feedforward neural networks.\" International Conference\n",
       "    on Artificial Intelligence and Statistics. 2010.\n",
       "\n",
       "He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
       "    performance on imagenet classification.\" arXiv preprint\n",
       "    arXiv:1502.01852 (2015).\n",
       "\n",
       "Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
       "    optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?mlpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_params = {\"alpha\": [0.1, 0.01, 0.02, 0.005, 0.0001,0.00001],\n",
    "              \"hidden_layer_sizes\": [(10,10,10),\n",
    "                                     (100,100,100),\n",
    "                                     (100,100),\n",
    "                                     (3,5), \n",
    "                                     (5, 3)],\n",
    "              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n",
    "              \"activation\": [\"relu\",\"logistic\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'activation': ['relu', 'logistic'],\n",
       "                         'alpha': [0.1, 0.01, 0.02, 0.005, 0.0001, 1e-05],\n",
       "                         'hidden_layer_sizes': [(10, 10, 10), (100, 100, 100),\n",
       "                                                (100, 100), (3, 5), (5, 3)],\n",
       "                         'solver': ['lbfgs', 'adam', 'sgd']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc = MLPClassifier()\n",
    "mlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n",
    "                         cv = 10, \n",
    "                         n_jobs = -1,\n",
    "                         verbose = 2)\n",
    "\n",
    "mlpc_cv_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 100), 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametreler: \" + str(mlpc_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_tuned = MLPClassifier(activation = \"relu\", \n",
    "                           alpha = 0.01, \n",
    "                           hidden_layer_sizes = (100, 100),\n",
    "                          solver = \"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, hidden_layer_sizes=(100, 100), solver='sgd')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc_tuned.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729257641921398"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlpc_tuned.predict(X_test_scaled)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "#X = df[\"Pregnancies\"]\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816593886462883"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        RandomForestClassifier\n",
       "\u001b[1;31mString form:\u001b[0m RandomForestClassifier()\n",
       "\u001b[1;31mLength:\u001b[0m      100\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\donba\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "A random forest classifier.\n",
       "\n",
       "A random forest is a meta estimator that fits a number of decision tree\n",
       "classifiers on various sub-samples of the dataset and uses averaging to\n",
       "improve the predictive accuracy and control over-fitting.\n",
       "The sub-sample size is controlled with the `max_samples` parameter if\n",
       "`bootstrap=True` (default), otherwise the whole dataset is used to build\n",
       "each tree.\n",
       "\n",
       "Read more in the :ref:`User Guide <forest>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_estimators : int, default=100\n",
       "    The number of trees in the forest.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``n_estimators`` changed from 10 to 100\n",
       "       in 0.22.\n",
       "\n",
       "criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
       "    The function to measure the quality of a split. Supported criteria are\n",
       "    \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
       "    Note: this parameter is tree-specific.\n",
       "\n",
       "max_depth : int, default=None\n",
       "    The maximum depth of the tree. If None, then nodes are expanded until\n",
       "    all leaves are pure or until all leaves contain less than\n",
       "    min_samples_split samples.\n",
       "\n",
       "min_samples_split : int or float, default=2\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a fraction and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_samples_leaf : int or float, default=1\n",
       "    The minimum number of samples required to be at a leaf node.\n",
       "    A split point at any depth will only be considered if it leaves at\n",
       "    least ``min_samples_leaf`` training samples in each of the left and\n",
       "    right branches.  This may have the effect of smoothing the model,\n",
       "    especially in regression.\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a fraction and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_weight_fraction_leaf : float, default=0.0\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "    - If int, then consider `max_features` features at each split.\n",
       "    - If float, then `max_features` is a fraction and\n",
       "      `round(max_features * n_features)` features are considered at each\n",
       "      split.\n",
       "    - If \"auto\", then `max_features=sqrt(n_features)`.\n",
       "    - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
       "    - If \"log2\", then `max_features=log2(n_features)`.\n",
       "    - If None, then `max_features=n_features`.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "max_leaf_nodes : int, default=None\n",
       "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "min_impurity_decrease : float, default=0.0\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "min_impurity_split : float, default=None\n",
       "    Threshold for early stopping in tree growth. A node will split\n",
       "    if its impurity is above the threshold, otherwise it is a leaf.\n",
       "\n",
       "    .. deprecated:: 0.19\n",
       "       ``min_impurity_split`` has been deprecated in favor of\n",
       "       ``min_impurity_decrease`` in 0.19. The default value of\n",
       "       ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
       "       will be removed in 1.0 (renaming of 0.25).\n",
       "       Use ``min_impurity_decrease`` instead.\n",
       "\n",
       "bootstrap : bool, default=True\n",
       "    Whether bootstrap samples are used when building trees. If False, the\n",
       "    whole dataset is used to build each tree.\n",
       "\n",
       "oob_score : bool, default=False\n",
       "    Whether to use out-of-bag samples to estimate\n",
       "    the generalization accuracy.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
       "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
       "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
       "    context. ``-1`` means using all processors. See :term:`Glossary\n",
       "    <n_jobs>` for more details.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls both the randomness of the bootstrapping of the samples used\n",
       "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
       "    features to consider when looking for the best split at each node\n",
       "    (if ``max_features < n_features``).\n",
       "    See :term:`Glossary <random_state>` for details.\n",
       "\n",
       "verbose : int, default=0\n",
       "    Controls the verbosity when fitting and predicting.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to ``True``, reuse the solution of the previous call to fit\n",
       "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
       "    new forest. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    If not given, all classes are supposed to have weight one. For\n",
       "    multi-output problems, a list of dicts can be provided in the same\n",
       "    order as the columns of y.\n",
       "\n",
       "    Note that for multioutput (including multilabel) weights should be\n",
       "    defined for each class of every column in its own dict. For example,\n",
       "    for four-class multilabel classification weights should be\n",
       "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
       "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
       "\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "    The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
       "    weights are computed based on the bootstrap sample for every tree\n",
       "    grown.\n",
       "\n",
       "    For multi-output, the weights of each column of y will be multiplied.\n",
       "\n",
       "    Note that these weights will be multiplied with sample_weight (passed\n",
       "    through the fit method) if sample_weight is specified.\n",
       "\n",
       "ccp_alpha : non-negative float, default=0.0\n",
       "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
       "    subtree with the largest cost complexity that is smaller than\n",
       "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
       "    :ref:`minimal_cost_complexity_pruning` for details.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "max_samples : int or float, default=None\n",
       "    If bootstrap is True, the number of samples to draw from X\n",
       "    to train each base estimator.\n",
       "\n",
       "    - If None (default), then draw `X.shape[0]` samples.\n",
       "    - If int, then draw `max_samples` samples.\n",
       "    - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
       "      `max_samples` should be in the interval `(0, 1)`.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "base_estimator_ : DecisionTreeClassifier\n",
       "    The child estimator template used to create the collection of fitted\n",
       "    sub-estimators.\n",
       "\n",
       "estimators_ : list of DecisionTreeClassifier\n",
       "    The collection of fitted sub-estimators.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
       "    The classes labels (single output problem), or a list of arrays of\n",
       "    class labels (multi-output problem).\n",
       "\n",
       "n_classes_ : int or list\n",
       "    The number of classes (single output problem), or a list containing the\n",
       "    number of classes for each output (multi-output problem).\n",
       "\n",
       "n_features_ : int\n",
       "    The number of features when ``fit`` is performed.\n",
       "\n",
       "n_outputs_ : int\n",
       "    The number of outputs when ``fit`` is performed.\n",
       "\n",
       "feature_importances_ : ndarray of shape (n_features,)\n",
       "    The impurity-based feature importances.\n",
       "    The higher, the more important the feature.\n",
       "    The importance of a feature is computed as the (normalized)\n",
       "    total reduction of the criterion brought by that feature.  It is also\n",
       "    known as the Gini importance.\n",
       "\n",
       "    Warning: impurity-based feature importances can be misleading for\n",
       "    high cardinality features (many unique values). See\n",
       "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
       "\n",
       "oob_score_ : float\n",
       "    Score of the training dataset obtained using an out-of-bag estimate.\n",
       "    This attribute exists only when ``oob_score`` is True.\n",
       "\n",
       "oob_decision_function_ : ndarray of shape (n_samples, n_classes)\n",
       "    Decision function computed with out-of-bag estimate on the training\n",
       "    set. If n_estimators is small it might be possible that a data point\n",
       "    was never left out during the bootstrap. In this case,\n",
       "    `oob_decision_function_` might contain NaN. This attribute exists\n",
       "    only when ``oob_score`` is True.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DecisionTreeClassifier, ExtraTreesClassifier\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The default values for the parameters controlling the size of the trees\n",
       "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
       "unpruned trees which can potentially be very large on some data sets. To\n",
       "reduce memory consumption, the complexity and size of the trees should be\n",
       "controlled by setting those parameter values.\n",
       "\n",
       "The features are always randomly permuted at each split. Therefore,\n",
       "the best found split may vary, even with the same training data,\n",
       "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
       "of the criterion is identical for several splits enumerated during the\n",
       "search of the best split. To obtain a deterministic behaviour during\n",
       "fitting, ``random_state`` has to be fixed.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.ensemble import RandomForestClassifier\n",
       ">>> from sklearn.datasets import make_classification\n",
       ">>> X, y = make_classification(n_samples=1000, n_features=4,\n",
       "...                            n_informative=2, n_redundant=0,\n",
       "...                            random_state=0, shuffle=False)\n",
       ">>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
       ">>> clf.fit(X, y)\n",
       "RandomForestClassifier(...)\n",
       ">>> print(clf.predict([[0, 0, 0, 0]]))\n",
       "[1]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"max_depth\": [2,5,8,10],\n",
    "            \"max_features\": [2,5,8],\n",
    "            \"n_estimators\": [10,500,1000],\n",
    "            \"min_samples_split\": [2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_cv_model = GridSearchCV(rf_model, \n",
    "                           rf_params, \n",
    "                           cv = 10, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 5, 8, 10], 'max_features': [2, 5, 8],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 500, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'max_depth': 8, 'max_features': 8, 'min_samples_split': 10, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametreler: \" + str(rf_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=8, min_samples_split=10,\n",
       "                       n_estimators=10)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tuned = RandomForestClassifier(max_depth = 8, \n",
    "                                  max_features = 8, \n",
    "                                  min_samples_split = 10,\n",
    "                                  n_estimators = 10)\n",
    "\n",
    "rf_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685589519650655"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Değişken Önem Düzeyleri')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "plt.xlabel(\"Değişken Önem Düzeyleri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "#X = df[\"Pregnancies\"]\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74235807860262"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        GradientBoostingClassifier\n",
       "\u001b[1;31mString form:\u001b[0m GradientBoostingClassifier()\n",
       "\u001b[1;31mLength:\u001b[0m      100\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\donba\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Gradient Boosting for classification.\n",
       "\n",
       "GB builds an additive model in a\n",
       "forward stage-wise fashion; it allows for the optimization of\n",
       "arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
       "regression trees are fit on the negative gradient of the\n",
       "binomial or multinomial deviance loss function. Binary classification\n",
       "is a special case where only a single regression tree is induced.\n",
       "\n",
       "Read more in the :ref:`User Guide <gradient_boosting>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "loss : {'deviance', 'exponential'}, default='deviance'\n",
       "    The loss function to be optimized. 'deviance' refers to\n",
       "    deviance (= logistic regression) for classification\n",
       "    with probabilistic outputs. For loss 'exponential' gradient\n",
       "    boosting recovers the AdaBoost algorithm.\n",
       "\n",
       "learning_rate : float, default=0.1\n",
       "    Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
       "    There is a trade-off between learning_rate and n_estimators.\n",
       "\n",
       "n_estimators : int, default=100\n",
       "    The number of boosting stages to perform. Gradient boosting\n",
       "    is fairly robust to over-fitting so a large number usually\n",
       "    results in better performance.\n",
       "\n",
       "subsample : float, default=1.0\n",
       "    The fraction of samples to be used for fitting the individual base\n",
       "    learners. If smaller than 1.0 this results in Stochastic Gradient\n",
       "    Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
       "    Choosing `subsample < 1.0` leads to a reduction of variance\n",
       "    and an increase in bias.\n",
       "\n",
       "criterion : {'friedman_mse', 'mse', 'mae'}, default='friedman_mse'\n",
       "    The function to measure the quality of a split. Supported criteria\n",
       "    are 'friedman_mse' for the mean squared error with improvement\n",
       "    score by Friedman, 'mse' for mean squared error, and 'mae' for\n",
       "    the mean absolute error. The default value of 'friedman_mse' is\n",
       "    generally the best as it can provide a better approximation in\n",
       "    some cases.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "    .. deprecated:: 0.24\n",
       "        `criterion='mae'` is deprecated and will be removed in version\n",
       "        1.1 (renaming of 0.26). Use `criterion='friedman_mse'` or `'mse'`\n",
       "        instead, as trees should use a least-square criterion in\n",
       "        Gradient Boosting.\n",
       "\n",
       "min_samples_split : int or float, default=2\n",
       "    The minimum number of samples required to split an internal node:\n",
       "\n",
       "    - If int, then consider `min_samples_split` as the minimum number.\n",
       "    - If float, then `min_samples_split` is a fraction and\n",
       "      `ceil(min_samples_split * n_samples)` are the minimum\n",
       "      number of samples for each split.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_samples_leaf : int or float, default=1\n",
       "    The minimum number of samples required to be at a leaf node.\n",
       "    A split point at any depth will only be considered if it leaves at\n",
       "    least ``min_samples_leaf`` training samples in each of the left and\n",
       "    right branches.  This may have the effect of smoothing the model,\n",
       "    especially in regression.\n",
       "\n",
       "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
       "    - If float, then `min_samples_leaf` is a fraction and\n",
       "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
       "      number of samples for each node.\n",
       "\n",
       "    .. versionchanged:: 0.18\n",
       "       Added float values for fractions.\n",
       "\n",
       "min_weight_fraction_leaf : float, default=0.0\n",
       "    The minimum weighted fraction of the sum total of weights (of all\n",
       "    the input samples) required to be at a leaf node. Samples have\n",
       "    equal weight when sample_weight is not provided.\n",
       "\n",
       "max_depth : int, default=3\n",
       "    The maximum depth of the individual regression estimators. The maximum\n",
       "    depth limits the number of nodes in the tree. Tune this parameter\n",
       "    for best performance; the best value depends on the interaction\n",
       "    of the input variables.\n",
       "\n",
       "min_impurity_decrease : float, default=0.0\n",
       "    A node will be split if this split induces a decrease of the impurity\n",
       "    greater than or equal to this value.\n",
       "\n",
       "    The weighted impurity decrease equation is the following::\n",
       "\n",
       "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
       "                            - N_t_L / N_t * left_impurity)\n",
       "\n",
       "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
       "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
       "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
       "\n",
       "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
       "    if ``sample_weight`` is passed.\n",
       "\n",
       "    .. versionadded:: 0.19\n",
       "\n",
       "min_impurity_split : float, default=None\n",
       "    Threshold for early stopping in tree growth. A node will split\n",
       "    if its impurity is above the threshold, otherwise it is a leaf.\n",
       "\n",
       "    .. deprecated:: 0.19\n",
       "       ``min_impurity_split`` has been deprecated in favor of\n",
       "       ``min_impurity_decrease`` in 0.19. The default value of\n",
       "       ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\n",
       "       will be removed in 1.0 (renaming of 0.25).\n",
       "       Use ``min_impurity_decrease`` instead.\n",
       "\n",
       "init : estimator or 'zero', default=None\n",
       "    An estimator object that is used to compute the initial predictions.\n",
       "    ``init`` has to provide :meth:`fit` and :meth:`predict_proba`. If\n",
       "    'zero', the initial raw predictions are set to zero. By default, a\n",
       "    ``DummyEstimator`` predicting the classes priors is used.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the random seed given to each Tree estimator at each\n",
       "    boosting iteration.\n",
       "    In addition, it controls the random permutation of the features at\n",
       "    each split (see Notes for more details).\n",
       "    It also controls the random spliting of the training data to obtain a\n",
       "    validation set if `n_iter_no_change` is not None.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "max_features : {'auto', 'sqrt', 'log2'}, int or float, default=None\n",
       "    The number of features to consider when looking for the best split:\n",
       "\n",
       "    - If int, then consider `max_features` features at each split.\n",
       "    - If float, then `max_features` is a fraction and\n",
       "      `int(max_features * n_features)` features are considered at each\n",
       "      split.\n",
       "    - If 'auto', then `max_features=sqrt(n_features)`.\n",
       "    - If 'sqrt', then `max_features=sqrt(n_features)`.\n",
       "    - If 'log2', then `max_features=log2(n_features)`.\n",
       "    - If None, then `max_features=n_features`.\n",
       "\n",
       "    Choosing `max_features < n_features` leads to a reduction of variance\n",
       "    and an increase in bias.\n",
       "\n",
       "    Note: the search for a split does not stop until at least one\n",
       "    valid partition of the node samples is found, even if it requires to\n",
       "    effectively inspect more than ``max_features`` features.\n",
       "\n",
       "verbose : int, default=0\n",
       "    Enable verbose output. If 1 then it prints progress and performance\n",
       "    once in a while (the more trees the lower the frequency). If greater\n",
       "    than 1 then it prints progress and performance for every tree.\n",
       "\n",
       "max_leaf_nodes : int, default=None\n",
       "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
       "    Best nodes are defined as relative reduction in impurity.\n",
       "    If None then unlimited number of leaf nodes.\n",
       "\n",
       "warm_start : bool, default=False\n",
       "    When set to ``True``, reuse the solution of the previous call to fit\n",
       "    and add more estimators to the ensemble, otherwise, just erase the\n",
       "    previous solution. See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "validation_fraction : float, default=0.1\n",
       "    The proportion of training data to set aside as validation set for\n",
       "    early stopping. Must be between 0 and 1.\n",
       "    Only used if ``n_iter_no_change`` is set to an integer.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "n_iter_no_change : int, default=None\n",
       "    ``n_iter_no_change`` is used to decide if early stopping will be used\n",
       "    to terminate training when validation score is not improving. By\n",
       "    default it is set to None to disable early stopping. If set to a\n",
       "    number, it will set aside ``validation_fraction`` size of the training\n",
       "    data as validation and terminate training when validation score is not\n",
       "    improving in all of the previous ``n_iter_no_change`` numbers of\n",
       "    iterations. The split is stratified.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "tol : float, default=1e-4\n",
       "    Tolerance for the early stopping. When the loss is not improving\n",
       "    by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
       "    number), the training stops.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "ccp_alpha : non-negative float, default=0.0\n",
       "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
       "    subtree with the largest cost complexity that is smaller than\n",
       "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
       "    :ref:`minimal_cost_complexity_pruning` for details.\n",
       "\n",
       "    .. versionadded:: 0.22\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "n_estimators_ : int\n",
       "    The number of estimators as selected by early stopping (if\n",
       "    ``n_iter_no_change`` is specified). Otherwise it is set to\n",
       "    ``n_estimators``.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "feature_importances_ : ndarray of shape (n_features,)\n",
       "    The impurity-based feature importances.\n",
       "    The higher, the more important the feature.\n",
       "    The importance of a feature is computed as the (normalized)\n",
       "    total reduction of the criterion brought by that feature.  It is also\n",
       "    known as the Gini importance.\n",
       "\n",
       "    Warning: impurity-based feature importances can be misleading for\n",
       "    high cardinality features (many unique values). See\n",
       "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
       "\n",
       "oob_improvement_ : ndarray of shape (n_estimators,)\n",
       "    The improvement in loss (= deviance) on the out-of-bag samples\n",
       "    relative to the previous iteration.\n",
       "    ``oob_improvement_[0]`` is the improvement in\n",
       "    loss of the first stage over the ``init`` estimator.\n",
       "    Only available if ``subsample < 1.0``\n",
       "\n",
       "train_score_ : ndarray of shape (n_estimators,)\n",
       "    The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
       "    model at iteration ``i`` on the in-bag sample.\n",
       "    If ``subsample == 1`` this is the deviance on the training data.\n",
       "\n",
       "loss_ : LossFunction\n",
       "    The concrete ``LossFunction`` object.\n",
       "\n",
       "init_ : estimator\n",
       "    The estimator that provides the initial predictions.\n",
       "    Set via the ``init`` argument or ``loss.init_estimator``.\n",
       "\n",
       "estimators_ : ndarray of DecisionTreeRegressor of shape (n_estimators, ``loss_.K``)\n",
       "    The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
       "    classification, otherwise n_classes.\n",
       "\n",
       "classes_ : ndarray of shape (n_classes,)\n",
       "    The classes labels.\n",
       "\n",
       "n_features_ : int\n",
       "    The number of data features.\n",
       "\n",
       "n_classes_ : int\n",
       "    The number of classes.\n",
       "\n",
       "max_features_ : int\n",
       "    The inferred value of max_features.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "HistGradientBoostingClassifier : Histogram-based Gradient Boosting\n",
       "    Classification Tree.\n",
       "sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
       "RandomForestClassifier : A meta-estimator that fits a number of decision\n",
       "    tree classifiers on various sub-samples of the dataset and uses\n",
       "    averaging to improve the predictive accuracy and control over-fitting.\n",
       "AdaBoostClassifier : A meta-estimator that begins by fitting a classifier\n",
       "    on the original dataset and then fits additional copies of the\n",
       "    classifier on the same dataset where the weights of incorrectly\n",
       "    classified instances are adjusted such that subsequent classifiers\n",
       "    focus more on difficult cases.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The features are always randomly permuted at each split. Therefore,\n",
       "the best found split may vary, even with the same training data and\n",
       "``max_features=n_features``, if the improvement of the criterion is\n",
       "identical for several splits enumerated during the search of the best\n",
       "split. To obtain a deterministic behaviour during fitting,\n",
       "``random_state`` has to be fixed.\n",
       "\n",
       "References\n",
       "----------\n",
       "J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
       "Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
       "\n",
       "J. Friedman, Stochastic Gradient Boosting, 1999\n",
       "\n",
       "T. Hastie, R. Tibshirani and J. Friedman.\n",
       "Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "The following example shows how to fit a gradient boosting classifier with\n",
       "100 decision stumps as weak learners.\n",
       "\n",
       ">>> from sklearn.datasets import make_hastie_10_2\n",
       ">>> from sklearn.ensemble import GradientBoostingClassifier\n",
       "\n",
       ">>> X, y = make_hastie_10_2(random_state=0)\n",
       ">>> X_train, X_test = X[:2000], X[2000:]\n",
       ">>> y_train, y_test = y[:2000], y[2000:]\n",
       "\n",
       ">>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
       "...     max_depth=1, random_state=0).fit(X_train, y_train)\n",
       ">>> clf.score(X_test, y_test)\n",
       "0.913...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?gbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n",
    "             \"n_estimators\": [100,500,100],\n",
    "             \"max_depth\": [3,5,10],\n",
    "             \"min_samples_split\": [2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "gbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.01, 0.1, 0.05],\n",
       "                         'max_depth': [3, 5, 10],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 500, 100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'learning_rate': 0.01, 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametreler: \" + str(gbm_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(learning_rate = 0.01, \n",
    "                                 max_depth = 5,\n",
    "                                min_samples_split = 10,\n",
    "                                n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tuned =  gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759825327510917"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "#X = df[\"Pregnancies\"]\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74235807860262"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        XGBClassifier\n",
       "\u001b[1;31mString form:\u001b[0m\n",
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "           colsample_byno <...> _weight=1, subsample=1,\n",
       "           tree_method='exact', validate_parameters=1, verbosity=None)\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\donba\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Implementation of the scikit-learn API for XGBoost classification.\n",
       "\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "\n",
       "    n_estimators : int\n",
       "        Number of boosting rounds.\n",
       "    use_label_encoder : bool\n",
       "        (Deprecated) Use the label encoder from scikit-learn to encode the labels. For new\n",
       "        code, we recommend that you set this parameter to False.\n",
       "\n",
       "    max_depth : int\n",
       "        Maximum tree depth for base learners.\n",
       "    learning_rate : float\n",
       "        Boosting learning rate (xgb's \"eta\")\n",
       "    verbosity : int\n",
       "        The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
       "    objective : string or callable\n",
       "        Specify the learning task and the corresponding learning objective or\n",
       "        a custom objective function to be used (see note below).\n",
       "    booster: string\n",
       "        Specify which booster to use: gbtree, gblinear or dart.\n",
       "    tree_method: string\n",
       "        Specify which tree method to use.  Default to auto.  If this parameter\n",
       "        is set to default, XGBoost will choose the most conservative option\n",
       "        available.  It's recommended to study this option from parameters\n",
       "        document.\n",
       "    n_jobs : int\n",
       "        Number of parallel threads used to run xgboost.  When used with other Scikit-Learn\n",
       "        algorithms like grid search, you may choose which algorithm to parallelize and\n",
       "        balance the threads.  Creating thread contention will significantly slow down both\n",
       "        algorithms.\n",
       "    gamma : float\n",
       "        Minimum loss reduction required to make a further partition on a leaf\n",
       "        node of the tree.\n",
       "    min_child_weight : float\n",
       "        Minimum sum of instance weight(hessian) needed in a child.\n",
       "    max_delta_step : float\n",
       "        Maximum delta step we allow each tree's weight estimation to be.\n",
       "    subsample : float\n",
       "        Subsample ratio of the training instance.\n",
       "    colsample_bytree : float\n",
       "        Subsample ratio of columns when constructing each tree.\n",
       "    colsample_bylevel : float\n",
       "        Subsample ratio of columns for each level.\n",
       "    colsample_bynode : float\n",
       "        Subsample ratio of columns for each split.\n",
       "    reg_alpha : float (xgb's alpha)\n",
       "        L1 regularization term on weights\n",
       "    reg_lambda : float (xgb's lambda)\n",
       "        L2 regularization term on weights\n",
       "    scale_pos_weight : float\n",
       "        Balancing of positive and negative weights.\n",
       "    base_score:\n",
       "        The initial prediction score of all instances, global bias.\n",
       "    random_state : int\n",
       "        Random number seed.\n",
       "\n",
       "        .. note::\n",
       "\n",
       "           Using gblinear booster with shotgun updater is nondeterministic as\n",
       "           it uses Hogwild algorithm.\n",
       "\n",
       "    missing : float, default np.nan\n",
       "        Value in the data which needs to be present as a missing value.\n",
       "    num_parallel_tree: int\n",
       "        Used for boosting random forest.\n",
       "    monotone_constraints : str\n",
       "        Constraint of variable monotonicity.  See tutorial for more\n",
       "        information.\n",
       "    interaction_constraints : str\n",
       "        Constraints for interaction representing permitted interactions.  The\n",
       "        constraints must be specified in the form of a nest list, e.g. [[0, 1],\n",
       "        [2, 3, 4]], where each inner list is a group of indices of features\n",
       "        that are allowed to interact with each other.  See tutorial for more\n",
       "        information\n",
       "    importance_type: string, default \"gain\"\n",
       "        The feature importance type for the feature_importances\\_ property:\n",
       "        either \"gain\", \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
       "    gpu_id :\n",
       "        Device ordinal.\n",
       "    validate_parameters :\n",
       "        Give warnings for unknown parameter.\n",
       "\n",
       "    \\*\\*kwargs : dict, optional\n",
       "        Keyword arguments for XGBoost Booster object.  Full documentation of\n",
       "        parameters can be found here:\n",
       "        https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
       "        Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
       "        dict simultaneously will result in a TypeError.\n",
       "\n",
       "        .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
       "\n",
       "            \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
       "            that parameters passed via this argument will interact properly\n",
       "            with scikit-learn.\n",
       "\n",
       "        .. note::  Custom objective function\n",
       "\n",
       "            A custom objective function can be provided for the ``objective``\n",
       "            parameter. In this case, it should have the signature\n",
       "            ``objective(y_true, y_pred) -> grad, hess``:\n",
       "\n",
       "            y_true: array_like of shape [n_samples]\n",
       "                The target values\n",
       "            y_pred: array_like of shape [n_samples]\n",
       "                The predicted values\n",
       "\n",
       "            grad: array_like of shape [n_samples]\n",
       "                The value of the gradient for each sample point.\n",
       "            hess: array_like of shape [n_samples]\n",
       "                The value of the second derivative for each sample point\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'n_estimators': [100, 500, 1000, 2000],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5,6],\n",
    "        'learning_rate': [0.1,0.01,0.02,0.05],\n",
    "        \"min_samples_split\": [2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 576 candidates, totalling 5760 fits\n",
      "[16:59:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:59:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_job...,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.02, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 500, 1000, 2000],\n",
       "                         'subsample': [0.6, 0.8, 1.0]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate = 0.05, \n",
    "                    max_depth = 5,\n",
    "                    min_samples_split = 2,\n",
    "                    n_estimators = 100,\n",
    "                    subsample = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"min_samples_split\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned =  xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729257641921398"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "#X = df[\"Pregnancies\"]\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge lightgbm\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7554585152838428"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgbm_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "        'n_estimators': [100, 500, 1000, 2000],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5,6],\n",
    "        'learning_rate': [0.1,0.01,0.02,0.05],\n",
    "        \"min_child_samples\": [5,10,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "\n",
    "lgbm_cv_model = GridSearchCV(lgbm, lgbm_params, \n",
    "                             cv = 10, \n",
    "                             n_jobs = -1, \n",
    "                             verbose = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 576 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LGBMClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.02, 0.05],\n",
       "                         'max_depth': [3, 4, 5, 6],\n",
       "                         'min_child_samples': [5, 10, 20],\n",
       "                         'n_estimators': [100, 500, 1000, 2000],\n",
       "                         'subsample': [0.6, 0.8, 1.0]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 5,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(learning_rate = 0.02, \n",
    "                       max_depth = 5,\n",
    "                       subsample = 0.6,\n",
    "                       n_estimators = 100,\n",
    "                       min_child_samples = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_tuned = lgbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685589519650655"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgbm_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Outcome\"]\n",
    "X = df.drop(['Outcome'], axis=1)\n",
    "#X = df[\"Pregnancies\"]\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.007875\n",
      "0:\tlearn: 0.6884635\ttotal: 124ms\tremaining: 2m 3s\n",
      "1:\tlearn: 0.6839412\ttotal: 129ms\tremaining: 1m 4s\n",
      "2:\tlearn: 0.6798718\ttotal: 133ms\tremaining: 44.1s\n",
      "3:\tlearn: 0.6760508\ttotal: 137ms\tremaining: 34.1s\n",
      "4:\tlearn: 0.6728764\ttotal: 140ms\tremaining: 27.8s\n",
      "5:\tlearn: 0.6688114\ttotal: 143ms\tremaining: 23.7s\n",
      "6:\tlearn: 0.6652028\ttotal: 146ms\tremaining: 20.7s\n",
      "7:\tlearn: 0.6617717\ttotal: 150ms\tremaining: 18.6s\n",
      "8:\tlearn: 0.6589662\ttotal: 153ms\tremaining: 16.9s\n",
      "9:\tlearn: 0.6561000\ttotal: 157ms\tremaining: 15.5s\n",
      "10:\tlearn: 0.6520011\ttotal: 160ms\tremaining: 14.4s\n",
      "11:\tlearn: 0.6491374\ttotal: 163ms\tremaining: 13.4s\n",
      "12:\tlearn: 0.6458028\ttotal: 166ms\tremaining: 12.6s\n",
      "13:\tlearn: 0.6424921\ttotal: 170ms\tremaining: 12s\n",
      "14:\tlearn: 0.6386606\ttotal: 174ms\tremaining: 11.4s\n",
      "15:\tlearn: 0.6356130\ttotal: 177ms\tremaining: 10.9s\n",
      "16:\tlearn: 0.6319201\ttotal: 180ms\tremaining: 10.4s\n",
      "17:\tlearn: 0.6287306\ttotal: 184ms\tremaining: 10s\n",
      "18:\tlearn: 0.6260176\ttotal: 187ms\tremaining: 9.63s\n",
      "19:\tlearn: 0.6237592\ttotal: 190ms\tremaining: 9.3s\n",
      "20:\tlearn: 0.6204317\ttotal: 193ms\tremaining: 9.02s\n",
      "21:\tlearn: 0.6177830\ttotal: 197ms\tremaining: 8.74s\n",
      "22:\tlearn: 0.6145918\ttotal: 200ms\tremaining: 8.49s\n",
      "23:\tlearn: 0.6111969\ttotal: 203ms\tremaining: 8.27s\n",
      "24:\tlearn: 0.6087238\ttotal: 207ms\tremaining: 8.07s\n",
      "25:\tlearn: 0.6065525\ttotal: 211ms\tremaining: 7.91s\n",
      "26:\tlearn: 0.6034798\ttotal: 214ms\tremaining: 7.73s\n",
      "27:\tlearn: 0.6006233\ttotal: 218ms\tremaining: 7.57s\n",
      "28:\tlearn: 0.5981031\ttotal: 222ms\tremaining: 7.43s\n",
      "29:\tlearn: 0.5953804\ttotal: 225ms\tremaining: 7.28s\n",
      "30:\tlearn: 0.5923895\ttotal: 228ms\tremaining: 7.14s\n",
      "31:\tlearn: 0.5897439\ttotal: 232ms\tremaining: 7.02s\n",
      "32:\tlearn: 0.5870777\ttotal: 236ms\tremaining: 6.92s\n",
      "33:\tlearn: 0.5854047\ttotal: 240ms\tremaining: 6.8s\n",
      "34:\tlearn: 0.5834430\ttotal: 243ms\tremaining: 6.7s\n",
      "35:\tlearn: 0.5811181\ttotal: 246ms\tremaining: 6.6s\n",
      "36:\tlearn: 0.5785914\ttotal: 250ms\tremaining: 6.5s\n",
      "37:\tlearn: 0.5765278\ttotal: 253ms\tremaining: 6.41s\n",
      "38:\tlearn: 0.5744867\ttotal: 257ms\tremaining: 6.34s\n",
      "39:\tlearn: 0.5719159\ttotal: 262ms\tremaining: 6.28s\n",
      "40:\tlearn: 0.5695529\ttotal: 265ms\tremaining: 6.21s\n",
      "41:\tlearn: 0.5670907\ttotal: 269ms\tremaining: 6.14s\n",
      "42:\tlearn: 0.5649162\ttotal: 273ms\tremaining: 6.08s\n",
      "43:\tlearn: 0.5624961\ttotal: 277ms\tremaining: 6.01s\n",
      "44:\tlearn: 0.5602539\ttotal: 280ms\tremaining: 5.95s\n",
      "45:\tlearn: 0.5579043\ttotal: 285ms\tremaining: 5.9s\n",
      "46:\tlearn: 0.5563789\ttotal: 290ms\tremaining: 5.88s\n",
      "47:\tlearn: 0.5543106\ttotal: 294ms\tremaining: 5.82s\n",
      "48:\tlearn: 0.5519208\ttotal: 299ms\tremaining: 5.79s\n",
      "49:\tlearn: 0.5503907\ttotal: 302ms\tremaining: 5.73s\n",
      "50:\tlearn: 0.5482357\ttotal: 305ms\tremaining: 5.68s\n",
      "51:\tlearn: 0.5465601\ttotal: 310ms\tremaining: 5.65s\n",
      "52:\tlearn: 0.5443082\ttotal: 314ms\tremaining: 5.61s\n",
      "53:\tlearn: 0.5425685\ttotal: 318ms\tremaining: 5.57s\n",
      "54:\tlearn: 0.5405515\ttotal: 321ms\tremaining: 5.52s\n",
      "55:\tlearn: 0.5383084\ttotal: 325ms\tremaining: 5.48s\n",
      "56:\tlearn: 0.5367662\ttotal: 330ms\tremaining: 5.45s\n",
      "57:\tlearn: 0.5352244\ttotal: 333ms\tremaining: 5.41s\n",
      "58:\tlearn: 0.5332020\ttotal: 338ms\tremaining: 5.39s\n",
      "59:\tlearn: 0.5314650\ttotal: 342ms\tremaining: 5.35s\n",
      "60:\tlearn: 0.5296842\ttotal: 346ms\tremaining: 5.32s\n",
      "61:\tlearn: 0.5280219\ttotal: 349ms\tremaining: 5.28s\n",
      "62:\tlearn: 0.5261422\ttotal: 352ms\tremaining: 5.24s\n",
      "63:\tlearn: 0.5241607\ttotal: 355ms\tremaining: 5.2s\n",
      "64:\tlearn: 0.5222112\ttotal: 359ms\tremaining: 5.16s\n",
      "65:\tlearn: 0.5202464\ttotal: 362ms\tremaining: 5.12s\n",
      "66:\tlearn: 0.5182671\ttotal: 365ms\tremaining: 5.08s\n",
      "67:\tlearn: 0.5163844\ttotal: 369ms\tremaining: 5.05s\n",
      "68:\tlearn: 0.5154142\ttotal: 371ms\tremaining: 5s\n",
      "69:\tlearn: 0.5137742\ttotal: 374ms\tremaining: 4.97s\n",
      "70:\tlearn: 0.5122018\ttotal: 378ms\tremaining: 4.94s\n",
      "71:\tlearn: 0.5107177\ttotal: 381ms\tremaining: 4.91s\n",
      "72:\tlearn: 0.5091825\ttotal: 384ms\tremaining: 4.88s\n",
      "73:\tlearn: 0.5079613\ttotal: 388ms\tremaining: 4.85s\n",
      "74:\tlearn: 0.5062202\ttotal: 391ms\tremaining: 4.83s\n",
      "75:\tlearn: 0.5049225\ttotal: 394ms\tremaining: 4.8s\n",
      "76:\tlearn: 0.5034202\ttotal: 397ms\tremaining: 4.76s\n",
      "77:\tlearn: 0.5017657\ttotal: 401ms\tremaining: 4.74s\n",
      "78:\tlearn: 0.5005111\ttotal: 404ms\tremaining: 4.71s\n",
      "79:\tlearn: 0.4992058\ttotal: 408ms\tremaining: 4.69s\n",
      "80:\tlearn: 0.4979896\ttotal: 411ms\tremaining: 4.67s\n",
      "81:\tlearn: 0.4971986\ttotal: 415ms\tremaining: 4.65s\n",
      "82:\tlearn: 0.4959122\ttotal: 419ms\tremaining: 4.62s\n",
      "83:\tlearn: 0.4946468\ttotal: 422ms\tremaining: 4.6s\n",
      "84:\tlearn: 0.4931801\ttotal: 425ms\tremaining: 4.58s\n",
      "85:\tlearn: 0.4921432\ttotal: 429ms\tremaining: 4.56s\n",
      "86:\tlearn: 0.4908045\ttotal: 433ms\tremaining: 4.54s\n",
      "87:\tlearn: 0.4895597\ttotal: 437ms\tremaining: 4.53s\n",
      "88:\tlearn: 0.4879561\ttotal: 441ms\tremaining: 4.51s\n",
      "89:\tlearn: 0.4867797\ttotal: 444ms\tremaining: 4.49s\n",
      "90:\tlearn: 0.4855264\ttotal: 448ms\tremaining: 4.47s\n",
      "91:\tlearn: 0.4842552\ttotal: 451ms\tremaining: 4.45s\n",
      "92:\tlearn: 0.4825971\ttotal: 455ms\tremaining: 4.43s\n",
      "93:\tlearn: 0.4817296\ttotal: 460ms\tremaining: 4.43s\n",
      "94:\tlearn: 0.4805977\ttotal: 464ms\tremaining: 4.42s\n",
      "95:\tlearn: 0.4790972\ttotal: 468ms\tremaining: 4.41s\n",
      "96:\tlearn: 0.4777923\ttotal: 472ms\tremaining: 4.4s\n",
      "97:\tlearn: 0.4764679\ttotal: 476ms\tremaining: 4.38s\n",
      "98:\tlearn: 0.4751990\ttotal: 480ms\tremaining: 4.37s\n",
      "99:\tlearn: 0.4739475\ttotal: 484ms\tremaining: 4.35s\n",
      "100:\tlearn: 0.4726301\ttotal: 487ms\tremaining: 4.34s\n",
      "101:\tlearn: 0.4713474\ttotal: 491ms\tremaining: 4.33s\n",
      "102:\tlearn: 0.4703793\ttotal: 495ms\tremaining: 4.31s\n",
      "103:\tlearn: 0.4692857\ttotal: 499ms\tremaining: 4.3s\n",
      "104:\tlearn: 0.4680258\ttotal: 503ms\tremaining: 4.29s\n",
      "105:\tlearn: 0.4668465\ttotal: 507ms\tremaining: 4.28s\n",
      "106:\tlearn: 0.4658460\ttotal: 511ms\tremaining: 4.26s\n",
      "107:\tlearn: 0.4649434\ttotal: 514ms\tremaining: 4.25s\n",
      "108:\tlearn: 0.4641276\ttotal: 519ms\tremaining: 4.25s\n",
      "109:\tlearn: 0.4634386\ttotal: 524ms\tremaining: 4.24s\n",
      "110:\tlearn: 0.4626345\ttotal: 528ms\tremaining: 4.23s\n",
      "111:\tlearn: 0.4617130\ttotal: 531ms\tremaining: 4.21s\n",
      "112:\tlearn: 0.4605254\ttotal: 534ms\tremaining: 4.19s\n",
      "113:\tlearn: 0.4598700\ttotal: 538ms\tremaining: 4.18s\n",
      "114:\tlearn: 0.4591122\ttotal: 541ms\tremaining: 4.16s\n",
      "115:\tlearn: 0.4584264\ttotal: 543ms\tremaining: 4.14s\n",
      "116:\tlearn: 0.4574767\ttotal: 546ms\tremaining: 4.12s\n",
      "117:\tlearn: 0.4566676\ttotal: 551ms\tremaining: 4.12s\n",
      "118:\tlearn: 0.4559729\ttotal: 555ms\tremaining: 4.11s\n",
      "119:\tlearn: 0.4550486\ttotal: 559ms\tremaining: 4.1s\n",
      "120:\tlearn: 0.4538569\ttotal: 562ms\tremaining: 4.08s\n",
      "121:\tlearn: 0.4529287\ttotal: 566ms\tremaining: 4.07s\n",
      "122:\tlearn: 0.4523714\ttotal: 569ms\tremaining: 4.06s\n",
      "123:\tlearn: 0.4515172\ttotal: 573ms\tremaining: 4.04s\n",
      "124:\tlearn: 0.4504241\ttotal: 576ms\tremaining: 4.03s\n",
      "125:\tlearn: 0.4494838\ttotal: 580ms\tremaining: 4.02s\n",
      "126:\tlearn: 0.4485774\ttotal: 583ms\tremaining: 4.01s\n",
      "127:\tlearn: 0.4477631\ttotal: 587ms\tremaining: 4s\n",
      "128:\tlearn: 0.4468897\ttotal: 591ms\tremaining: 3.99s\n",
      "129:\tlearn: 0.4460440\ttotal: 594ms\tremaining: 3.98s\n",
      "130:\tlearn: 0.4453980\ttotal: 598ms\tremaining: 3.97s\n",
      "131:\tlearn: 0.4444381\ttotal: 601ms\tremaining: 3.95s\n",
      "132:\tlearn: 0.4434916\ttotal: 605ms\tremaining: 3.94s\n",
      "133:\tlearn: 0.4426400\ttotal: 608ms\tremaining: 3.93s\n",
      "134:\tlearn: 0.4418708\ttotal: 611ms\tremaining: 3.92s\n",
      "135:\tlearn: 0.4408543\ttotal: 615ms\tremaining: 3.91s\n",
      "136:\tlearn: 0.4401415\ttotal: 619ms\tremaining: 3.9s\n",
      "137:\tlearn: 0.4393201\ttotal: 622ms\tremaining: 3.89s\n",
      "138:\tlearn: 0.4386519\ttotal: 626ms\tremaining: 3.88s\n",
      "139:\tlearn: 0.4375685\ttotal: 629ms\tremaining: 3.87s\n",
      "140:\tlearn: 0.4367332\ttotal: 633ms\tremaining: 3.85s\n",
      "141:\tlearn: 0.4355464\ttotal: 636ms\tremaining: 3.84s\n",
      "142:\tlearn: 0.4347501\ttotal: 643ms\tremaining: 3.85s\n",
      "143:\tlearn: 0.4341170\ttotal: 646ms\tremaining: 3.84s\n",
      "144:\tlearn: 0.4335822\ttotal: 650ms\tremaining: 3.83s\n",
      "145:\tlearn: 0.4327340\ttotal: 653ms\tremaining: 3.82s\n",
      "146:\tlearn: 0.4317376\ttotal: 657ms\tremaining: 3.81s\n",
      "147:\tlearn: 0.4311505\ttotal: 660ms\tremaining: 3.8s\n",
      "148:\tlearn: 0.4304911\ttotal: 663ms\tremaining: 3.78s\n",
      "149:\tlearn: 0.4298788\ttotal: 665ms\tremaining: 3.77s\n",
      "150:\tlearn: 0.4292165\ttotal: 669ms\tremaining: 3.76s\n",
      "151:\tlearn: 0.4285197\ttotal: 672ms\tremaining: 3.75s\n",
      "152:\tlearn: 0.4277801\ttotal: 674ms\tremaining: 3.73s\n",
      "153:\tlearn: 0.4270844\ttotal: 677ms\tremaining: 3.72s\n",
      "154:\tlearn: 0.4265789\ttotal: 680ms\tremaining: 3.71s\n",
      "155:\tlearn: 0.4256177\ttotal: 683ms\tremaining: 3.69s\n",
      "156:\tlearn: 0.4249595\ttotal: 686ms\tremaining: 3.68s\n",
      "157:\tlearn: 0.4247007\ttotal: 689ms\tremaining: 3.67s\n",
      "158:\tlearn: 0.4237543\ttotal: 692ms\tremaining: 3.66s\n",
      "159:\tlearn: 0.4231841\ttotal: 695ms\tremaining: 3.65s\n",
      "160:\tlearn: 0.4227081\ttotal: 698ms\tremaining: 3.64s\n",
      "161:\tlearn: 0.4219174\ttotal: 702ms\tremaining: 3.63s\n",
      "162:\tlearn: 0.4214313\ttotal: 706ms\tremaining: 3.63s\n",
      "163:\tlearn: 0.4207974\ttotal: 709ms\tremaining: 3.61s\n",
      "164:\tlearn: 0.4201576\ttotal: 712ms\tremaining: 3.6s\n",
      "165:\tlearn: 0.4194181\ttotal: 716ms\tremaining: 3.6s\n",
      "166:\tlearn: 0.4188327\ttotal: 720ms\tremaining: 3.59s\n",
      "167:\tlearn: 0.4183605\ttotal: 724ms\tremaining: 3.58s\n",
      "168:\tlearn: 0.4174978\ttotal: 728ms\tremaining: 3.58s\n",
      "169:\tlearn: 0.4168223\ttotal: 732ms\tremaining: 3.57s\n",
      "170:\tlearn: 0.4162154\ttotal: 735ms\tremaining: 3.56s\n",
      "171:\tlearn: 0.4152679\ttotal: 738ms\tremaining: 3.55s\n",
      "172:\tlearn: 0.4147112\ttotal: 741ms\tremaining: 3.54s\n",
      "173:\tlearn: 0.4142023\ttotal: 744ms\tremaining: 3.53s\n",
      "174:\tlearn: 0.4136684\ttotal: 747ms\tremaining: 3.52s\n",
      "175:\tlearn: 0.4131173\ttotal: 750ms\tremaining: 3.51s\n",
      "176:\tlearn: 0.4123794\ttotal: 753ms\tremaining: 3.5s\n",
      "177:\tlearn: 0.4114712\ttotal: 758ms\tremaining: 3.5s\n",
      "178:\tlearn: 0.4106940\ttotal: 761ms\tremaining: 3.49s\n",
      "179:\tlearn: 0.4099035\ttotal: 764ms\tremaining: 3.48s\n",
      "180:\tlearn: 0.4095392\ttotal: 767ms\tremaining: 3.47s\n",
      "181:\tlearn: 0.4086974\ttotal: 770ms\tremaining: 3.46s\n",
      "182:\tlearn: 0.4079610\ttotal: 772ms\tremaining: 3.45s\n",
      "183:\tlearn: 0.4073115\ttotal: 776ms\tremaining: 3.44s\n",
      "184:\tlearn: 0.4069852\ttotal: 778ms\tremaining: 3.43s\n",
      "185:\tlearn: 0.4062705\ttotal: 781ms\tremaining: 3.42s\n",
      "186:\tlearn: 0.4057207\ttotal: 784ms\tremaining: 3.41s\n",
      "187:\tlearn: 0.4053523\ttotal: 787ms\tremaining: 3.4s\n",
      "188:\tlearn: 0.4046349\ttotal: 791ms\tremaining: 3.39s\n",
      "189:\tlearn: 0.4040313\ttotal: 794ms\tremaining: 3.38s\n",
      "190:\tlearn: 0.4034972\ttotal: 797ms\tremaining: 3.38s\n",
      "191:\tlearn: 0.4030150\ttotal: 800ms\tremaining: 3.37s\n",
      "192:\tlearn: 0.4023878\ttotal: 804ms\tremaining: 3.36s\n",
      "193:\tlearn: 0.4017301\ttotal: 808ms\tremaining: 3.35s\n",
      "194:\tlearn: 0.4010142\ttotal: 811ms\tremaining: 3.35s\n",
      "195:\tlearn: 0.4005760\ttotal: 815ms\tremaining: 3.34s\n",
      "196:\tlearn: 0.3999321\ttotal: 818ms\tremaining: 3.34s\n",
      "197:\tlearn: 0.3993148\ttotal: 823ms\tremaining: 3.33s\n",
      "198:\tlearn: 0.3988838\ttotal: 826ms\tremaining: 3.33s\n",
      "199:\tlearn: 0.3983889\ttotal: 830ms\tremaining: 3.32s\n",
      "200:\tlearn: 0.3979113\ttotal: 835ms\tremaining: 3.32s\n",
      "201:\tlearn: 0.3974201\ttotal: 839ms\tremaining: 3.31s\n",
      "202:\tlearn: 0.3970783\ttotal: 842ms\tremaining: 3.31s\n",
      "203:\tlearn: 0.3964617\ttotal: 845ms\tremaining: 3.3s\n",
      "204:\tlearn: 0.3957786\ttotal: 849ms\tremaining: 3.29s\n",
      "205:\tlearn: 0.3953262\ttotal: 852ms\tremaining: 3.28s\n",
      "206:\tlearn: 0.3947027\ttotal: 855ms\tremaining: 3.27s\n",
      "207:\tlearn: 0.3943181\ttotal: 858ms\tremaining: 3.27s\n",
      "208:\tlearn: 0.3938481\ttotal: 862ms\tremaining: 3.26s\n",
      "209:\tlearn: 0.3934061\ttotal: 865ms\tremaining: 3.25s\n",
      "210:\tlearn: 0.3930601\ttotal: 870ms\tremaining: 3.25s\n",
      "211:\tlearn: 0.3925449\ttotal: 874ms\tremaining: 3.25s\n",
      "212:\tlearn: 0.3920327\ttotal: 878ms\tremaining: 3.25s\n",
      "213:\tlearn: 0.3913942\ttotal: 883ms\tremaining: 3.24s\n",
      "214:\tlearn: 0.3909603\ttotal: 888ms\tremaining: 3.24s\n",
      "215:\tlearn: 0.3905080\ttotal: 892ms\tremaining: 3.24s\n",
      "216:\tlearn: 0.3899342\ttotal: 896ms\tremaining: 3.23s\n",
      "217:\tlearn: 0.3890845\ttotal: 901ms\tremaining: 3.23s\n",
      "218:\tlearn: 0.3884633\ttotal: 905ms\tremaining: 3.23s\n",
      "219:\tlearn: 0.3879147\ttotal: 910ms\tremaining: 3.23s\n",
      "220:\tlearn: 0.3876372\ttotal: 914ms\tremaining: 3.22s\n",
      "221:\tlearn: 0.3868894\ttotal: 919ms\tremaining: 3.22s\n",
      "222:\tlearn: 0.3864744\ttotal: 924ms\tremaining: 3.22s\n",
      "223:\tlearn: 0.3860097\ttotal: 929ms\tremaining: 3.22s\n",
      "224:\tlearn: 0.3853693\ttotal: 933ms\tremaining: 3.21s\n",
      "225:\tlearn: 0.3851379\ttotal: 938ms\tremaining: 3.21s\n",
      "226:\tlearn: 0.3844358\ttotal: 944ms\tremaining: 3.21s\n",
      "227:\tlearn: 0.3841614\ttotal: 950ms\tremaining: 3.22s\n",
      "228:\tlearn: 0.3836231\ttotal: 954ms\tremaining: 3.21s\n",
      "229:\tlearn: 0.3832965\ttotal: 957ms\tremaining: 3.2s\n",
      "230:\tlearn: 0.3827490\ttotal: 960ms\tremaining: 3.2s\n",
      "231:\tlearn: 0.3821719\ttotal: 964ms\tremaining: 3.19s\n",
      "232:\tlearn: 0.3816233\ttotal: 972ms\tremaining: 3.2s\n",
      "233:\tlearn: 0.3811327\ttotal: 981ms\tremaining: 3.21s\n",
      "234:\tlearn: 0.3806269\ttotal: 987ms\tremaining: 3.21s\n",
      "235:\tlearn: 0.3801221\ttotal: 996ms\tremaining: 3.22s\n",
      "236:\tlearn: 0.3798001\ttotal: 1s\tremaining: 3.23s\n",
      "237:\tlearn: 0.3794909\ttotal: 1.01s\tremaining: 3.23s\n",
      "238:\tlearn: 0.3792403\ttotal: 1.02s\tremaining: 3.24s\n",
      "239:\tlearn: 0.3787134\ttotal: 1.03s\tremaining: 3.25s\n",
      "240:\tlearn: 0.3782087\ttotal: 1.03s\tremaining: 3.25s\n",
      "241:\tlearn: 0.3775148\ttotal: 1.03s\tremaining: 3.24s\n",
      "242:\tlearn: 0.3768465\ttotal: 1.04s\tremaining: 3.24s\n",
      "243:\tlearn: 0.3764512\ttotal: 1.04s\tremaining: 3.24s\n",
      "244:\tlearn: 0.3761008\ttotal: 1.05s\tremaining: 3.23s\n",
      "245:\tlearn: 0.3756755\ttotal: 1.05s\tremaining: 3.23s\n",
      "246:\tlearn: 0.3750313\ttotal: 1.06s\tremaining: 3.22s\n",
      "247:\tlearn: 0.3746107\ttotal: 1.06s\tremaining: 3.23s\n",
      "248:\tlearn: 0.3740636\ttotal: 1.07s\tremaining: 3.23s\n",
      "249:\tlearn: 0.3736547\ttotal: 1.08s\tremaining: 3.23s\n",
      "250:\tlearn: 0.3731457\ttotal: 1.08s\tremaining: 3.23s\n",
      "251:\tlearn: 0.3728254\ttotal: 1.09s\tremaining: 3.23s\n",
      "252:\tlearn: 0.3724377\ttotal: 1.09s\tremaining: 3.22s\n",
      "253:\tlearn: 0.3719729\ttotal: 1.1s\tremaining: 3.22s\n",
      "254:\tlearn: 0.3716076\ttotal: 1.1s\tremaining: 3.22s\n",
      "255:\tlearn: 0.3712443\ttotal: 1.11s\tremaining: 3.22s\n",
      "256:\tlearn: 0.3709101\ttotal: 1.11s\tremaining: 3.21s\n",
      "257:\tlearn: 0.3703656\ttotal: 1.12s\tremaining: 3.21s\n",
      "258:\tlearn: 0.3700367\ttotal: 1.12s\tremaining: 3.21s\n",
      "259:\tlearn: 0.3696511\ttotal: 1.12s\tremaining: 3.2s\n",
      "260:\tlearn: 0.3692213\ttotal: 1.13s\tremaining: 3.2s\n",
      "261:\tlearn: 0.3689459\ttotal: 1.13s\tremaining: 3.19s\n",
      "262:\tlearn: 0.3685450\ttotal: 1.14s\tremaining: 3.19s\n",
      "263:\tlearn: 0.3681474\ttotal: 1.14s\tremaining: 3.18s\n",
      "264:\tlearn: 0.3676801\ttotal: 1.15s\tremaining: 3.18s\n",
      "265:\tlearn: 0.3673640\ttotal: 1.15s\tremaining: 3.18s\n",
      "266:\tlearn: 0.3669994\ttotal: 1.16s\tremaining: 3.18s\n",
      "267:\tlearn: 0.3663935\ttotal: 1.16s\tremaining: 3.17s\n",
      "268:\tlearn: 0.3658536\ttotal: 1.17s\tremaining: 3.17s\n",
      "269:\tlearn: 0.3652406\ttotal: 1.17s\tremaining: 3.17s\n",
      "270:\tlearn: 0.3648433\ttotal: 1.18s\tremaining: 3.16s\n",
      "271:\tlearn: 0.3642316\ttotal: 1.18s\tremaining: 3.16s\n",
      "272:\tlearn: 0.3639708\ttotal: 1.18s\tremaining: 3.15s\n",
      "273:\tlearn: 0.3631419\ttotal: 1.19s\tremaining: 3.15s\n",
      "274:\tlearn: 0.3628742\ttotal: 1.19s\tremaining: 3.14s\n",
      "275:\tlearn: 0.3623907\ttotal: 1.19s\tremaining: 3.13s\n",
      "276:\tlearn: 0.3620473\ttotal: 1.2s\tremaining: 3.13s\n",
      "277:\tlearn: 0.3616725\ttotal: 1.2s\tremaining: 3.12s\n",
      "278:\tlearn: 0.3613386\ttotal: 1.21s\tremaining: 3.11s\n",
      "279:\tlearn: 0.3612022\ttotal: 1.21s\tremaining: 3.11s\n",
      "280:\tlearn: 0.3609046\ttotal: 1.21s\tremaining: 3.11s\n",
      "281:\tlearn: 0.3605474\ttotal: 1.22s\tremaining: 3.1s\n",
      "282:\tlearn: 0.3600984\ttotal: 1.22s\tremaining: 3.1s\n",
      "283:\tlearn: 0.3598561\ttotal: 1.23s\tremaining: 3.09s\n",
      "284:\tlearn: 0.3594807\ttotal: 1.23s\tremaining: 3.09s\n",
      "285:\tlearn: 0.3591062\ttotal: 1.24s\tremaining: 3.08s\n",
      "286:\tlearn: 0.3585860\ttotal: 1.24s\tremaining: 3.08s\n",
      "287:\tlearn: 0.3580512\ttotal: 1.24s\tremaining: 3.07s\n",
      "288:\tlearn: 0.3577359\ttotal: 1.25s\tremaining: 3.07s\n",
      "289:\tlearn: 0.3575932\ttotal: 1.25s\tremaining: 3.06s\n",
      "290:\tlearn: 0.3573532\ttotal: 1.25s\tremaining: 3.06s\n",
      "291:\tlearn: 0.3569323\ttotal: 1.26s\tremaining: 3.05s\n",
      "292:\tlearn: 0.3565307\ttotal: 1.26s\tremaining: 3.05s\n",
      "293:\tlearn: 0.3561744\ttotal: 1.27s\tremaining: 3.04s\n",
      "294:\tlearn: 0.3559377\ttotal: 1.27s\tremaining: 3.04s\n",
      "295:\tlearn: 0.3554295\ttotal: 1.27s\tremaining: 3.03s\n",
      "296:\tlearn: 0.3551685\ttotal: 1.28s\tremaining: 3.02s\n",
      "297:\tlearn: 0.3547410\ttotal: 1.28s\tremaining: 3.02s\n",
      "298:\tlearn: 0.3544338\ttotal: 1.29s\tremaining: 3.02s\n",
      "299:\tlearn: 0.3539701\ttotal: 1.29s\tremaining: 3.01s\n",
      "300:\tlearn: 0.3536275\ttotal: 1.29s\tremaining: 3s\n",
      "301:\tlearn: 0.3533737\ttotal: 1.3s\tremaining: 3s\n",
      "302:\tlearn: 0.3531009\ttotal: 1.3s\tremaining: 2.99s\n",
      "303:\tlearn: 0.3527669\ttotal: 1.3s\tremaining: 2.98s\n",
      "304:\tlearn: 0.3524888\ttotal: 1.3s\tremaining: 2.98s\n",
      "305:\tlearn: 0.3521824\ttotal: 1.31s\tremaining: 2.97s\n",
      "306:\tlearn: 0.3518806\ttotal: 1.31s\tremaining: 2.96s\n",
      "307:\tlearn: 0.3514240\ttotal: 1.32s\tremaining: 2.96s\n",
      "308:\tlearn: 0.3510056\ttotal: 1.32s\tremaining: 2.95s\n",
      "309:\tlearn: 0.3507766\ttotal: 1.32s\tremaining: 2.94s\n",
      "310:\tlearn: 0.3505821\ttotal: 1.33s\tremaining: 2.94s\n",
      "311:\tlearn: 0.3502135\ttotal: 1.33s\tremaining: 2.93s\n",
      "312:\tlearn: 0.3499608\ttotal: 1.33s\tremaining: 2.92s\n",
      "313:\tlearn: 0.3497382\ttotal: 1.33s\tremaining: 2.92s\n",
      "314:\tlearn: 0.3493827\ttotal: 1.34s\tremaining: 2.91s\n",
      "315:\tlearn: 0.3490218\ttotal: 1.34s\tremaining: 2.9s\n",
      "316:\tlearn: 0.3487542\ttotal: 1.34s\tremaining: 2.9s\n",
      "317:\tlearn: 0.3482480\ttotal: 1.35s\tremaining: 2.9s\n",
      "318:\tlearn: 0.3479680\ttotal: 1.35s\tremaining: 2.89s\n",
      "319:\tlearn: 0.3477628\ttotal: 1.36s\tremaining: 2.88s\n",
      "320:\tlearn: 0.3474626\ttotal: 1.36s\tremaining: 2.88s\n",
      "321:\tlearn: 0.3470728\ttotal: 1.36s\tremaining: 2.87s\n",
      "322:\tlearn: 0.3469215\ttotal: 1.37s\tremaining: 2.87s\n",
      "323:\tlearn: 0.3466608\ttotal: 1.37s\tremaining: 2.86s\n",
      "324:\tlearn: 0.3464185\ttotal: 1.38s\tremaining: 2.86s\n",
      "325:\tlearn: 0.3460148\ttotal: 1.38s\tremaining: 2.85s\n",
      "326:\tlearn: 0.3457302\ttotal: 1.38s\tremaining: 2.85s\n",
      "327:\tlearn: 0.3453374\ttotal: 1.39s\tremaining: 2.84s\n",
      "328:\tlearn: 0.3448992\ttotal: 1.39s\tremaining: 2.83s\n",
      "329:\tlearn: 0.3446431\ttotal: 1.39s\tremaining: 2.83s\n",
      "330:\tlearn: 0.3443652\ttotal: 1.4s\tremaining: 2.82s\n",
      "331:\tlearn: 0.3440109\ttotal: 1.4s\tremaining: 2.82s\n",
      "332:\tlearn: 0.3436886\ttotal: 1.41s\tremaining: 2.82s\n",
      "333:\tlearn: 0.3434134\ttotal: 1.41s\tremaining: 2.81s\n",
      "334:\tlearn: 0.3431160\ttotal: 1.41s\tremaining: 2.81s\n",
      "335:\tlearn: 0.3425791\ttotal: 1.42s\tremaining: 2.8s\n",
      "336:\tlearn: 0.3422077\ttotal: 1.42s\tremaining: 2.8s\n",
      "337:\tlearn: 0.3417247\ttotal: 1.43s\tremaining: 2.79s\n",
      "338:\tlearn: 0.3415543\ttotal: 1.43s\tremaining: 2.79s\n",
      "339:\tlearn: 0.3412778\ttotal: 1.44s\tremaining: 2.79s\n",
      "340:\tlearn: 0.3410635\ttotal: 1.44s\tremaining: 2.78s\n",
      "341:\tlearn: 0.3407431\ttotal: 1.44s\tremaining: 2.78s\n",
      "342:\tlearn: 0.3403147\ttotal: 1.45s\tremaining: 2.77s\n",
      "343:\tlearn: 0.3399865\ttotal: 1.45s\tremaining: 2.77s\n",
      "344:\tlearn: 0.3394820\ttotal: 1.46s\tremaining: 2.76s\n",
      "345:\tlearn: 0.3392283\ttotal: 1.46s\tremaining: 2.76s\n",
      "346:\tlearn: 0.3388403\ttotal: 1.47s\tremaining: 2.76s\n",
      "347:\tlearn: 0.3385051\ttotal: 1.47s\tremaining: 2.76s\n",
      "348:\tlearn: 0.3382753\ttotal: 1.48s\tremaining: 2.75s\n",
      "349:\tlearn: 0.3380422\ttotal: 1.48s\tremaining: 2.75s\n",
      "350:\tlearn: 0.3377786\ttotal: 1.49s\tremaining: 2.75s\n",
      "351:\tlearn: 0.3374629\ttotal: 1.49s\tremaining: 2.75s\n",
      "352:\tlearn: 0.3371860\ttotal: 1.5s\tremaining: 2.74s\n",
      "353:\tlearn: 0.3369964\ttotal: 1.5s\tremaining: 2.74s\n",
      "354:\tlearn: 0.3367112\ttotal: 1.51s\tremaining: 2.74s\n",
      "355:\tlearn: 0.3365888\ttotal: 1.51s\tremaining: 2.73s\n",
      "356:\tlearn: 0.3364466\ttotal: 1.51s\tremaining: 2.73s\n",
      "357:\tlearn: 0.3363649\ttotal: 1.52s\tremaining: 2.72s\n",
      "358:\tlearn: 0.3358459\ttotal: 1.52s\tremaining: 2.72s\n",
      "359:\tlearn: 0.3353481\ttotal: 1.53s\tremaining: 2.71s\n",
      "360:\tlearn: 0.3350098\ttotal: 1.53s\tremaining: 2.71s\n",
      "361:\tlearn: 0.3346386\ttotal: 1.53s\tremaining: 2.71s\n",
      "362:\tlearn: 0.3342878\ttotal: 1.54s\tremaining: 2.7s\n",
      "363:\tlearn: 0.3340057\ttotal: 1.54s\tremaining: 2.7s\n",
      "364:\tlearn: 0.3336796\ttotal: 1.55s\tremaining: 2.69s\n",
      "365:\tlearn: 0.3333646\ttotal: 1.55s\tremaining: 2.69s\n",
      "366:\tlearn: 0.3330395\ttotal: 1.56s\tremaining: 2.69s\n",
      "367:\tlearn: 0.3324175\ttotal: 1.57s\tremaining: 2.69s\n",
      "368:\tlearn: 0.3321797\ttotal: 1.57s\tremaining: 2.69s\n",
      "369:\tlearn: 0.3318538\ttotal: 1.57s\tremaining: 2.68s\n",
      "370:\tlearn: 0.3316696\ttotal: 1.58s\tremaining: 2.68s\n",
      "371:\tlearn: 0.3313000\ttotal: 1.58s\tremaining: 2.67s\n",
      "372:\tlearn: 0.3308738\ttotal: 1.59s\tremaining: 2.67s\n",
      "373:\tlearn: 0.3306328\ttotal: 1.59s\tremaining: 2.67s\n",
      "374:\tlearn: 0.3301538\ttotal: 1.6s\tremaining: 2.66s\n",
      "375:\tlearn: 0.3299186\ttotal: 1.6s\tremaining: 2.66s\n",
      "376:\tlearn: 0.3295357\ttotal: 1.61s\tremaining: 2.66s\n",
      "377:\tlearn: 0.3294587\ttotal: 1.61s\tremaining: 2.65s\n",
      "378:\tlearn: 0.3291220\ttotal: 1.62s\tremaining: 2.65s\n",
      "379:\tlearn: 0.3289312\ttotal: 1.62s\tremaining: 2.64s\n",
      "380:\tlearn: 0.3286907\ttotal: 1.62s\tremaining: 2.64s\n",
      "381:\tlearn: 0.3282064\ttotal: 1.63s\tremaining: 2.63s\n",
      "382:\tlearn: 0.3278113\ttotal: 1.63s\tremaining: 2.63s\n",
      "383:\tlearn: 0.3275219\ttotal: 1.63s\tremaining: 2.62s\n",
      "384:\tlearn: 0.3272107\ttotal: 1.64s\tremaining: 2.61s\n",
      "385:\tlearn: 0.3269723\ttotal: 1.64s\tremaining: 2.61s\n",
      "386:\tlearn: 0.3265135\ttotal: 1.65s\tremaining: 2.61s\n",
      "387:\tlearn: 0.3261763\ttotal: 1.65s\tremaining: 2.6s\n",
      "388:\tlearn: 0.3259566\ttotal: 1.65s\tremaining: 2.6s\n",
      "389:\tlearn: 0.3256053\ttotal: 1.66s\tremaining: 2.59s\n",
      "390:\tlearn: 0.3254097\ttotal: 1.66s\tremaining: 2.59s\n",
      "391:\tlearn: 0.3250780\ttotal: 1.67s\tremaining: 2.59s\n",
      "392:\tlearn: 0.3245374\ttotal: 1.67s\tremaining: 2.58s\n",
      "393:\tlearn: 0.3244047\ttotal: 1.67s\tremaining: 2.58s\n",
      "394:\tlearn: 0.3241838\ttotal: 1.68s\tremaining: 2.57s\n",
      "395:\tlearn: 0.3238757\ttotal: 1.68s\tremaining: 2.56s\n",
      "396:\tlearn: 0.3235388\ttotal: 1.68s\tremaining: 2.56s\n",
      "397:\tlearn: 0.3231423\ttotal: 1.69s\tremaining: 2.55s\n",
      "398:\tlearn: 0.3229335\ttotal: 1.69s\tremaining: 2.54s\n",
      "399:\tlearn: 0.3226077\ttotal: 1.69s\tremaining: 2.54s\n",
      "400:\tlearn: 0.3222357\ttotal: 1.7s\tremaining: 2.53s\n",
      "401:\tlearn: 0.3220122\ttotal: 1.7s\tremaining: 2.53s\n",
      "402:\tlearn: 0.3219237\ttotal: 1.7s\tremaining: 2.52s\n",
      "403:\tlearn: 0.3217410\ttotal: 1.71s\tremaining: 2.52s\n",
      "404:\tlearn: 0.3214635\ttotal: 1.71s\tremaining: 2.51s\n",
      "405:\tlearn: 0.3211757\ttotal: 1.71s\tremaining: 2.51s\n",
      "406:\tlearn: 0.3208935\ttotal: 1.72s\tremaining: 2.5s\n",
      "407:\tlearn: 0.3207118\ttotal: 1.72s\tremaining: 2.5s\n",
      "408:\tlearn: 0.3204778\ttotal: 1.73s\tremaining: 2.5s\n",
      "409:\tlearn: 0.3202017\ttotal: 1.73s\tremaining: 2.49s\n",
      "410:\tlearn: 0.3199053\ttotal: 1.74s\tremaining: 2.49s\n",
      "411:\tlearn: 0.3196375\ttotal: 1.74s\tremaining: 2.48s\n",
      "412:\tlearn: 0.3191974\ttotal: 1.74s\tremaining: 2.48s\n",
      "413:\tlearn: 0.3186910\ttotal: 1.75s\tremaining: 2.47s\n",
      "414:\tlearn: 0.3183050\ttotal: 1.75s\tremaining: 2.47s\n",
      "415:\tlearn: 0.3181102\ttotal: 1.76s\tremaining: 2.47s\n",
      "416:\tlearn: 0.3180254\ttotal: 1.76s\tremaining: 2.46s\n",
      "417:\tlearn: 0.3176843\ttotal: 1.77s\tremaining: 2.46s\n",
      "418:\tlearn: 0.3174147\ttotal: 1.77s\tremaining: 2.46s\n",
      "419:\tlearn: 0.3170945\ttotal: 1.78s\tremaining: 2.45s\n",
      "420:\tlearn: 0.3168760\ttotal: 1.78s\tremaining: 2.45s\n",
      "421:\tlearn: 0.3166949\ttotal: 1.78s\tremaining: 2.44s\n",
      "422:\tlearn: 0.3164222\ttotal: 1.79s\tremaining: 2.44s\n",
      "423:\tlearn: 0.3162462\ttotal: 1.79s\tremaining: 2.44s\n",
      "424:\tlearn: 0.3160731\ttotal: 1.8s\tremaining: 2.43s\n",
      "425:\tlearn: 0.3159006\ttotal: 1.8s\tremaining: 2.43s\n",
      "426:\tlearn: 0.3155786\ttotal: 1.8s\tremaining: 2.42s\n",
      "427:\tlearn: 0.3154530\ttotal: 1.81s\tremaining: 2.42s\n",
      "428:\tlearn: 0.3151548\ttotal: 1.81s\tremaining: 2.41s\n",
      "429:\tlearn: 0.3149705\ttotal: 1.81s\tremaining: 2.4s\n",
      "430:\tlearn: 0.3144768\ttotal: 1.82s\tremaining: 2.4s\n",
      "431:\tlearn: 0.3142905\ttotal: 1.82s\tremaining: 2.4s\n",
      "432:\tlearn: 0.3140732\ttotal: 1.83s\tremaining: 2.39s\n",
      "433:\tlearn: 0.3137257\ttotal: 1.83s\tremaining: 2.39s\n",
      "434:\tlearn: 0.3133887\ttotal: 1.84s\tremaining: 2.39s\n",
      "435:\tlearn: 0.3131041\ttotal: 1.84s\tremaining: 2.38s\n",
      "436:\tlearn: 0.3128339\ttotal: 1.85s\tremaining: 2.38s\n",
      "437:\tlearn: 0.3124740\ttotal: 1.85s\tremaining: 2.38s\n",
      "438:\tlearn: 0.3122589\ttotal: 1.86s\tremaining: 2.37s\n",
      "439:\tlearn: 0.3120100\ttotal: 1.86s\tremaining: 2.37s\n",
      "440:\tlearn: 0.3116897\ttotal: 1.87s\tremaining: 2.37s\n",
      "441:\tlearn: 0.3114179\ttotal: 1.87s\tremaining: 2.36s\n",
      "442:\tlearn: 0.3110733\ttotal: 1.87s\tremaining: 2.36s\n",
      "443:\tlearn: 0.3108204\ttotal: 1.88s\tremaining: 2.35s\n",
      "444:\tlearn: 0.3106657\ttotal: 1.88s\tremaining: 2.35s\n",
      "445:\tlearn: 0.3104465\ttotal: 1.89s\tremaining: 2.34s\n",
      "446:\tlearn: 0.3102562\ttotal: 1.89s\tremaining: 2.34s\n",
      "447:\tlearn: 0.3099061\ttotal: 1.89s\tremaining: 2.33s\n",
      "448:\tlearn: 0.3095081\ttotal: 1.9s\tremaining: 2.33s\n",
      "449:\tlearn: 0.3093382\ttotal: 1.91s\tremaining: 2.33s\n",
      "450:\tlearn: 0.3092328\ttotal: 1.91s\tremaining: 2.32s\n",
      "451:\tlearn: 0.3089322\ttotal: 1.91s\tremaining: 2.32s\n",
      "452:\tlearn: 0.3086720\ttotal: 1.92s\tremaining: 2.31s\n",
      "453:\tlearn: 0.3083362\ttotal: 1.92s\tremaining: 2.31s\n",
      "454:\tlearn: 0.3081028\ttotal: 1.92s\tremaining: 2.3s\n",
      "455:\tlearn: 0.3079860\ttotal: 1.93s\tremaining: 2.3s\n",
      "456:\tlearn: 0.3077197\ttotal: 1.93s\tremaining: 2.29s\n",
      "457:\tlearn: 0.3076043\ttotal: 1.93s\tremaining: 2.29s\n",
      "458:\tlearn: 0.3074212\ttotal: 1.94s\tremaining: 2.28s\n",
      "459:\tlearn: 0.3072879\ttotal: 1.94s\tremaining: 2.28s\n",
      "460:\tlearn: 0.3068893\ttotal: 1.95s\tremaining: 2.27s\n",
      "461:\tlearn: 0.3065018\ttotal: 1.95s\tremaining: 2.27s\n",
      "462:\tlearn: 0.3062968\ttotal: 1.95s\tremaining: 2.27s\n",
      "463:\tlearn: 0.3062072\ttotal: 1.96s\tremaining: 2.26s\n",
      "464:\tlearn: 0.3059277\ttotal: 1.96s\tremaining: 2.26s\n",
      "465:\tlearn: 0.3057230\ttotal: 1.97s\tremaining: 2.26s\n",
      "466:\tlearn: 0.3055604\ttotal: 1.97s\tremaining: 2.25s\n",
      "467:\tlearn: 0.3053769\ttotal: 1.98s\tremaining: 2.25s\n",
      "468:\tlearn: 0.3052505\ttotal: 1.98s\tremaining: 2.24s\n",
      "469:\tlearn: 0.3048979\ttotal: 1.99s\tremaining: 2.24s\n",
      "470:\tlearn: 0.3044979\ttotal: 1.99s\tremaining: 2.23s\n",
      "471:\tlearn: 0.3042380\ttotal: 1.99s\tremaining: 2.23s\n",
      "472:\tlearn: 0.3039383\ttotal: 2s\tremaining: 2.23s\n",
      "473:\tlearn: 0.3037351\ttotal: 2s\tremaining: 2.22s\n",
      "474:\tlearn: 0.3034588\ttotal: 2s\tremaining: 2.22s\n",
      "475:\tlearn: 0.3032029\ttotal: 2.01s\tremaining: 2.21s\n",
      "476:\tlearn: 0.3029685\ttotal: 2.01s\tremaining: 2.21s\n",
      "477:\tlearn: 0.3026713\ttotal: 2.02s\tremaining: 2.2s\n",
      "478:\tlearn: 0.3025163\ttotal: 2.02s\tremaining: 2.2s\n",
      "479:\tlearn: 0.3022972\ttotal: 2.02s\tremaining: 2.19s\n",
      "480:\tlearn: 0.3020348\ttotal: 2.03s\tremaining: 2.19s\n",
      "481:\tlearn: 0.3018121\ttotal: 2.03s\tremaining: 2.18s\n",
      "482:\tlearn: 0.3015988\ttotal: 2.04s\tremaining: 2.18s\n",
      "483:\tlearn: 0.3013443\ttotal: 2.04s\tremaining: 2.17s\n",
      "484:\tlearn: 0.3011286\ttotal: 2.04s\tremaining: 2.17s\n",
      "485:\tlearn: 0.3008706\ttotal: 2.04s\tremaining: 2.16s\n",
      "486:\tlearn: 0.3006424\ttotal: 2.05s\tremaining: 2.16s\n",
      "487:\tlearn: 0.3004241\ttotal: 2.05s\tremaining: 2.15s\n",
      "488:\tlearn: 0.2999521\ttotal: 2.06s\tremaining: 2.15s\n",
      "489:\tlearn: 0.2997687\ttotal: 2.06s\tremaining: 2.15s\n",
      "490:\tlearn: 0.2995491\ttotal: 2.06s\tremaining: 2.14s\n",
      "491:\tlearn: 0.2995010\ttotal: 2.07s\tremaining: 2.14s\n",
      "492:\tlearn: 0.2993298\ttotal: 2.07s\tremaining: 2.13s\n",
      "493:\tlearn: 0.2991960\ttotal: 2.08s\tremaining: 2.13s\n",
      "494:\tlearn: 0.2988913\ttotal: 2.08s\tremaining: 2.12s\n",
      "495:\tlearn: 0.2988421\ttotal: 2.09s\tremaining: 2.12s\n",
      "496:\tlearn: 0.2985398\ttotal: 2.09s\tremaining: 2.12s\n",
      "497:\tlearn: 0.2981075\ttotal: 2.09s\tremaining: 2.11s\n",
      "498:\tlearn: 0.2979078\ttotal: 2.1s\tremaining: 2.11s\n",
      "499:\tlearn: 0.2974203\ttotal: 2.1s\tremaining: 2.1s\n",
      "500:\tlearn: 0.2970690\ttotal: 2.1s\tremaining: 2.1s\n",
      "501:\tlearn: 0.2968446\ttotal: 2.11s\tremaining: 2.09s\n",
      "502:\tlearn: 0.2966248\ttotal: 2.11s\tremaining: 2.09s\n",
      "503:\tlearn: 0.2963980\ttotal: 2.12s\tremaining: 2.08s\n",
      "504:\tlearn: 0.2961572\ttotal: 2.12s\tremaining: 2.08s\n",
      "505:\tlearn: 0.2960557\ttotal: 2.12s\tremaining: 2.07s\n",
      "506:\tlearn: 0.2958230\ttotal: 2.13s\tremaining: 2.07s\n",
      "507:\tlearn: 0.2954525\ttotal: 2.13s\tremaining: 2.07s\n",
      "508:\tlearn: 0.2950937\ttotal: 2.14s\tremaining: 2.06s\n",
      "509:\tlearn: 0.2949307\ttotal: 2.14s\tremaining: 2.06s\n",
      "510:\tlearn: 0.2947958\ttotal: 2.15s\tremaining: 2.06s\n",
      "511:\tlearn: 0.2944630\ttotal: 2.15s\tremaining: 2.05s\n",
      "512:\tlearn: 0.2942679\ttotal: 2.16s\tremaining: 2.05s\n",
      "513:\tlearn: 0.2941402\ttotal: 2.16s\tremaining: 2.04s\n",
      "514:\tlearn: 0.2939235\ttotal: 2.17s\tremaining: 2.04s\n",
      "515:\tlearn: 0.2937761\ttotal: 2.17s\tremaining: 2.03s\n",
      "516:\tlearn: 0.2935286\ttotal: 2.17s\tremaining: 2.03s\n",
      "517:\tlearn: 0.2932771\ttotal: 2.18s\tremaining: 2.02s\n",
      "518:\tlearn: 0.2929864\ttotal: 2.18s\tremaining: 2.02s\n",
      "519:\tlearn: 0.2927364\ttotal: 2.19s\tremaining: 2.02s\n",
      "520:\tlearn: 0.2923799\ttotal: 2.19s\tremaining: 2.01s\n",
      "521:\tlearn: 0.2922016\ttotal: 2.19s\tremaining: 2.01s\n",
      "522:\tlearn: 0.2919902\ttotal: 2.2s\tremaining: 2s\n",
      "523:\tlearn: 0.2916210\ttotal: 2.2s\tremaining: 2s\n",
      "524:\tlearn: 0.2914312\ttotal: 2.21s\tremaining: 2s\n",
      "525:\tlearn: 0.2912985\ttotal: 2.21s\tremaining: 1.99s\n",
      "526:\tlearn: 0.2911404\ttotal: 2.21s\tremaining: 1.99s\n",
      "527:\tlearn: 0.2908264\ttotal: 2.22s\tremaining: 1.98s\n",
      "528:\tlearn: 0.2907144\ttotal: 2.22s\tremaining: 1.98s\n",
      "529:\tlearn: 0.2904410\ttotal: 2.23s\tremaining: 1.97s\n",
      "530:\tlearn: 0.2903091\ttotal: 2.23s\tremaining: 1.97s\n",
      "531:\tlearn: 0.2900599\ttotal: 2.23s\tremaining: 1.96s\n",
      "532:\tlearn: 0.2897608\ttotal: 2.24s\tremaining: 1.96s\n",
      "533:\tlearn: 0.2896396\ttotal: 2.24s\tremaining: 1.96s\n",
      "534:\tlearn: 0.2894265\ttotal: 2.25s\tremaining: 1.95s\n",
      "535:\tlearn: 0.2892680\ttotal: 2.25s\tremaining: 1.95s\n",
      "536:\tlearn: 0.2889540\ttotal: 2.26s\tremaining: 1.95s\n",
      "537:\tlearn: 0.2887113\ttotal: 2.26s\tremaining: 1.94s\n",
      "538:\tlearn: 0.2885413\ttotal: 2.27s\tremaining: 1.94s\n",
      "539:\tlearn: 0.2882990\ttotal: 2.27s\tremaining: 1.94s\n",
      "540:\tlearn: 0.2879806\ttotal: 2.28s\tremaining: 1.93s\n",
      "541:\tlearn: 0.2878841\ttotal: 2.28s\tremaining: 1.93s\n",
      "542:\tlearn: 0.2876698\ttotal: 2.29s\tremaining: 1.92s\n",
      "543:\tlearn: 0.2875311\ttotal: 2.29s\tremaining: 1.92s\n",
      "544:\tlearn: 0.2873574\ttotal: 2.29s\tremaining: 1.92s\n",
      "545:\tlearn: 0.2868368\ttotal: 2.3s\tremaining: 1.91s\n",
      "546:\tlearn: 0.2867057\ttotal: 2.3s\tremaining: 1.91s\n",
      "547:\tlearn: 0.2865085\ttotal: 2.31s\tremaining: 1.9s\n",
      "548:\tlearn: 0.2860525\ttotal: 2.31s\tremaining: 1.9s\n",
      "549:\tlearn: 0.2858592\ttotal: 2.31s\tremaining: 1.89s\n",
      "550:\tlearn: 0.2856427\ttotal: 2.32s\tremaining: 1.89s\n",
      "551:\tlearn: 0.2854115\ttotal: 2.32s\tremaining: 1.89s\n",
      "552:\tlearn: 0.2851348\ttotal: 2.33s\tremaining: 1.88s\n",
      "553:\tlearn: 0.2849871\ttotal: 2.33s\tremaining: 1.88s\n",
      "554:\tlearn: 0.2846397\ttotal: 2.33s\tremaining: 1.87s\n",
      "555:\tlearn: 0.2843977\ttotal: 2.34s\tremaining: 1.87s\n",
      "556:\tlearn: 0.2842746\ttotal: 2.34s\tremaining: 1.86s\n",
      "557:\tlearn: 0.2840526\ttotal: 2.34s\tremaining: 1.86s\n",
      "558:\tlearn: 0.2839473\ttotal: 2.35s\tremaining: 1.85s\n",
      "559:\tlearn: 0.2837242\ttotal: 2.35s\tremaining: 1.85s\n",
      "560:\tlearn: 0.2835284\ttotal: 2.35s\tremaining: 1.84s\n",
      "561:\tlearn: 0.2831412\ttotal: 2.36s\tremaining: 1.84s\n",
      "562:\tlearn: 0.2829436\ttotal: 2.36s\tremaining: 1.83s\n",
      "563:\tlearn: 0.2826168\ttotal: 2.36s\tremaining: 1.83s\n",
      "564:\tlearn: 0.2823293\ttotal: 2.37s\tremaining: 1.82s\n",
      "565:\tlearn: 0.2821834\ttotal: 2.37s\tremaining: 1.82s\n",
      "566:\tlearn: 0.2819841\ttotal: 2.37s\tremaining: 1.81s\n",
      "567:\tlearn: 0.2818550\ttotal: 2.38s\tremaining: 1.81s\n",
      "568:\tlearn: 0.2814545\ttotal: 2.38s\tremaining: 1.8s\n",
      "569:\tlearn: 0.2811864\ttotal: 2.38s\tremaining: 1.8s\n",
      "570:\tlearn: 0.2809367\ttotal: 2.39s\tremaining: 1.79s\n",
      "571:\tlearn: 0.2806963\ttotal: 2.39s\tremaining: 1.79s\n",
      "572:\tlearn: 0.2804700\ttotal: 2.39s\tremaining: 1.78s\n",
      "573:\tlearn: 0.2802912\ttotal: 2.4s\tremaining: 1.78s\n",
      "574:\tlearn: 0.2799496\ttotal: 2.4s\tremaining: 1.77s\n",
      "575:\tlearn: 0.2795946\ttotal: 2.4s\tremaining: 1.77s\n",
      "576:\tlearn: 0.2793203\ttotal: 2.41s\tremaining: 1.76s\n",
      "577:\tlearn: 0.2792004\ttotal: 2.41s\tremaining: 1.76s\n",
      "578:\tlearn: 0.2790009\ttotal: 2.42s\tremaining: 1.76s\n",
      "579:\tlearn: 0.2788771\ttotal: 2.42s\tremaining: 1.75s\n",
      "580:\tlearn: 0.2787176\ttotal: 2.42s\tremaining: 1.75s\n",
      "581:\tlearn: 0.2786036\ttotal: 2.43s\tremaining: 1.74s\n",
      "582:\tlearn: 0.2784394\ttotal: 2.43s\tremaining: 1.74s\n",
      "583:\tlearn: 0.2779199\ttotal: 2.44s\tremaining: 1.73s\n",
      "584:\tlearn: 0.2776802\ttotal: 2.44s\tremaining: 1.73s\n",
      "585:\tlearn: 0.2774198\ttotal: 2.44s\tremaining: 1.72s\n",
      "586:\tlearn: 0.2772951\ttotal: 2.44s\tremaining: 1.72s\n",
      "587:\tlearn: 0.2771427\ttotal: 2.45s\tremaining: 1.72s\n",
      "588:\tlearn: 0.2769517\ttotal: 2.45s\tremaining: 1.71s\n",
      "589:\tlearn: 0.2767215\ttotal: 2.46s\tremaining: 1.71s\n",
      "590:\tlearn: 0.2764944\ttotal: 2.46s\tremaining: 1.7s\n",
      "591:\tlearn: 0.2762599\ttotal: 2.46s\tremaining: 1.7s\n",
      "592:\tlearn: 0.2759473\ttotal: 2.47s\tremaining: 1.69s\n",
      "593:\tlearn: 0.2756793\ttotal: 2.47s\tremaining: 1.69s\n",
      "594:\tlearn: 0.2755530\ttotal: 2.47s\tremaining: 1.68s\n",
      "595:\tlearn: 0.2752937\ttotal: 2.48s\tremaining: 1.68s\n",
      "596:\tlearn: 0.2750013\ttotal: 2.48s\tremaining: 1.67s\n",
      "597:\tlearn: 0.2748888\ttotal: 2.48s\tremaining: 1.67s\n",
      "598:\tlearn: 0.2747631\ttotal: 2.49s\tremaining: 1.67s\n",
      "599:\tlearn: 0.2744910\ttotal: 2.49s\tremaining: 1.66s\n",
      "600:\tlearn: 0.2743274\ttotal: 2.5s\tremaining: 1.66s\n",
      "601:\tlearn: 0.2741434\ttotal: 2.5s\tremaining: 1.65s\n",
      "602:\tlearn: 0.2738370\ttotal: 2.5s\tremaining: 1.65s\n",
      "603:\tlearn: 0.2735253\ttotal: 2.51s\tremaining: 1.64s\n",
      "604:\tlearn: 0.2733289\ttotal: 2.51s\tremaining: 1.64s\n",
      "605:\tlearn: 0.2731170\ttotal: 2.51s\tremaining: 1.63s\n",
      "606:\tlearn: 0.2728888\ttotal: 2.52s\tremaining: 1.63s\n",
      "607:\tlearn: 0.2726579\ttotal: 2.52s\tremaining: 1.63s\n",
      "608:\tlearn: 0.2724114\ttotal: 2.52s\tremaining: 1.62s\n",
      "609:\tlearn: 0.2722314\ttotal: 2.53s\tremaining: 1.62s\n",
      "610:\tlearn: 0.2719778\ttotal: 2.53s\tremaining: 1.61s\n",
      "611:\tlearn: 0.2717553\ttotal: 2.53s\tremaining: 1.61s\n",
      "612:\tlearn: 0.2716201\ttotal: 2.54s\tremaining: 1.6s\n",
      "613:\tlearn: 0.2713470\ttotal: 2.54s\tremaining: 1.6s\n",
      "614:\tlearn: 0.2710979\ttotal: 2.54s\tremaining: 1.59s\n",
      "615:\tlearn: 0.2708985\ttotal: 2.55s\tremaining: 1.59s\n",
      "616:\tlearn: 0.2707586\ttotal: 2.55s\tremaining: 1.58s\n",
      "617:\tlearn: 0.2705570\ttotal: 2.55s\tremaining: 1.58s\n",
      "618:\tlearn: 0.2702028\ttotal: 2.56s\tremaining: 1.57s\n",
      "619:\tlearn: 0.2700131\ttotal: 2.56s\tremaining: 1.57s\n",
      "620:\tlearn: 0.2699062\ttotal: 2.56s\tremaining: 1.56s\n",
      "621:\tlearn: 0.2697685\ttotal: 2.57s\tremaining: 1.56s\n",
      "622:\tlearn: 0.2695962\ttotal: 2.57s\tremaining: 1.55s\n",
      "623:\tlearn: 0.2694138\ttotal: 2.57s\tremaining: 1.55s\n",
      "624:\tlearn: 0.2692486\ttotal: 2.58s\tremaining: 1.55s\n",
      "625:\tlearn: 0.2689249\ttotal: 2.58s\tremaining: 1.54s\n",
      "626:\tlearn: 0.2686805\ttotal: 2.58s\tremaining: 1.54s\n",
      "627:\tlearn: 0.2684390\ttotal: 2.59s\tremaining: 1.53s\n",
      "628:\tlearn: 0.2681603\ttotal: 2.59s\tremaining: 1.53s\n",
      "629:\tlearn: 0.2678035\ttotal: 2.59s\tremaining: 1.52s\n",
      "630:\tlearn: 0.2676993\ttotal: 2.6s\tremaining: 1.52s\n",
      "631:\tlearn: 0.2673989\ttotal: 2.6s\tremaining: 1.51s\n",
      "632:\tlearn: 0.2670374\ttotal: 2.6s\tremaining: 1.51s\n",
      "633:\tlearn: 0.2666560\ttotal: 2.61s\tremaining: 1.5s\n",
      "634:\tlearn: 0.2665019\ttotal: 2.61s\tremaining: 1.5s\n",
      "635:\tlearn: 0.2663275\ttotal: 2.61s\tremaining: 1.5s\n",
      "636:\tlearn: 0.2661822\ttotal: 2.62s\tremaining: 1.49s\n",
      "637:\tlearn: 0.2660234\ttotal: 2.62s\tremaining: 1.49s\n",
      "638:\tlearn: 0.2657987\ttotal: 2.62s\tremaining: 1.48s\n",
      "639:\tlearn: 0.2657011\ttotal: 2.63s\tremaining: 1.48s\n",
      "640:\tlearn: 0.2656032\ttotal: 2.63s\tremaining: 1.47s\n",
      "641:\tlearn: 0.2654605\ttotal: 2.63s\tremaining: 1.47s\n",
      "642:\tlearn: 0.2651257\ttotal: 2.63s\tremaining: 1.46s\n",
      "643:\tlearn: 0.2649106\ttotal: 2.64s\tremaining: 1.46s\n",
      "644:\tlearn: 0.2647637\ttotal: 2.64s\tremaining: 1.45s\n",
      "645:\tlearn: 0.2646258\ttotal: 2.64s\tremaining: 1.45s\n",
      "646:\tlearn: 0.2643263\ttotal: 2.65s\tremaining: 1.44s\n",
      "647:\tlearn: 0.2641239\ttotal: 2.65s\tremaining: 1.44s\n",
      "648:\tlearn: 0.2639378\ttotal: 2.65s\tremaining: 1.43s\n",
      "649:\tlearn: 0.2637633\ttotal: 2.65s\tremaining: 1.43s\n",
      "650:\tlearn: 0.2636283\ttotal: 2.66s\tremaining: 1.43s\n",
      "651:\tlearn: 0.2635208\ttotal: 2.66s\tremaining: 1.42s\n",
      "652:\tlearn: 0.2633647\ttotal: 2.66s\tremaining: 1.42s\n",
      "653:\tlearn: 0.2631496\ttotal: 2.67s\tremaining: 1.41s\n",
      "654:\tlearn: 0.2630451\ttotal: 2.67s\tremaining: 1.41s\n",
      "655:\tlearn: 0.2629246\ttotal: 2.67s\tremaining: 1.4s\n",
      "656:\tlearn: 0.2628067\ttotal: 2.68s\tremaining: 1.4s\n",
      "657:\tlearn: 0.2626244\ttotal: 2.68s\tremaining: 1.39s\n",
      "658:\tlearn: 0.2624764\ttotal: 2.68s\tremaining: 1.39s\n",
      "659:\tlearn: 0.2623092\ttotal: 2.69s\tremaining: 1.38s\n",
      "660:\tlearn: 0.2620845\ttotal: 2.69s\tremaining: 1.38s\n",
      "661:\tlearn: 0.2619253\ttotal: 2.69s\tremaining: 1.37s\n",
      "662:\tlearn: 0.2617608\ttotal: 2.69s\tremaining: 1.37s\n",
      "663:\tlearn: 0.2614240\ttotal: 2.7s\tremaining: 1.36s\n",
      "664:\tlearn: 0.2612769\ttotal: 2.7s\tremaining: 1.36s\n",
      "665:\tlearn: 0.2610788\ttotal: 2.7s\tremaining: 1.36s\n",
      "666:\tlearn: 0.2609045\ttotal: 2.71s\tremaining: 1.35s\n",
      "667:\tlearn: 0.2607615\ttotal: 2.71s\tremaining: 1.35s\n",
      "668:\tlearn: 0.2605143\ttotal: 2.71s\tremaining: 1.34s\n",
      "669:\tlearn: 0.2603812\ttotal: 2.72s\tremaining: 1.34s\n",
      "670:\tlearn: 0.2601980\ttotal: 2.72s\tremaining: 1.33s\n",
      "671:\tlearn: 0.2601900\ttotal: 2.72s\tremaining: 1.33s\n",
      "672:\tlearn: 0.2600302\ttotal: 2.73s\tremaining: 1.32s\n",
      "673:\tlearn: 0.2597810\ttotal: 2.73s\tremaining: 1.32s\n",
      "674:\tlearn: 0.2596304\ttotal: 2.73s\tremaining: 1.31s\n",
      "675:\tlearn: 0.2594992\ttotal: 2.73s\tremaining: 1.31s\n",
      "676:\tlearn: 0.2592487\ttotal: 2.74s\tremaining: 1.31s\n",
      "677:\tlearn: 0.2591513\ttotal: 2.74s\tremaining: 1.3s\n",
      "678:\tlearn: 0.2589734\ttotal: 2.75s\tremaining: 1.3s\n",
      "679:\tlearn: 0.2587593\ttotal: 2.75s\tremaining: 1.29s\n",
      "680:\tlearn: 0.2585634\ttotal: 2.75s\tremaining: 1.29s\n",
      "681:\tlearn: 0.2583017\ttotal: 2.76s\tremaining: 1.28s\n",
      "682:\tlearn: 0.2580762\ttotal: 2.76s\tremaining: 1.28s\n",
      "683:\tlearn: 0.2579349\ttotal: 2.77s\tremaining: 1.28s\n",
      "684:\tlearn: 0.2577218\ttotal: 2.77s\tremaining: 1.27s\n",
      "685:\tlearn: 0.2575654\ttotal: 2.77s\tremaining: 1.27s\n",
      "686:\tlearn: 0.2574274\ttotal: 2.78s\tremaining: 1.26s\n",
      "687:\tlearn: 0.2572896\ttotal: 2.78s\tremaining: 1.26s\n",
      "688:\tlearn: 0.2571511\ttotal: 2.79s\tremaining: 1.26s\n",
      "689:\tlearn: 0.2570243\ttotal: 2.79s\tremaining: 1.25s\n",
      "690:\tlearn: 0.2568537\ttotal: 2.79s\tremaining: 1.25s\n",
      "691:\tlearn: 0.2565121\ttotal: 2.8s\tremaining: 1.25s\n",
      "692:\tlearn: 0.2563758\ttotal: 2.8s\tremaining: 1.24s\n",
      "693:\tlearn: 0.2562872\ttotal: 2.81s\tremaining: 1.24s\n",
      "694:\tlearn: 0.2561368\ttotal: 2.81s\tremaining: 1.23s\n",
      "695:\tlearn: 0.2558316\ttotal: 2.81s\tremaining: 1.23s\n",
      "696:\tlearn: 0.2556258\ttotal: 2.82s\tremaining: 1.23s\n",
      "697:\tlearn: 0.2555027\ttotal: 2.82s\tremaining: 1.22s\n",
      "698:\tlearn: 0.2553256\ttotal: 2.83s\tremaining: 1.22s\n",
      "699:\tlearn: 0.2550661\ttotal: 2.83s\tremaining: 1.21s\n",
      "700:\tlearn: 0.2549541\ttotal: 2.83s\tremaining: 1.21s\n",
      "701:\tlearn: 0.2546101\ttotal: 2.84s\tremaining: 1.21s\n",
      "702:\tlearn: 0.2544714\ttotal: 2.85s\tremaining: 1.2s\n",
      "703:\tlearn: 0.2543671\ttotal: 2.85s\tremaining: 1.2s\n",
      "704:\tlearn: 0.2540798\ttotal: 2.85s\tremaining: 1.19s\n",
      "705:\tlearn: 0.2538127\ttotal: 2.86s\tremaining: 1.19s\n",
      "706:\tlearn: 0.2536337\ttotal: 2.86s\tremaining: 1.19s\n",
      "707:\tlearn: 0.2534568\ttotal: 2.86s\tremaining: 1.18s\n",
      "708:\tlearn: 0.2532373\ttotal: 2.87s\tremaining: 1.18s\n",
      "709:\tlearn: 0.2529170\ttotal: 2.87s\tremaining: 1.17s\n",
      "710:\tlearn: 0.2527737\ttotal: 2.87s\tremaining: 1.17s\n",
      "711:\tlearn: 0.2524652\ttotal: 2.88s\tremaining: 1.16s\n",
      "712:\tlearn: 0.2521364\ttotal: 2.88s\tremaining: 1.16s\n",
      "713:\tlearn: 0.2518888\ttotal: 2.89s\tremaining: 1.16s\n",
      "714:\tlearn: 0.2516953\ttotal: 2.89s\tremaining: 1.15s\n",
      "715:\tlearn: 0.2514797\ttotal: 2.89s\tremaining: 1.15s\n",
      "716:\tlearn: 0.2513053\ttotal: 2.9s\tremaining: 1.14s\n",
      "717:\tlearn: 0.2511645\ttotal: 2.9s\tremaining: 1.14s\n",
      "718:\tlearn: 0.2509003\ttotal: 2.9s\tremaining: 1.14s\n",
      "719:\tlearn: 0.2507846\ttotal: 2.91s\tremaining: 1.13s\n",
      "720:\tlearn: 0.2505643\ttotal: 2.91s\tremaining: 1.13s\n",
      "721:\tlearn: 0.2503008\ttotal: 2.92s\tremaining: 1.12s\n",
      "722:\tlearn: 0.2498884\ttotal: 2.92s\tremaining: 1.12s\n",
      "723:\tlearn: 0.2495797\ttotal: 2.92s\tremaining: 1.11s\n",
      "724:\tlearn: 0.2493788\ttotal: 2.93s\tremaining: 1.11s\n",
      "725:\tlearn: 0.2492290\ttotal: 2.93s\tremaining: 1.11s\n",
      "726:\tlearn: 0.2490422\ttotal: 2.94s\tremaining: 1.1s\n",
      "727:\tlearn: 0.2489390\ttotal: 2.94s\tremaining: 1.1s\n",
      "728:\tlearn: 0.2488069\ttotal: 2.95s\tremaining: 1.1s\n",
      "729:\tlearn: 0.2485813\ttotal: 2.95s\tremaining: 1.09s\n",
      "730:\tlearn: 0.2483795\ttotal: 2.96s\tremaining: 1.09s\n",
      "731:\tlearn: 0.2482315\ttotal: 2.96s\tremaining: 1.08s\n",
      "732:\tlearn: 0.2479647\ttotal: 2.97s\tremaining: 1.08s\n",
      "733:\tlearn: 0.2477586\ttotal: 2.97s\tremaining: 1.08s\n",
      "734:\tlearn: 0.2475858\ttotal: 2.98s\tremaining: 1.07s\n",
      "735:\tlearn: 0.2474270\ttotal: 2.98s\tremaining: 1.07s\n",
      "736:\tlearn: 0.2473290\ttotal: 2.98s\tremaining: 1.06s\n",
      "737:\tlearn: 0.2471910\ttotal: 2.99s\tremaining: 1.06s\n",
      "738:\tlearn: 0.2470639\ttotal: 2.99s\tremaining: 1.06s\n",
      "739:\tlearn: 0.2466921\ttotal: 3s\tremaining: 1.05s\n",
      "740:\tlearn: 0.2463936\ttotal: 3s\tremaining: 1.05s\n",
      "741:\tlearn: 0.2462100\ttotal: 3.01s\tremaining: 1.04s\n",
      "742:\tlearn: 0.2460661\ttotal: 3.01s\tremaining: 1.04s\n",
      "743:\tlearn: 0.2459705\ttotal: 3.01s\tremaining: 1.04s\n",
      "744:\tlearn: 0.2456404\ttotal: 3.02s\tremaining: 1.03s\n",
      "745:\tlearn: 0.2453988\ttotal: 3.02s\tremaining: 1.03s\n",
      "746:\tlearn: 0.2453214\ttotal: 3.03s\tremaining: 1.02s\n",
      "747:\tlearn: 0.2451421\ttotal: 3.03s\tremaining: 1.02s\n",
      "748:\tlearn: 0.2450704\ttotal: 3.04s\tremaining: 1.02s\n",
      "749:\tlearn: 0.2446311\ttotal: 3.04s\tremaining: 1.01s\n",
      "750:\tlearn: 0.2444758\ttotal: 3.05s\tremaining: 1.01s\n",
      "751:\tlearn: 0.2443453\ttotal: 3.05s\tremaining: 1.01s\n",
      "752:\tlearn: 0.2441531\ttotal: 3.05s\tremaining: 1s\n",
      "753:\tlearn: 0.2440097\ttotal: 3.06s\tremaining: 998ms\n",
      "754:\tlearn: 0.2437095\ttotal: 3.06s\tremaining: 994ms\n",
      "755:\tlearn: 0.2435671\ttotal: 3.06s\tremaining: 989ms\n",
      "756:\tlearn: 0.2434517\ttotal: 3.07s\tremaining: 985ms\n",
      "757:\tlearn: 0.2433125\ttotal: 3.07s\tremaining: 981ms\n",
      "758:\tlearn: 0.2430768\ttotal: 3.08s\tremaining: 977ms\n",
      "759:\tlearn: 0.2430185\ttotal: 3.08s\tremaining: 972ms\n",
      "760:\tlearn: 0.2427720\ttotal: 3.08s\tremaining: 968ms\n",
      "761:\tlearn: 0.2425824\ttotal: 3.08s\tremaining: 964ms\n",
      "762:\tlearn: 0.2424442\ttotal: 3.09s\tremaining: 959ms\n",
      "763:\tlearn: 0.2422624\ttotal: 3.09s\tremaining: 955ms\n",
      "764:\tlearn: 0.2420646\ttotal: 3.1s\tremaining: 951ms\n",
      "765:\tlearn: 0.2417760\ttotal: 3.1s\tremaining: 946ms\n",
      "766:\tlearn: 0.2416349\ttotal: 3.1s\tremaining: 942ms\n",
      "767:\tlearn: 0.2414353\ttotal: 3.1s\tremaining: 938ms\n",
      "768:\tlearn: 0.2412118\ttotal: 3.11s\tremaining: 934ms\n",
      "769:\tlearn: 0.2410831\ttotal: 3.11s\tremaining: 930ms\n",
      "770:\tlearn: 0.2408914\ttotal: 3.12s\tremaining: 925ms\n",
      "771:\tlearn: 0.2407374\ttotal: 3.12s\tremaining: 921ms\n",
      "772:\tlearn: 0.2406380\ttotal: 3.12s\tremaining: 917ms\n",
      "773:\tlearn: 0.2405036\ttotal: 3.13s\tremaining: 913ms\n",
      "774:\tlearn: 0.2403485\ttotal: 3.13s\tremaining: 909ms\n",
      "775:\tlearn: 0.2402093\ttotal: 3.13s\tremaining: 905ms\n",
      "776:\tlearn: 0.2400854\ttotal: 3.14s\tremaining: 901ms\n",
      "777:\tlearn: 0.2398966\ttotal: 3.14s\tremaining: 896ms\n",
      "778:\tlearn: 0.2395745\ttotal: 3.15s\tremaining: 892ms\n",
      "779:\tlearn: 0.2393650\ttotal: 3.15s\tremaining: 888ms\n",
      "780:\tlearn: 0.2392259\ttotal: 3.15s\tremaining: 884ms\n",
      "781:\tlearn: 0.2390109\ttotal: 3.15s\tremaining: 880ms\n",
      "782:\tlearn: 0.2388979\ttotal: 3.16s\tremaining: 875ms\n",
      "783:\tlearn: 0.2388026\ttotal: 3.16s\tremaining: 871ms\n",
      "784:\tlearn: 0.2385425\ttotal: 3.17s\tremaining: 867ms\n",
      "785:\tlearn: 0.2383090\ttotal: 3.17s\tremaining: 863ms\n",
      "786:\tlearn: 0.2380874\ttotal: 3.17s\tremaining: 858ms\n",
      "787:\tlearn: 0.2378152\ttotal: 3.17s\tremaining: 854ms\n",
      "788:\tlearn: 0.2376900\ttotal: 3.18s\tremaining: 850ms\n",
      "789:\tlearn: 0.2375830\ttotal: 3.18s\tremaining: 846ms\n",
      "790:\tlearn: 0.2374158\ttotal: 3.19s\tremaining: 842ms\n",
      "791:\tlearn: 0.2372971\ttotal: 3.19s\tremaining: 837ms\n",
      "792:\tlearn: 0.2370831\ttotal: 3.19s\tremaining: 833ms\n",
      "793:\tlearn: 0.2369133\ttotal: 3.19s\tremaining: 829ms\n",
      "794:\tlearn: 0.2366106\ttotal: 3.2s\tremaining: 825ms\n",
      "795:\tlearn: 0.2363777\ttotal: 3.2s\tremaining: 820ms\n",
      "796:\tlearn: 0.2362358\ttotal: 3.2s\tremaining: 816ms\n",
      "797:\tlearn: 0.2359011\ttotal: 3.21s\tremaining: 812ms\n",
      "798:\tlearn: 0.2357859\ttotal: 3.21s\tremaining: 808ms\n",
      "799:\tlearn: 0.2355913\ttotal: 3.21s\tremaining: 804ms\n",
      "800:\tlearn: 0.2354010\ttotal: 3.22s\tremaining: 799ms\n",
      "801:\tlearn: 0.2352666\ttotal: 3.22s\tremaining: 795ms\n",
      "802:\tlearn: 0.2351489\ttotal: 3.22s\tremaining: 791ms\n",
      "803:\tlearn: 0.2349078\ttotal: 3.23s\tremaining: 787ms\n",
      "804:\tlearn: 0.2347671\ttotal: 3.23s\tremaining: 783ms\n",
      "805:\tlearn: 0.2344939\ttotal: 3.23s\tremaining: 779ms\n",
      "806:\tlearn: 0.2343187\ttotal: 3.24s\tremaining: 774ms\n",
      "807:\tlearn: 0.2342246\ttotal: 3.24s\tremaining: 770ms\n",
      "808:\tlearn: 0.2339179\ttotal: 3.24s\tremaining: 766ms\n",
      "809:\tlearn: 0.2337512\ttotal: 3.25s\tremaining: 762ms\n",
      "810:\tlearn: 0.2336018\ttotal: 3.25s\tremaining: 757ms\n",
      "811:\tlearn: 0.2334202\ttotal: 3.25s\tremaining: 753ms\n",
      "812:\tlearn: 0.2332176\ttotal: 3.25s\tremaining: 749ms\n",
      "813:\tlearn: 0.2330511\ttotal: 3.26s\tremaining: 745ms\n",
      "814:\tlearn: 0.2328750\ttotal: 3.26s\tremaining: 740ms\n",
      "815:\tlearn: 0.2326687\ttotal: 3.26s\tremaining: 736ms\n",
      "816:\tlearn: 0.2325222\ttotal: 3.27s\tremaining: 732ms\n",
      "817:\tlearn: 0.2322874\ttotal: 3.27s\tremaining: 728ms\n",
      "818:\tlearn: 0.2320689\ttotal: 3.28s\tremaining: 724ms\n",
      "819:\tlearn: 0.2319297\ttotal: 3.28s\tremaining: 720ms\n",
      "820:\tlearn: 0.2317644\ttotal: 3.28s\tremaining: 716ms\n",
      "821:\tlearn: 0.2316623\ttotal: 3.29s\tremaining: 712ms\n",
      "822:\tlearn: 0.2314678\ttotal: 3.29s\tremaining: 708ms\n",
      "823:\tlearn: 0.2312015\ttotal: 3.29s\tremaining: 704ms\n",
      "824:\tlearn: 0.2310542\ttotal: 3.3s\tremaining: 700ms\n",
      "825:\tlearn: 0.2308565\ttotal: 3.3s\tremaining: 696ms\n",
      "826:\tlearn: 0.2305400\ttotal: 3.31s\tremaining: 692ms\n",
      "827:\tlearn: 0.2304169\ttotal: 3.31s\tremaining: 687ms\n",
      "828:\tlearn: 0.2300992\ttotal: 3.31s\tremaining: 683ms\n",
      "829:\tlearn: 0.2299721\ttotal: 3.31s\tremaining: 679ms\n",
      "830:\tlearn: 0.2298389\ttotal: 3.32s\tremaining: 675ms\n",
      "831:\tlearn: 0.2296860\ttotal: 3.32s\tremaining: 671ms\n",
      "832:\tlearn: 0.2295475\ttotal: 3.32s\tremaining: 666ms\n",
      "833:\tlearn: 0.2293742\ttotal: 3.33s\tremaining: 662ms\n",
      "834:\tlearn: 0.2290182\ttotal: 3.33s\tremaining: 658ms\n",
      "835:\tlearn: 0.2288583\ttotal: 3.33s\tremaining: 654ms\n",
      "836:\tlearn: 0.2286264\ttotal: 3.33s\tremaining: 650ms\n",
      "837:\tlearn: 0.2284781\ttotal: 3.34s\tremaining: 645ms\n",
      "838:\tlearn: 0.2283670\ttotal: 3.34s\tremaining: 641ms\n",
      "839:\tlearn: 0.2282271\ttotal: 3.35s\tremaining: 637ms\n",
      "840:\tlearn: 0.2280889\ttotal: 3.35s\tremaining: 633ms\n",
      "841:\tlearn: 0.2279137\ttotal: 3.35s\tremaining: 629ms\n",
      "842:\tlearn: 0.2276853\ttotal: 3.35s\tremaining: 625ms\n",
      "843:\tlearn: 0.2274174\ttotal: 3.36s\tremaining: 621ms\n",
      "844:\tlearn: 0.2271959\ttotal: 3.36s\tremaining: 617ms\n",
      "845:\tlearn: 0.2270551\ttotal: 3.37s\tremaining: 613ms\n",
      "846:\tlearn: 0.2268876\ttotal: 3.37s\tremaining: 609ms\n",
      "847:\tlearn: 0.2267159\ttotal: 3.37s\tremaining: 604ms\n",
      "848:\tlearn: 0.2265691\ttotal: 3.38s\tremaining: 600ms\n",
      "849:\tlearn: 0.2264057\ttotal: 3.38s\tremaining: 596ms\n",
      "850:\tlearn: 0.2260267\ttotal: 3.38s\tremaining: 592ms\n",
      "851:\tlearn: 0.2257976\ttotal: 3.38s\tremaining: 588ms\n",
      "852:\tlearn: 0.2257136\ttotal: 3.39s\tremaining: 584ms\n",
      "853:\tlearn: 0.2256663\ttotal: 3.39s\tremaining: 580ms\n",
      "854:\tlearn: 0.2254221\ttotal: 3.4s\tremaining: 576ms\n",
      "855:\tlearn: 0.2252427\ttotal: 3.4s\tremaining: 572ms\n",
      "856:\tlearn: 0.2250433\ttotal: 3.4s\tremaining: 568ms\n",
      "857:\tlearn: 0.2247595\ttotal: 3.4s\tremaining: 564ms\n",
      "858:\tlearn: 0.2246394\ttotal: 3.41s\tremaining: 559ms\n",
      "859:\tlearn: 0.2243120\ttotal: 3.41s\tremaining: 555ms\n",
      "860:\tlearn: 0.2241925\ttotal: 3.42s\tremaining: 551ms\n",
      "861:\tlearn: 0.2240638\ttotal: 3.42s\tremaining: 547ms\n",
      "862:\tlearn: 0.2239352\ttotal: 3.42s\tremaining: 543ms\n",
      "863:\tlearn: 0.2236692\ttotal: 3.42s\tremaining: 539ms\n",
      "864:\tlearn: 0.2234794\ttotal: 3.43s\tremaining: 535ms\n",
      "865:\tlearn: 0.2231145\ttotal: 3.43s\tremaining: 531ms\n",
      "866:\tlearn: 0.2229700\ttotal: 3.44s\tremaining: 527ms\n",
      "867:\tlearn: 0.2227991\ttotal: 3.44s\tremaining: 523ms\n",
      "868:\tlearn: 0.2225395\ttotal: 3.44s\tremaining: 519ms\n",
      "869:\tlearn: 0.2223273\ttotal: 3.45s\tremaining: 515ms\n",
      "870:\tlearn: 0.2222060\ttotal: 3.45s\tremaining: 512ms\n",
      "871:\tlearn: 0.2219445\ttotal: 3.46s\tremaining: 507ms\n",
      "872:\tlearn: 0.2217785\ttotal: 3.46s\tremaining: 503ms\n",
      "873:\tlearn: 0.2216847\ttotal: 3.46s\tremaining: 499ms\n",
      "874:\tlearn: 0.2214140\ttotal: 3.47s\tremaining: 495ms\n",
      "875:\tlearn: 0.2212080\ttotal: 3.47s\tremaining: 492ms\n",
      "876:\tlearn: 0.2208512\ttotal: 3.48s\tremaining: 488ms\n",
      "877:\tlearn: 0.2207645\ttotal: 3.48s\tremaining: 484ms\n",
      "878:\tlearn: 0.2205555\ttotal: 3.48s\tremaining: 480ms\n",
      "879:\tlearn: 0.2204548\ttotal: 3.49s\tremaining: 476ms\n",
      "880:\tlearn: 0.2202015\ttotal: 3.49s\tremaining: 472ms\n",
      "881:\tlearn: 0.2200388\ttotal: 3.5s\tremaining: 468ms\n",
      "882:\tlearn: 0.2198433\ttotal: 3.5s\tremaining: 464ms\n",
      "883:\tlearn: 0.2196712\ttotal: 3.51s\tremaining: 460ms\n",
      "884:\tlearn: 0.2194914\ttotal: 3.51s\tremaining: 456ms\n",
      "885:\tlearn: 0.2193409\ttotal: 3.51s\tremaining: 452ms\n",
      "886:\tlearn: 0.2191832\ttotal: 3.52s\tremaining: 448ms\n",
      "887:\tlearn: 0.2189982\ttotal: 3.52s\tremaining: 444ms\n",
      "888:\tlearn: 0.2189541\ttotal: 3.52s\tremaining: 440ms\n",
      "889:\tlearn: 0.2187998\ttotal: 3.52s\tremaining: 436ms\n",
      "890:\tlearn: 0.2186731\ttotal: 3.53s\tremaining: 432ms\n",
      "891:\tlearn: 0.2185396\ttotal: 3.53s\tremaining: 428ms\n",
      "892:\tlearn: 0.2183128\ttotal: 3.54s\tremaining: 424ms\n",
      "893:\tlearn: 0.2182888\ttotal: 3.54s\tremaining: 419ms\n",
      "894:\tlearn: 0.2181653\ttotal: 3.54s\tremaining: 416ms\n",
      "895:\tlearn: 0.2179473\ttotal: 3.54s\tremaining: 411ms\n",
      "896:\tlearn: 0.2177788\ttotal: 3.55s\tremaining: 407ms\n",
      "897:\tlearn: 0.2176164\ttotal: 3.55s\tremaining: 403ms\n",
      "898:\tlearn: 0.2174889\ttotal: 3.55s\tremaining: 399ms\n",
      "899:\tlearn: 0.2172979\ttotal: 3.56s\tremaining: 395ms\n",
      "900:\tlearn: 0.2171429\ttotal: 3.56s\tremaining: 391ms\n",
      "901:\tlearn: 0.2169466\ttotal: 3.56s\tremaining: 387ms\n",
      "902:\tlearn: 0.2168087\ttotal: 3.57s\tremaining: 383ms\n",
      "903:\tlearn: 0.2167165\ttotal: 3.57s\tremaining: 379ms\n",
      "904:\tlearn: 0.2166321\ttotal: 3.57s\tremaining: 375ms\n",
      "905:\tlearn: 0.2164486\ttotal: 3.58s\tremaining: 371ms\n",
      "906:\tlearn: 0.2163672\ttotal: 3.58s\tremaining: 367ms\n",
      "907:\tlearn: 0.2162739\ttotal: 3.58s\tremaining: 363ms\n",
      "908:\tlearn: 0.2161120\ttotal: 3.58s\tremaining: 359ms\n",
      "909:\tlearn: 0.2159395\ttotal: 3.59s\tremaining: 355ms\n",
      "910:\tlearn: 0.2157345\ttotal: 3.59s\tremaining: 351ms\n",
      "911:\tlearn: 0.2156024\ttotal: 3.59s\tremaining: 347ms\n",
      "912:\tlearn: 0.2154856\ttotal: 3.6s\tremaining: 343ms\n",
      "913:\tlearn: 0.2153331\ttotal: 3.6s\tremaining: 339ms\n",
      "914:\tlearn: 0.2151199\ttotal: 3.6s\tremaining: 335ms\n",
      "915:\tlearn: 0.2150830\ttotal: 3.61s\tremaining: 331ms\n",
      "916:\tlearn: 0.2148211\ttotal: 3.61s\tremaining: 327ms\n",
      "917:\tlearn: 0.2147122\ttotal: 3.61s\tremaining: 323ms\n",
      "918:\tlearn: 0.2145809\ttotal: 3.62s\tremaining: 319ms\n",
      "919:\tlearn: 0.2144906\ttotal: 3.62s\tremaining: 315ms\n",
      "920:\tlearn: 0.2143125\ttotal: 3.62s\tremaining: 311ms\n",
      "921:\tlearn: 0.2141795\ttotal: 3.63s\tremaining: 307ms\n",
      "922:\tlearn: 0.2139721\ttotal: 3.63s\tremaining: 303ms\n",
      "923:\tlearn: 0.2138950\ttotal: 3.63s\tremaining: 299ms\n",
      "924:\tlearn: 0.2136272\ttotal: 3.64s\tremaining: 295ms\n",
      "925:\tlearn: 0.2134429\ttotal: 3.64s\tremaining: 291ms\n",
      "926:\tlearn: 0.2133051\ttotal: 3.64s\tremaining: 287ms\n",
      "927:\tlearn: 0.2132245\ttotal: 3.65s\tremaining: 283ms\n",
      "928:\tlearn: 0.2129692\ttotal: 3.65s\tremaining: 279ms\n",
      "929:\tlearn: 0.2128509\ttotal: 3.65s\tremaining: 275ms\n",
      "930:\tlearn: 0.2127490\ttotal: 3.66s\tremaining: 271ms\n",
      "931:\tlearn: 0.2126729\ttotal: 3.66s\tremaining: 267ms\n",
      "932:\tlearn: 0.2125671\ttotal: 3.66s\tremaining: 263ms\n",
      "933:\tlearn: 0.2124625\ttotal: 3.66s\tremaining: 259ms\n",
      "934:\tlearn: 0.2122646\ttotal: 3.67s\tremaining: 255ms\n",
      "935:\tlearn: 0.2122177\ttotal: 3.67s\tremaining: 251ms\n",
      "936:\tlearn: 0.2121628\ttotal: 3.67s\tremaining: 247ms\n",
      "937:\tlearn: 0.2118548\ttotal: 3.68s\tremaining: 243ms\n",
      "938:\tlearn: 0.2115543\ttotal: 3.68s\tremaining: 239ms\n",
      "939:\tlearn: 0.2113833\ttotal: 3.68s\tremaining: 235ms\n",
      "940:\tlearn: 0.2112589\ttotal: 3.69s\tremaining: 231ms\n",
      "941:\tlearn: 0.2109733\ttotal: 3.69s\tremaining: 227ms\n",
      "942:\tlearn: 0.2108908\ttotal: 3.69s\tremaining: 223ms\n",
      "943:\tlearn: 0.2106761\ttotal: 3.69s\tremaining: 219ms\n",
      "944:\tlearn: 0.2105579\ttotal: 3.7s\tremaining: 215ms\n",
      "945:\tlearn: 0.2104493\ttotal: 3.7s\tremaining: 211ms\n",
      "946:\tlearn: 0.2102952\ttotal: 3.7s\tremaining: 207ms\n",
      "947:\tlearn: 0.2101792\ttotal: 3.71s\tremaining: 203ms\n",
      "948:\tlearn: 0.2100537\ttotal: 3.71s\tremaining: 199ms\n",
      "949:\tlearn: 0.2097245\ttotal: 3.71s\tremaining: 195ms\n",
      "950:\tlearn: 0.2096027\ttotal: 3.71s\tremaining: 191ms\n",
      "951:\tlearn: 0.2094258\ttotal: 3.72s\tremaining: 187ms\n",
      "952:\tlearn: 0.2093069\ttotal: 3.72s\tremaining: 183ms\n",
      "953:\tlearn: 0.2091477\ttotal: 3.72s\tremaining: 180ms\n",
      "954:\tlearn: 0.2091106\ttotal: 3.73s\tremaining: 176ms\n",
      "955:\tlearn: 0.2089329\ttotal: 3.73s\tremaining: 172ms\n",
      "956:\tlearn: 0.2088182\ttotal: 3.73s\tremaining: 168ms\n",
      "957:\tlearn: 0.2087164\ttotal: 3.74s\tremaining: 164ms\n",
      "958:\tlearn: 0.2085796\ttotal: 3.74s\tremaining: 160ms\n",
      "959:\tlearn: 0.2083627\ttotal: 3.74s\tremaining: 156ms\n",
      "960:\tlearn: 0.2082662\ttotal: 3.75s\tremaining: 152ms\n",
      "961:\tlearn: 0.2081014\ttotal: 3.75s\tremaining: 148ms\n",
      "962:\tlearn: 0.2079390\ttotal: 3.75s\tremaining: 144ms\n",
      "963:\tlearn: 0.2078367\ttotal: 3.75s\tremaining: 140ms\n",
      "964:\tlearn: 0.2077387\ttotal: 3.76s\tremaining: 136ms\n",
      "965:\tlearn: 0.2075533\ttotal: 3.76s\tremaining: 132ms\n",
      "966:\tlearn: 0.2073085\ttotal: 3.76s\tremaining: 128ms\n",
      "967:\tlearn: 0.2071515\ttotal: 3.77s\tremaining: 124ms\n",
      "968:\tlearn: 0.2070871\ttotal: 3.77s\tremaining: 121ms\n",
      "969:\tlearn: 0.2069655\ttotal: 3.77s\tremaining: 117ms\n",
      "970:\tlearn: 0.2067653\ttotal: 3.77s\tremaining: 113ms\n",
      "971:\tlearn: 0.2066368\ttotal: 3.78s\tremaining: 109ms\n",
      "972:\tlearn: 0.2065378\ttotal: 3.78s\tremaining: 105ms\n",
      "973:\tlearn: 0.2063725\ttotal: 3.78s\tremaining: 101ms\n",
      "974:\tlearn: 0.2062326\ttotal: 3.79s\tremaining: 97.1ms\n",
      "975:\tlearn: 0.2061532\ttotal: 3.79s\tremaining: 93.2ms\n",
      "976:\tlearn: 0.2059564\ttotal: 3.79s\tremaining: 89.3ms\n",
      "977:\tlearn: 0.2058368\ttotal: 3.8s\tremaining: 85.5ms\n",
      "978:\tlearn: 0.2057706\ttotal: 3.8s\tremaining: 81.6ms\n",
      "979:\tlearn: 0.2056539\ttotal: 3.81s\tremaining: 77.7ms\n",
      "980:\tlearn: 0.2054951\ttotal: 3.81s\tremaining: 73.8ms\n",
      "981:\tlearn: 0.2053346\ttotal: 3.81s\tremaining: 69.9ms\n",
      "982:\tlearn: 0.2052033\ttotal: 3.81s\tremaining: 66ms\n",
      "983:\tlearn: 0.2050678\ttotal: 3.82s\tremaining: 62.1ms\n",
      "984:\tlearn: 0.2048613\ttotal: 3.82s\tremaining: 58.2ms\n",
      "985:\tlearn: 0.2047229\ttotal: 3.82s\tremaining: 54.3ms\n",
      "986:\tlearn: 0.2046777\ttotal: 3.83s\tremaining: 50.4ms\n",
      "987:\tlearn: 0.2044878\ttotal: 3.83s\tremaining: 46.5ms\n",
      "988:\tlearn: 0.2043539\ttotal: 3.83s\tremaining: 42.6ms\n",
      "989:\tlearn: 0.2041824\ttotal: 3.83s\tremaining: 38.7ms\n",
      "990:\tlearn: 0.2039445\ttotal: 3.84s\tremaining: 34.9ms\n",
      "991:\tlearn: 0.2038224\ttotal: 3.84s\tremaining: 31ms\n",
      "992:\tlearn: 0.2036633\ttotal: 3.84s\tremaining: 27.1ms\n",
      "993:\tlearn: 0.2033966\ttotal: 3.85s\tremaining: 23.2ms\n",
      "994:\tlearn: 0.2032914\ttotal: 3.85s\tremaining: 19.3ms\n",
      "995:\tlearn: 0.2030529\ttotal: 3.85s\tremaining: 15.5ms\n",
      "996:\tlearn: 0.2029108\ttotal: 3.85s\tremaining: 11.6ms\n",
      "997:\tlearn: 0.2027234\ttotal: 3.86s\tremaining: 7.73ms\n",
      "998:\tlearn: 0.2026604\ttotal: 3.86s\tremaining: 3.86ms\n",
      "999:\tlearn: 0.2025371\ttotal: 3.86s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777292576419214"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cat_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "catb_params = {\n",
    "    'iterations': [200,500],\n",
    "    'learning_rate': [0.01,0.05, 0.1],\n",
    "    'depth': [3,5,8] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "0:\tlearn: 0.6556552\ttotal: 3.76ms\tremaining: 1.88s\n",
      "1:\tlearn: 0.6292138\ttotal: 6.33ms\tremaining: 1.58s\n",
      "2:\tlearn: 0.6109906\ttotal: 9.15ms\tremaining: 1.52s\n",
      "3:\tlearn: 0.5880711\ttotal: 11.5ms\tremaining: 1.43s\n",
      "4:\tlearn: 0.5663977\ttotal: 15.2ms\tremaining: 1.5s\n",
      "5:\tlearn: 0.5459126\ttotal: 18.6ms\tremaining: 1.53s\n",
      "6:\tlearn: 0.5340227\ttotal: 21.4ms\tremaining: 1.51s\n",
      "7:\tlearn: 0.5227953\ttotal: 24.6ms\tremaining: 1.51s\n",
      "8:\tlearn: 0.5108263\ttotal: 28ms\tremaining: 1.52s\n",
      "9:\tlearn: 0.5025857\ttotal: 30.1ms\tremaining: 1.47s\n",
      "10:\tlearn: 0.4955538\ttotal: 32.6ms\tremaining: 1.45s\n",
      "11:\tlearn: 0.4856709\ttotal: 34.8ms\tremaining: 1.42s\n",
      "12:\tlearn: 0.4799371\ttotal: 36.8ms\tremaining: 1.38s\n",
      "13:\tlearn: 0.4740515\ttotal: 39ms\tremaining: 1.35s\n",
      "14:\tlearn: 0.4682936\ttotal: 41.6ms\tremaining: 1.34s\n",
      "15:\tlearn: 0.4646692\ttotal: 43.7ms\tremaining: 1.32s\n",
      "16:\tlearn: 0.4584397\ttotal: 45.7ms\tremaining: 1.3s\n",
      "17:\tlearn: 0.4550613\ttotal: 48.5ms\tremaining: 1.3s\n",
      "18:\tlearn: 0.4527892\ttotal: 50.6ms\tremaining: 1.28s\n",
      "19:\tlearn: 0.4477699\ttotal: 53.3ms\tremaining: 1.28s\n",
      "20:\tlearn: 0.4419841\ttotal: 55.3ms\tremaining: 1.26s\n",
      "21:\tlearn: 0.4392537\ttotal: 57.7ms\tremaining: 1.25s\n",
      "22:\tlearn: 0.4367955\ttotal: 59.8ms\tremaining: 1.24s\n",
      "23:\tlearn: 0.4342329\ttotal: 62.5ms\tremaining: 1.24s\n",
      "24:\tlearn: 0.4318246\ttotal: 64.8ms\tremaining: 1.23s\n",
      "25:\tlearn: 0.4299995\ttotal: 66.6ms\tremaining: 1.21s\n",
      "26:\tlearn: 0.4277870\ttotal: 68.6ms\tremaining: 1.2s\n",
      "27:\tlearn: 0.4246737\ttotal: 70.3ms\tremaining: 1.18s\n",
      "28:\tlearn: 0.4220365\ttotal: 72.7ms\tremaining: 1.18s\n",
      "29:\tlearn: 0.4197254\ttotal: 75ms\tremaining: 1.18s\n",
      "30:\tlearn: 0.4185454\ttotal: 76.7ms\tremaining: 1.16s\n",
      "31:\tlearn: 0.4169747\ttotal: 78.7ms\tremaining: 1.15s\n",
      "32:\tlearn: 0.4142823\ttotal: 81.6ms\tremaining: 1.15s\n",
      "33:\tlearn: 0.4133513\ttotal: 85.1ms\tremaining: 1.17s\n",
      "34:\tlearn: 0.4119644\ttotal: 88ms\tremaining: 1.17s\n",
      "35:\tlearn: 0.4096200\ttotal: 90.1ms\tremaining: 1.16s\n",
      "36:\tlearn: 0.4077322\ttotal: 93ms\tremaining: 1.16s\n",
      "37:\tlearn: 0.4052567\ttotal: 96.7ms\tremaining: 1.18s\n",
      "38:\tlearn: 0.4044945\ttotal: 99.4ms\tremaining: 1.18s\n",
      "39:\tlearn: 0.4031664\ttotal: 102ms\tremaining: 1.17s\n",
      "40:\tlearn: 0.4014256\ttotal: 105ms\tremaining: 1.18s\n",
      "41:\tlearn: 0.4005433\ttotal: 109ms\tremaining: 1.19s\n",
      "42:\tlearn: 0.3990250\ttotal: 111ms\tremaining: 1.18s\n",
      "43:\tlearn: 0.3971231\ttotal: 113ms\tremaining: 1.17s\n",
      "44:\tlearn: 0.3962900\ttotal: 116ms\tremaining: 1.17s\n",
      "45:\tlearn: 0.3943350\ttotal: 120ms\tremaining: 1.19s\n",
      "46:\tlearn: 0.3927359\ttotal: 125ms\tremaining: 1.2s\n",
      "47:\tlearn: 0.3911599\ttotal: 127ms\tremaining: 1.19s\n",
      "48:\tlearn: 0.3887982\ttotal: 129ms\tremaining: 1.19s\n",
      "49:\tlearn: 0.3880143\ttotal: 132ms\tremaining: 1.18s\n",
      "50:\tlearn: 0.3864979\ttotal: 133ms\tremaining: 1.17s\n",
      "51:\tlearn: 0.3850136\ttotal: 136ms\tremaining: 1.17s\n",
      "52:\tlearn: 0.3833479\ttotal: 138ms\tremaining: 1.16s\n",
      "53:\tlearn: 0.3815247\ttotal: 140ms\tremaining: 1.16s\n",
      "54:\tlearn: 0.3794538\ttotal: 143ms\tremaining: 1.16s\n",
      "55:\tlearn: 0.3783572\ttotal: 145ms\tremaining: 1.15s\n",
      "56:\tlearn: 0.3771278\ttotal: 148ms\tremaining: 1.15s\n",
      "57:\tlearn: 0.3749796\ttotal: 150ms\tremaining: 1.14s\n",
      "58:\tlearn: 0.3737387\ttotal: 152ms\tremaining: 1.14s\n",
      "59:\tlearn: 0.3724256\ttotal: 154ms\tremaining: 1.13s\n",
      "60:\tlearn: 0.3707556\ttotal: 158ms\tremaining: 1.14s\n",
      "61:\tlearn: 0.3689258\ttotal: 160ms\tremaining: 1.13s\n",
      "62:\tlearn: 0.3680360\ttotal: 162ms\tremaining: 1.13s\n",
      "63:\tlearn: 0.3666578\ttotal: 165ms\tremaining: 1.12s\n",
      "64:\tlearn: 0.3649717\ttotal: 167ms\tremaining: 1.12s\n",
      "65:\tlearn: 0.3637861\ttotal: 170ms\tremaining: 1.12s\n",
      "66:\tlearn: 0.3622250\ttotal: 173ms\tremaining: 1.12s\n",
      "67:\tlearn: 0.3605904\ttotal: 176ms\tremaining: 1.12s\n",
      "68:\tlearn: 0.3583399\ttotal: 178ms\tremaining: 1.11s\n",
      "69:\tlearn: 0.3561524\ttotal: 181ms\tremaining: 1.11s\n",
      "70:\tlearn: 0.3544471\ttotal: 183ms\tremaining: 1.11s\n",
      "71:\tlearn: 0.3533871\ttotal: 186ms\tremaining: 1.1s\n",
      "72:\tlearn: 0.3519183\ttotal: 189ms\tremaining: 1.11s\n",
      "73:\tlearn: 0.3502742\ttotal: 192ms\tremaining: 1.1s\n",
      "74:\tlearn: 0.3488070\ttotal: 195ms\tremaining: 1.1s\n",
      "75:\tlearn: 0.3470812\ttotal: 198ms\tremaining: 1.11s\n",
      "76:\tlearn: 0.3462123\ttotal: 201ms\tremaining: 1.1s\n",
      "77:\tlearn: 0.3440644\ttotal: 202ms\tremaining: 1.09s\n",
      "78:\tlearn: 0.3421755\ttotal: 205ms\tremaining: 1.09s\n",
      "79:\tlearn: 0.3404306\ttotal: 207ms\tremaining: 1.08s\n",
      "80:\tlearn: 0.3398666\ttotal: 209ms\tremaining: 1.08s\n",
      "81:\tlearn: 0.3380142\ttotal: 211ms\tremaining: 1.08s\n",
      "82:\tlearn: 0.3372165\ttotal: 213ms\tremaining: 1.07s\n",
      "83:\tlearn: 0.3353765\ttotal: 215ms\tremaining: 1.07s\n",
      "84:\tlearn: 0.3339927\ttotal: 217ms\tremaining: 1.06s\n",
      "85:\tlearn: 0.3318490\ttotal: 219ms\tremaining: 1.05s\n",
      "86:\tlearn: 0.3311474\ttotal: 221ms\tremaining: 1.05s\n",
      "87:\tlearn: 0.3291563\ttotal: 223ms\tremaining: 1.04s\n",
      "88:\tlearn: 0.3278247\ttotal: 225ms\tremaining: 1.04s\n",
      "89:\tlearn: 0.3273977\ttotal: 227ms\tremaining: 1.03s\n",
      "90:\tlearn: 0.3266835\ttotal: 229ms\tremaining: 1.03s\n",
      "91:\tlearn: 0.3249126\ttotal: 231ms\tremaining: 1.02s\n",
      "92:\tlearn: 0.3237811\ttotal: 233ms\tremaining: 1.02s\n",
      "93:\tlearn: 0.3222341\ttotal: 234ms\tremaining: 1.01s\n",
      "94:\tlearn: 0.3212766\ttotal: 236ms\tremaining: 1s\n",
      "95:\tlearn: 0.3202625\ttotal: 238ms\tremaining: 1s\n",
      "96:\tlearn: 0.3184539\ttotal: 240ms\tremaining: 996ms\n",
      "97:\tlearn: 0.3179943\ttotal: 241ms\tremaining: 989ms\n",
      "98:\tlearn: 0.3168224\ttotal: 243ms\tremaining: 983ms\n",
      "99:\tlearn: 0.3154744\ttotal: 245ms\tremaining: 978ms\n",
      "100:\tlearn: 0.3137756\ttotal: 246ms\tremaining: 972ms\n",
      "101:\tlearn: 0.3124163\ttotal: 248ms\tremaining: 967ms\n",
      "102:\tlearn: 0.3120212\ttotal: 249ms\tremaining: 961ms\n",
      "103:\tlearn: 0.3097368\ttotal: 251ms\tremaining: 956ms\n",
      "104:\tlearn: 0.3090124\ttotal: 253ms\tremaining: 952ms\n",
      "105:\tlearn: 0.3071801\ttotal: 255ms\tremaining: 949ms\n",
      "106:\tlearn: 0.3057606\ttotal: 257ms\tremaining: 944ms\n",
      "107:\tlearn: 0.3051412\ttotal: 259ms\tremaining: 940ms\n",
      "108:\tlearn: 0.3040576\ttotal: 261ms\tremaining: 935ms\n",
      "109:\tlearn: 0.3025061\ttotal: 263ms\tremaining: 931ms\n",
      "110:\tlearn: 0.3012222\ttotal: 264ms\tremaining: 926ms\n",
      "111:\tlearn: 0.2986968\ttotal: 266ms\tremaining: 921ms\n",
      "112:\tlearn: 0.2980037\ttotal: 268ms\tremaining: 918ms\n",
      "113:\tlearn: 0.2978067\ttotal: 270ms\tremaining: 913ms\n",
      "114:\tlearn: 0.2965494\ttotal: 271ms\tremaining: 909ms\n",
      "115:\tlearn: 0.2958209\ttotal: 274ms\tremaining: 906ms\n",
      "116:\tlearn: 0.2937516\ttotal: 276ms\tremaining: 903ms\n",
      "117:\tlearn: 0.2918059\ttotal: 278ms\tremaining: 901ms\n",
      "118:\tlearn: 0.2912345\ttotal: 280ms\tremaining: 897ms\n",
      "119:\tlearn: 0.2904953\ttotal: 282ms\tremaining: 894ms\n",
      "120:\tlearn: 0.2899694\ttotal: 284ms\tremaining: 890ms\n",
      "121:\tlearn: 0.2887913\ttotal: 287ms\tremaining: 890ms\n",
      "122:\tlearn: 0.2877858\ttotal: 291ms\tremaining: 892ms\n",
      "123:\tlearn: 0.2867633\ttotal: 294ms\tremaining: 890ms\n",
      "124:\tlearn: 0.2857686\ttotal: 296ms\tremaining: 889ms\n",
      "125:\tlearn: 0.2850919\ttotal: 298ms\tremaining: 884ms\n",
      "126:\tlearn: 0.2835206\ttotal: 299ms\tremaining: 879ms\n",
      "127:\tlearn: 0.2826183\ttotal: 301ms\tremaining: 874ms\n",
      "128:\tlearn: 0.2821099\ttotal: 302ms\tremaining: 870ms\n",
      "129:\tlearn: 0.2808446\ttotal: 305ms\tremaining: 868ms\n",
      "130:\tlearn: 0.2797359\ttotal: 307ms\tremaining: 864ms\n",
      "131:\tlearn: 0.2787988\ttotal: 309ms\tremaining: 861ms\n",
      "132:\tlearn: 0.2785913\ttotal: 312ms\tremaining: 861ms\n",
      "133:\tlearn: 0.2771466\ttotal: 313ms\tremaining: 856ms\n",
      "134:\tlearn: 0.2767686\ttotal: 315ms\tremaining: 851ms\n",
      "135:\tlearn: 0.2758044\ttotal: 316ms\tremaining: 846ms\n",
      "136:\tlearn: 0.2752077\ttotal: 318ms\tremaining: 841ms\n",
      "137:\tlearn: 0.2735741\ttotal: 319ms\tremaining: 836ms\n",
      "138:\tlearn: 0.2722733\ttotal: 321ms\tremaining: 833ms\n",
      "139:\tlearn: 0.2719397\ttotal: 322ms\tremaining: 829ms\n",
      "140:\tlearn: 0.2705035\ttotal: 324ms\tremaining: 824ms\n",
      "141:\tlearn: 0.2703516\ttotal: 325ms\tremaining: 820ms\n",
      "142:\tlearn: 0.2688300\ttotal: 327ms\tremaining: 816ms\n",
      "143:\tlearn: 0.2678968\ttotal: 328ms\tremaining: 812ms\n",
      "144:\tlearn: 0.2673779\ttotal: 330ms\tremaining: 808ms\n",
      "145:\tlearn: 0.2655695\ttotal: 332ms\tremaining: 806ms\n",
      "146:\tlearn: 0.2646470\ttotal: 334ms\tremaining: 803ms\n",
      "147:\tlearn: 0.2639481\ttotal: 336ms\tremaining: 799ms\n",
      "148:\tlearn: 0.2625742\ttotal: 337ms\tremaining: 794ms\n",
      "149:\tlearn: 0.2618532\ttotal: 339ms\tremaining: 790ms\n",
      "150:\tlearn: 0.2610353\ttotal: 340ms\tremaining: 786ms\n",
      "151:\tlearn: 0.2605344\ttotal: 341ms\tremaining: 782ms\n",
      "152:\tlearn: 0.2600992\ttotal: 343ms\tremaining: 777ms\n",
      "153:\tlearn: 0.2597135\ttotal: 345ms\tremaining: 775ms\n",
      "154:\tlearn: 0.2587357\ttotal: 346ms\tremaining: 771ms\n",
      "155:\tlearn: 0.2575216\ttotal: 348ms\tremaining: 767ms\n",
      "156:\tlearn: 0.2572603\ttotal: 349ms\tremaining: 762ms\n",
      "157:\tlearn: 0.2563390\ttotal: 350ms\tremaining: 758ms\n",
      "158:\tlearn: 0.2562210\ttotal: 352ms\tremaining: 755ms\n",
      "159:\tlearn: 0.2553903\ttotal: 353ms\tremaining: 751ms\n",
      "160:\tlearn: 0.2545478\ttotal: 355ms\tremaining: 748ms\n",
      "161:\tlearn: 0.2541011\ttotal: 357ms\tremaining: 745ms\n",
      "162:\tlearn: 0.2531932\ttotal: 359ms\tremaining: 742ms\n",
      "163:\tlearn: 0.2529657\ttotal: 361ms\tremaining: 740ms\n",
      "164:\tlearn: 0.2524274\ttotal: 362ms\tremaining: 735ms\n",
      "165:\tlearn: 0.2516756\ttotal: 363ms\tremaining: 731ms\n",
      "166:\tlearn: 0.2507301\ttotal: 365ms\tremaining: 727ms\n",
      "167:\tlearn: 0.2496542\ttotal: 366ms\tremaining: 724ms\n",
      "168:\tlearn: 0.2492567\ttotal: 367ms\tremaining: 720ms\n",
      "169:\tlearn: 0.2481999\ttotal: 369ms\tremaining: 716ms\n",
      "170:\tlearn: 0.2473141\ttotal: 370ms\tremaining: 712ms\n",
      "171:\tlearn: 0.2455191\ttotal: 372ms\tremaining: 709ms\n",
      "172:\tlearn: 0.2447594\ttotal: 373ms\tremaining: 705ms\n",
      "173:\tlearn: 0.2438101\ttotal: 374ms\tremaining: 701ms\n",
      "174:\tlearn: 0.2430255\ttotal: 376ms\tremaining: 697ms\n",
      "175:\tlearn: 0.2423667\ttotal: 378ms\tremaining: 696ms\n",
      "176:\tlearn: 0.2410700\ttotal: 380ms\tremaining: 693ms\n",
      "177:\tlearn: 0.2399345\ttotal: 382ms\tremaining: 690ms\n",
      "178:\tlearn: 0.2386370\ttotal: 383ms\tremaining: 688ms\n",
      "179:\tlearn: 0.2384280\ttotal: 386ms\tremaining: 685ms\n",
      "180:\tlearn: 0.2375899\ttotal: 387ms\tremaining: 683ms\n",
      "181:\tlearn: 0.2373685\ttotal: 389ms\tremaining: 680ms\n",
      "182:\tlearn: 0.2364903\ttotal: 391ms\tremaining: 677ms\n",
      "183:\tlearn: 0.2359474\ttotal: 392ms\tremaining: 674ms\n",
      "184:\tlearn: 0.2343720\ttotal: 394ms\tremaining: 672ms\n",
      "185:\tlearn: 0.2340414\ttotal: 396ms\tremaining: 669ms\n",
      "186:\tlearn: 0.2336527\ttotal: 398ms\tremaining: 666ms\n",
      "187:\tlearn: 0.2329022\ttotal: 399ms\tremaining: 663ms\n",
      "188:\tlearn: 0.2325413\ttotal: 402ms\tremaining: 661ms\n",
      "189:\tlearn: 0.2322812\ttotal: 403ms\tremaining: 658ms\n",
      "190:\tlearn: 0.2312950\ttotal: 405ms\tremaining: 654ms\n",
      "191:\tlearn: 0.2299716\ttotal: 406ms\tremaining: 652ms\n",
      "192:\tlearn: 0.2298265\ttotal: 408ms\tremaining: 649ms\n",
      "193:\tlearn: 0.2293380\ttotal: 410ms\tremaining: 646ms\n",
      "194:\tlearn: 0.2285937\ttotal: 412ms\tremaining: 645ms\n",
      "195:\tlearn: 0.2284143\ttotal: 414ms\tremaining: 642ms\n",
      "196:\tlearn: 0.2276729\ttotal: 416ms\tremaining: 640ms\n",
      "197:\tlearn: 0.2264193\ttotal: 418ms\tremaining: 637ms\n",
      "198:\tlearn: 0.2258926\ttotal: 420ms\tremaining: 635ms\n",
      "199:\tlearn: 0.2247964\ttotal: 422ms\tremaining: 633ms\n",
      "200:\tlearn: 0.2243014\ttotal: 423ms\tremaining: 630ms\n",
      "201:\tlearn: 0.2233608\ttotal: 425ms\tremaining: 627ms\n",
      "202:\tlearn: 0.2227371\ttotal: 427ms\tremaining: 624ms\n",
      "203:\tlearn: 0.2225749\ttotal: 429ms\tremaining: 623ms\n",
      "204:\tlearn: 0.2215938\ttotal: 431ms\tremaining: 620ms\n",
      "205:\tlearn: 0.2214769\ttotal: 432ms\tremaining: 617ms\n",
      "206:\tlearn: 0.2204198\ttotal: 435ms\tremaining: 615ms\n",
      "207:\tlearn: 0.2194359\ttotal: 436ms\tremaining: 612ms\n",
      "208:\tlearn: 0.2193407\ttotal: 438ms\tremaining: 610ms\n",
      "209:\tlearn: 0.2187875\ttotal: 439ms\tremaining: 607ms\n",
      "210:\tlearn: 0.2181259\ttotal: 441ms\tremaining: 604ms\n",
      "211:\tlearn: 0.2180281\ttotal: 442ms\tremaining: 600ms\n",
      "212:\tlearn: 0.2173140\ttotal: 444ms\tremaining: 598ms\n",
      "213:\tlearn: 0.2170410\ttotal: 445ms\tremaining: 595ms\n",
      "214:\tlearn: 0.2163775\ttotal: 447ms\tremaining: 592ms\n",
      "215:\tlearn: 0.2158407\ttotal: 448ms\tremaining: 589ms\n",
      "216:\tlearn: 0.2154784\ttotal: 449ms\tremaining: 586ms\n",
      "217:\tlearn: 0.2151947\ttotal: 451ms\tremaining: 583ms\n",
      "218:\tlearn: 0.2139125\ttotal: 453ms\tremaining: 581ms\n",
      "219:\tlearn: 0.2135035\ttotal: 454ms\tremaining: 578ms\n",
      "220:\tlearn: 0.2133718\ttotal: 456ms\tremaining: 576ms\n",
      "221:\tlearn: 0.2119201\ttotal: 459ms\tremaining: 574ms\n",
      "222:\tlearn: 0.2109899\ttotal: 461ms\tremaining: 572ms\n",
      "223:\tlearn: 0.2101504\ttotal: 462ms\tremaining: 570ms\n",
      "224:\tlearn: 0.2100708\ttotal: 464ms\tremaining: 567ms\n",
      "225:\tlearn: 0.2099687\ttotal: 466ms\tremaining: 565ms\n",
      "226:\tlearn: 0.2095331\ttotal: 467ms\tremaining: 562ms\n",
      "227:\tlearn: 0.2094676\ttotal: 469ms\tremaining: 560ms\n",
      "228:\tlearn: 0.2086030\ttotal: 471ms\tremaining: 557ms\n",
      "229:\tlearn: 0.2081022\ttotal: 473ms\tremaining: 555ms\n",
      "230:\tlearn: 0.2080567\ttotal: 475ms\tremaining: 553ms\n",
      "231:\tlearn: 0.2066541\ttotal: 477ms\tremaining: 551ms\n",
      "232:\tlearn: 0.2057689\ttotal: 478ms\tremaining: 548ms\n",
      "233:\tlearn: 0.2052297\ttotal: 480ms\tremaining: 546ms\n",
      "234:\tlearn: 0.2044734\ttotal: 482ms\tremaining: 544ms\n",
      "235:\tlearn: 0.2032589\ttotal: 484ms\tremaining: 541ms\n",
      "236:\tlearn: 0.2028771\ttotal: 486ms\tremaining: 539ms\n",
      "237:\tlearn: 0.2025787\ttotal: 488ms\tremaining: 537ms\n",
      "238:\tlearn: 0.2015859\ttotal: 490ms\tremaining: 535ms\n",
      "239:\tlearn: 0.2014785\ttotal: 492ms\tremaining: 533ms\n",
      "240:\tlearn: 0.2000984\ttotal: 494ms\tremaining: 531ms\n",
      "241:\tlearn: 0.1989847\ttotal: 496ms\tremaining: 529ms\n",
      "242:\tlearn: 0.1987791\ttotal: 497ms\tremaining: 526ms\n",
      "243:\tlearn: 0.1980506\ttotal: 500ms\tremaining: 525ms\n",
      "244:\tlearn: 0.1975157\ttotal: 505ms\tremaining: 525ms\n",
      "245:\tlearn: 0.1965191\ttotal: 507ms\tremaining: 523ms\n",
      "246:\tlearn: 0.1960298\ttotal: 510ms\tremaining: 522ms\n",
      "247:\tlearn: 0.1953317\ttotal: 512ms\tremaining: 520ms\n",
      "248:\tlearn: 0.1949992\ttotal: 515ms\tremaining: 519ms\n",
      "249:\tlearn: 0.1943742\ttotal: 517ms\tremaining: 517ms\n",
      "250:\tlearn: 0.1942453\ttotal: 519ms\tremaining: 515ms\n",
      "251:\tlearn: 0.1934757\ttotal: 521ms\tremaining: 513ms\n",
      "252:\tlearn: 0.1932056\ttotal: 523ms\tremaining: 511ms\n",
      "253:\tlearn: 0.1928213\ttotal: 525ms\tremaining: 509ms\n",
      "254:\tlearn: 0.1913185\ttotal: 528ms\tremaining: 507ms\n",
      "255:\tlearn: 0.1898836\ttotal: 530ms\tremaining: 505ms\n",
      "256:\tlearn: 0.1897296\ttotal: 532ms\tremaining: 503ms\n",
      "257:\tlearn: 0.1892976\ttotal: 535ms\tremaining: 502ms\n",
      "258:\tlearn: 0.1888314\ttotal: 538ms\tremaining: 500ms\n",
      "259:\tlearn: 0.1878615\ttotal: 540ms\tremaining: 499ms\n",
      "260:\tlearn: 0.1873766\ttotal: 542ms\tremaining: 497ms\n",
      "261:\tlearn: 0.1872957\ttotal: 545ms\tremaining: 495ms\n",
      "262:\tlearn: 0.1864479\ttotal: 547ms\tremaining: 493ms\n",
      "263:\tlearn: 0.1862648\ttotal: 549ms\tremaining: 490ms\n",
      "264:\tlearn: 0.1857471\ttotal: 550ms\tremaining: 488ms\n",
      "265:\tlearn: 0.1855543\ttotal: 552ms\tremaining: 486ms\n",
      "266:\tlearn: 0.1851030\ttotal: 554ms\tremaining: 483ms\n",
      "267:\tlearn: 0.1846067\ttotal: 556ms\tremaining: 481ms\n",
      "268:\tlearn: 0.1836943\ttotal: 558ms\tremaining: 479ms\n",
      "269:\tlearn: 0.1824782\ttotal: 559ms\tremaining: 477ms\n",
      "270:\tlearn: 0.1821358\ttotal: 561ms\tremaining: 474ms\n",
      "271:\tlearn: 0.1817772\ttotal: 563ms\tremaining: 472ms\n",
      "272:\tlearn: 0.1810876\ttotal: 565ms\tremaining: 470ms\n",
      "273:\tlearn: 0.1805865\ttotal: 567ms\tremaining: 467ms\n",
      "274:\tlearn: 0.1799685\ttotal: 568ms\tremaining: 465ms\n",
      "275:\tlearn: 0.1797071\ttotal: 570ms\tremaining: 463ms\n",
      "276:\tlearn: 0.1791678\ttotal: 572ms\tremaining: 460ms\n",
      "277:\tlearn: 0.1790213\ttotal: 574ms\tremaining: 458ms\n",
      "278:\tlearn: 0.1783738\ttotal: 575ms\tremaining: 456ms\n",
      "279:\tlearn: 0.1776471\ttotal: 577ms\tremaining: 453ms\n",
      "280:\tlearn: 0.1775647\ttotal: 579ms\tremaining: 451ms\n",
      "281:\tlearn: 0.1768319\ttotal: 581ms\tremaining: 449ms\n",
      "282:\tlearn: 0.1765478\ttotal: 583ms\tremaining: 447ms\n",
      "283:\tlearn: 0.1761244\ttotal: 585ms\tremaining: 445ms\n",
      "284:\tlearn: 0.1757168\ttotal: 588ms\tremaining: 444ms\n",
      "285:\tlearn: 0.1751421\ttotal: 591ms\tremaining: 442ms\n",
      "286:\tlearn: 0.1744884\ttotal: 593ms\tremaining: 440ms\n",
      "287:\tlearn: 0.1740941\ttotal: 596ms\tremaining: 438ms\n",
      "288:\tlearn: 0.1734151\ttotal: 598ms\tremaining: 437ms\n",
      "289:\tlearn: 0.1731862\ttotal: 600ms\tremaining: 435ms\n",
      "290:\tlearn: 0.1723572\ttotal: 603ms\tremaining: 433ms\n",
      "291:\tlearn: 0.1720263\ttotal: 605ms\tremaining: 431ms\n",
      "292:\tlearn: 0.1717539\ttotal: 607ms\tremaining: 429ms\n",
      "293:\tlearn: 0.1714114\ttotal: 609ms\tremaining: 426ms\n",
      "294:\tlearn: 0.1703880\ttotal: 612ms\tremaining: 425ms\n",
      "295:\tlearn: 0.1696562\ttotal: 614ms\tremaining: 423ms\n",
      "296:\tlearn: 0.1694276\ttotal: 616ms\tremaining: 421ms\n",
      "297:\tlearn: 0.1693669\ttotal: 618ms\tremaining: 419ms\n",
      "298:\tlearn: 0.1690960\ttotal: 620ms\tremaining: 417ms\n",
      "299:\tlearn: 0.1687932\ttotal: 622ms\tremaining: 415ms\n",
      "300:\tlearn: 0.1687352\ttotal: 624ms\tremaining: 413ms\n",
      "301:\tlearn: 0.1684313\ttotal: 627ms\tremaining: 411ms\n",
      "302:\tlearn: 0.1676177\ttotal: 629ms\tremaining: 409ms\n",
      "303:\tlearn: 0.1673387\ttotal: 632ms\tremaining: 407ms\n",
      "304:\tlearn: 0.1669622\ttotal: 634ms\tremaining: 405ms\n",
      "305:\tlearn: 0.1669106\ttotal: 636ms\tremaining: 403ms\n",
      "306:\tlearn: 0.1665050\ttotal: 637ms\tremaining: 401ms\n",
      "307:\tlearn: 0.1659279\ttotal: 639ms\tremaining: 398ms\n",
      "308:\tlearn: 0.1650134\ttotal: 642ms\tremaining: 397ms\n",
      "309:\tlearn: 0.1643704\ttotal: 643ms\tremaining: 394ms\n",
      "310:\tlearn: 0.1636769\ttotal: 645ms\tremaining: 392ms\n",
      "311:\tlearn: 0.1630857\ttotal: 647ms\tremaining: 390ms\n",
      "312:\tlearn: 0.1629326\ttotal: 649ms\tremaining: 388ms\n",
      "313:\tlearn: 0.1620151\ttotal: 651ms\tremaining: 386ms\n",
      "314:\tlearn: 0.1613797\ttotal: 653ms\tremaining: 384ms\n",
      "315:\tlearn: 0.1602040\ttotal: 655ms\tremaining: 381ms\n",
      "316:\tlearn: 0.1599068\ttotal: 657ms\tremaining: 379ms\n",
      "317:\tlearn: 0.1598601\ttotal: 659ms\tremaining: 377ms\n",
      "318:\tlearn: 0.1591838\ttotal: 661ms\tremaining: 375ms\n",
      "319:\tlearn: 0.1586149\ttotal: 662ms\tremaining: 373ms\n",
      "320:\tlearn: 0.1580392\ttotal: 664ms\tremaining: 370ms\n",
      "321:\tlearn: 0.1578566\ttotal: 667ms\tremaining: 369ms\n",
      "322:\tlearn: 0.1578162\ttotal: 669ms\tremaining: 367ms\n",
      "323:\tlearn: 0.1574463\ttotal: 672ms\tremaining: 365ms\n",
      "324:\tlearn: 0.1569555\ttotal: 675ms\tremaining: 363ms\n",
      "325:\tlearn: 0.1564683\ttotal: 676ms\tremaining: 361ms\n",
      "326:\tlearn: 0.1559306\ttotal: 678ms\tremaining: 359ms\n",
      "327:\tlearn: 0.1553264\ttotal: 681ms\tremaining: 357ms\n",
      "328:\tlearn: 0.1552834\ttotal: 683ms\tremaining: 355ms\n",
      "329:\tlearn: 0.1552482\ttotal: 685ms\tremaining: 353ms\n",
      "330:\tlearn: 0.1549700\ttotal: 688ms\tremaining: 351ms\n",
      "331:\tlearn: 0.1546016\ttotal: 691ms\tremaining: 349ms\n",
      "332:\tlearn: 0.1537083\ttotal: 693ms\tremaining: 348ms\n",
      "333:\tlearn: 0.1530937\ttotal: 695ms\tremaining: 346ms\n",
      "334:\tlearn: 0.1528675\ttotal: 697ms\tremaining: 343ms\n",
      "335:\tlearn: 0.1525499\ttotal: 700ms\tremaining: 342ms\n",
      "336:\tlearn: 0.1517267\ttotal: 702ms\tremaining: 340ms\n",
      "337:\tlearn: 0.1514337\ttotal: 704ms\tremaining: 338ms\n",
      "338:\tlearn: 0.1513043\ttotal: 707ms\tremaining: 336ms\n",
      "339:\tlearn: 0.1504702\ttotal: 709ms\tremaining: 334ms\n",
      "340:\tlearn: 0.1503170\ttotal: 712ms\tremaining: 332ms\n",
      "341:\tlearn: 0.1500580\ttotal: 714ms\tremaining: 330ms\n",
      "342:\tlearn: 0.1494611\ttotal: 717ms\tremaining: 328ms\n",
      "343:\tlearn: 0.1489875\ttotal: 719ms\tremaining: 326ms\n",
      "344:\tlearn: 0.1484416\ttotal: 721ms\tremaining: 324ms\n",
      "345:\tlearn: 0.1483204\ttotal: 724ms\tremaining: 322ms\n",
      "346:\tlearn: 0.1480966\ttotal: 726ms\tremaining: 320ms\n",
      "347:\tlearn: 0.1479291\ttotal: 728ms\tremaining: 318ms\n",
      "348:\tlearn: 0.1475348\ttotal: 731ms\tremaining: 316ms\n",
      "349:\tlearn: 0.1471259\ttotal: 733ms\tremaining: 314ms\n",
      "350:\tlearn: 0.1468358\ttotal: 736ms\tremaining: 312ms\n",
      "351:\tlearn: 0.1467544\ttotal: 739ms\tremaining: 311ms\n",
      "352:\tlearn: 0.1460108\ttotal: 741ms\tremaining: 309ms\n",
      "353:\tlearn: 0.1454572\ttotal: 744ms\tremaining: 307ms\n",
      "354:\tlearn: 0.1448753\ttotal: 747ms\tremaining: 305ms\n",
      "355:\tlearn: 0.1448254\ttotal: 750ms\tremaining: 303ms\n",
      "356:\tlearn: 0.1443475\ttotal: 752ms\tremaining: 301ms\n",
      "357:\tlearn: 0.1443094\ttotal: 754ms\tremaining: 299ms\n",
      "358:\tlearn: 0.1434003\ttotal: 756ms\tremaining: 297ms\n",
      "359:\tlearn: 0.1423987\ttotal: 759ms\tremaining: 295ms\n",
      "360:\tlearn: 0.1416168\ttotal: 762ms\tremaining: 293ms\n",
      "361:\tlearn: 0.1410278\ttotal: 766ms\tremaining: 292ms\n",
      "362:\tlearn: 0.1403138\ttotal: 768ms\tremaining: 290ms\n",
      "363:\tlearn: 0.1401879\ttotal: 772ms\tremaining: 288ms\n",
      "364:\tlearn: 0.1397517\ttotal: 778ms\tremaining: 288ms\n",
      "365:\tlearn: 0.1395102\ttotal: 781ms\tremaining: 286ms\n",
      "366:\tlearn: 0.1393133\ttotal: 784ms\tremaining: 284ms\n",
      "367:\tlearn: 0.1392841\ttotal: 786ms\tremaining: 282ms\n",
      "368:\tlearn: 0.1390703\ttotal: 789ms\tremaining: 280ms\n",
      "369:\tlearn: 0.1387526\ttotal: 792ms\tremaining: 278ms\n",
      "370:\tlearn: 0.1387203\ttotal: 795ms\tremaining: 276ms\n",
      "371:\tlearn: 0.1383520\ttotal: 799ms\tremaining: 275ms\n",
      "372:\tlearn: 0.1380247\ttotal: 802ms\tremaining: 273ms\n",
      "373:\tlearn: 0.1376657\ttotal: 805ms\tremaining: 271ms\n",
      "374:\tlearn: 0.1370591\ttotal: 808ms\tremaining: 269ms\n",
      "375:\tlearn: 0.1361125\ttotal: 811ms\tremaining: 267ms\n",
      "376:\tlearn: 0.1358998\ttotal: 813ms\tremaining: 265ms\n",
      "377:\tlearn: 0.1356875\ttotal: 816ms\tremaining: 263ms\n",
      "378:\tlearn: 0.1356682\ttotal: 819ms\tremaining: 262ms\n",
      "379:\tlearn: 0.1348674\ttotal: 823ms\tremaining: 260ms\n",
      "380:\tlearn: 0.1347022\ttotal: 825ms\tremaining: 258ms\n",
      "381:\tlearn: 0.1345311\ttotal: 830ms\tremaining: 256ms\n",
      "382:\tlearn: 0.1341860\ttotal: 835ms\tremaining: 255ms\n",
      "383:\tlearn: 0.1338914\ttotal: 838ms\tremaining: 253ms\n",
      "384:\tlearn: 0.1333224\ttotal: 841ms\tremaining: 251ms\n",
      "385:\tlearn: 0.1324901\ttotal: 844ms\tremaining: 249ms\n",
      "386:\tlearn: 0.1321991\ttotal: 846ms\tremaining: 247ms\n",
      "387:\tlearn: 0.1317578\ttotal: 849ms\tremaining: 245ms\n",
      "388:\tlearn: 0.1312753\ttotal: 852ms\tremaining: 243ms\n",
      "389:\tlearn: 0.1309334\ttotal: 854ms\tremaining: 241ms\n",
      "390:\tlearn: 0.1306168\ttotal: 857ms\tremaining: 239ms\n",
      "391:\tlearn: 0.1300161\ttotal: 859ms\tremaining: 237ms\n",
      "392:\tlearn: 0.1295187\ttotal: 862ms\tremaining: 235ms\n",
      "393:\tlearn: 0.1292029\ttotal: 864ms\tremaining: 232ms\n",
      "394:\tlearn: 0.1289456\ttotal: 866ms\tremaining: 230ms\n",
      "395:\tlearn: 0.1287442\ttotal: 868ms\tremaining: 228ms\n",
      "396:\tlearn: 0.1282791\ttotal: 871ms\tremaining: 226ms\n",
      "397:\tlearn: 0.1281510\ttotal: 874ms\tremaining: 224ms\n",
      "398:\tlearn: 0.1270643\ttotal: 876ms\tremaining: 222ms\n",
      "399:\tlearn: 0.1268778\ttotal: 879ms\tremaining: 220ms\n",
      "400:\tlearn: 0.1267936\ttotal: 881ms\tremaining: 217ms\n",
      "401:\tlearn: 0.1264586\ttotal: 883ms\tremaining: 215ms\n",
      "402:\tlearn: 0.1261269\ttotal: 885ms\tremaining: 213ms\n",
      "403:\tlearn: 0.1259925\ttotal: 887ms\tremaining: 211ms\n",
      "404:\tlearn: 0.1255444\ttotal: 890ms\tremaining: 209ms\n",
      "405:\tlearn: 0.1253109\ttotal: 892ms\tremaining: 207ms\n",
      "406:\tlearn: 0.1248152\ttotal: 895ms\tremaining: 204ms\n",
      "407:\tlearn: 0.1246245\ttotal: 897ms\tremaining: 202ms\n",
      "408:\tlearn: 0.1241865\ttotal: 900ms\tremaining: 200ms\n",
      "409:\tlearn: 0.1238422\ttotal: 902ms\tremaining: 198ms\n",
      "410:\tlearn: 0.1238216\ttotal: 904ms\tremaining: 196ms\n",
      "411:\tlearn: 0.1234716\ttotal: 906ms\tremaining: 193ms\n",
      "412:\tlearn: 0.1228187\ttotal: 907ms\tremaining: 191ms\n",
      "413:\tlearn: 0.1223955\ttotal: 909ms\tremaining: 189ms\n",
      "414:\tlearn: 0.1220043\ttotal: 911ms\tremaining: 187ms\n",
      "415:\tlearn: 0.1213649\ttotal: 913ms\tremaining: 184ms\n",
      "416:\tlearn: 0.1207236\ttotal: 915ms\tremaining: 182ms\n",
      "417:\tlearn: 0.1204061\ttotal: 917ms\tremaining: 180ms\n",
      "418:\tlearn: 0.1200582\ttotal: 918ms\tremaining: 178ms\n",
      "419:\tlearn: 0.1194790\ttotal: 920ms\tremaining: 175ms\n",
      "420:\tlearn: 0.1190384\ttotal: 922ms\tremaining: 173ms\n",
      "421:\tlearn: 0.1182275\ttotal: 924ms\tremaining: 171ms\n",
      "422:\tlearn: 0.1179046\ttotal: 926ms\tremaining: 169ms\n",
      "423:\tlearn: 0.1177006\ttotal: 928ms\tremaining: 166ms\n",
      "424:\tlearn: 0.1175385\ttotal: 930ms\tremaining: 164ms\n",
      "425:\tlearn: 0.1173110\ttotal: 931ms\tremaining: 162ms\n",
      "426:\tlearn: 0.1170153\ttotal: 933ms\tremaining: 160ms\n",
      "427:\tlearn: 0.1167449\ttotal: 935ms\tremaining: 157ms\n",
      "428:\tlearn: 0.1164321\ttotal: 937ms\tremaining: 155ms\n",
      "429:\tlearn: 0.1162703\ttotal: 938ms\tremaining: 153ms\n",
      "430:\tlearn: 0.1158990\ttotal: 939ms\tremaining: 150ms\n",
      "431:\tlearn: 0.1155744\ttotal: 941ms\tremaining: 148ms\n",
      "432:\tlearn: 0.1153562\ttotal: 942ms\tremaining: 146ms\n",
      "433:\tlearn: 0.1151284\ttotal: 944ms\tremaining: 144ms\n",
      "434:\tlearn: 0.1147006\ttotal: 946ms\tremaining: 141ms\n",
      "435:\tlearn: 0.1140345\ttotal: 948ms\tremaining: 139ms\n",
      "436:\tlearn: 0.1138599\ttotal: 950ms\tremaining: 137ms\n",
      "437:\tlearn: 0.1138195\ttotal: 952ms\tremaining: 135ms\n",
      "438:\tlearn: 0.1134605\ttotal: 953ms\tremaining: 132ms\n",
      "439:\tlearn: 0.1130957\ttotal: 956ms\tremaining: 130ms\n",
      "440:\tlearn: 0.1128575\ttotal: 957ms\tremaining: 128ms\n",
      "441:\tlearn: 0.1122564\ttotal: 959ms\tremaining: 126ms\n",
      "442:\tlearn: 0.1122294\ttotal: 961ms\tremaining: 124ms\n",
      "443:\tlearn: 0.1114303\ttotal: 963ms\tremaining: 122ms\n",
      "444:\tlearn: 0.1111446\ttotal: 965ms\tremaining: 119ms\n",
      "445:\tlearn: 0.1110934\ttotal: 967ms\tremaining: 117ms\n",
      "446:\tlearn: 0.1109038\ttotal: 969ms\tremaining: 115ms\n",
      "447:\tlearn: 0.1106266\ttotal: 972ms\tremaining: 113ms\n",
      "448:\tlearn: 0.1101824\ttotal: 974ms\tremaining: 111ms\n",
      "449:\tlearn: 0.1095247\ttotal: 976ms\tremaining: 108ms\n",
      "450:\tlearn: 0.1094565\ttotal: 979ms\tremaining: 106ms\n",
      "451:\tlearn: 0.1092401\ttotal: 981ms\tremaining: 104ms\n",
      "452:\tlearn: 0.1091821\ttotal: 983ms\tremaining: 102ms\n",
      "453:\tlearn: 0.1088201\ttotal: 986ms\tremaining: 99.9ms\n",
      "454:\tlearn: 0.1086290\ttotal: 988ms\tremaining: 97.7ms\n",
      "455:\tlearn: 0.1084800\ttotal: 990ms\tremaining: 95.6ms\n",
      "456:\tlearn: 0.1083226\ttotal: 992ms\tremaining: 93.3ms\n",
      "457:\tlearn: 0.1080520\ttotal: 994ms\tremaining: 91.1ms\n",
      "458:\tlearn: 0.1076280\ttotal: 996ms\tremaining: 89ms\n",
      "459:\tlearn: 0.1075446\ttotal: 998ms\tremaining: 86.8ms\n",
      "460:\tlearn: 0.1072740\ttotal: 1000ms\tremaining: 84.6ms\n",
      "461:\tlearn: 0.1070217\ttotal: 1s\tremaining: 82.4ms\n",
      "462:\tlearn: 0.1064748\ttotal: 1s\tremaining: 80.2ms\n",
      "463:\tlearn: 0.1064103\ttotal: 1s\tremaining: 77.9ms\n",
      "464:\tlearn: 0.1063378\ttotal: 1.01s\tremaining: 75.8ms\n",
      "465:\tlearn: 0.1061591\ttotal: 1.01s\tremaining: 73.6ms\n",
      "466:\tlearn: 0.1059257\ttotal: 1.01s\tremaining: 71.4ms\n",
      "467:\tlearn: 0.1056101\ttotal: 1.01s\tremaining: 69.2ms\n",
      "468:\tlearn: 0.1052068\ttotal: 1.01s\tremaining: 67.1ms\n",
      "469:\tlearn: 0.1050856\ttotal: 1.01s\tremaining: 64.8ms\n",
      "470:\tlearn: 0.1046281\ttotal: 1.02s\tremaining: 62.7ms\n",
      "471:\tlearn: 0.1042301\ttotal: 1.02s\tremaining: 60.5ms\n",
      "472:\tlearn: 0.1040811\ttotal: 1.02s\tremaining: 58.3ms\n",
      "473:\tlearn: 0.1039875\ttotal: 1.02s\tremaining: 56.1ms\n",
      "474:\tlearn: 0.1039271\ttotal: 1.02s\tremaining: 54ms\n",
      "475:\tlearn: 0.1037631\ttotal: 1.03s\tremaining: 51.8ms\n",
      "476:\tlearn: 0.1032900\ttotal: 1.03s\tremaining: 49.7ms\n",
      "477:\tlearn: 0.1031600\ttotal: 1.03s\tremaining: 47.5ms\n",
      "478:\tlearn: 0.1030177\ttotal: 1.03s\tremaining: 45.3ms\n",
      "479:\tlearn: 0.1027325\ttotal: 1.03s\tremaining: 43.1ms\n",
      "480:\tlearn: 0.1027103\ttotal: 1.04s\tremaining: 41ms\n",
      "481:\tlearn: 0.1023971\ttotal: 1.04s\tremaining: 38.8ms\n",
      "482:\tlearn: 0.1023801\ttotal: 1.04s\tremaining: 36.6ms\n",
      "483:\tlearn: 0.1020681\ttotal: 1.04s\tremaining: 34.5ms\n",
      "484:\tlearn: 0.1018747\ttotal: 1.04s\tremaining: 32.3ms\n",
      "485:\tlearn: 0.1013506\ttotal: 1.05s\tremaining: 30.2ms\n",
      "486:\tlearn: 0.1010811\ttotal: 1.05s\tremaining: 28ms\n",
      "487:\tlearn: 0.1008593\ttotal: 1.05s\tremaining: 25.8ms\n",
      "488:\tlearn: 0.1005717\ttotal: 1.05s\tremaining: 23.7ms\n",
      "489:\tlearn: 0.1005345\ttotal: 1.05s\tremaining: 21.5ms\n",
      "490:\tlearn: 0.1004211\ttotal: 1.06s\tremaining: 19.4ms\n",
      "491:\tlearn: 0.1000868\ttotal: 1.06s\tremaining: 17.2ms\n",
      "492:\tlearn: 0.1000592\ttotal: 1.06s\tremaining: 15.1ms\n",
      "493:\tlearn: 0.0996286\ttotal: 1.06s\tremaining: 12.9ms\n",
      "494:\tlearn: 0.0992965\ttotal: 1.07s\tremaining: 10.8ms\n",
      "495:\tlearn: 0.0991787\ttotal: 1.07s\tremaining: 8.61ms\n",
      "496:\tlearn: 0.0988802\ttotal: 1.07s\tremaining: 6.46ms\n",
      "497:\tlearn: 0.0987317\ttotal: 1.07s\tremaining: 4.3ms\n",
      "498:\tlearn: 0.0985638\ttotal: 1.07s\tremaining: 2.15ms\n",
      "499:\tlearn: 0.0983369\ttotal: 1.07s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depth': 3, 'iterations': 500, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb = CatBoostClassifier()\n",
    "catb_cv_model = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1, verbose = 2)\n",
    "catb_cv_model.fit(X_train, y_train)\n",
    "catb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 3, 'iterations': 500, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6645984\ttotal: 15.2ms\tremaining: 3.03s\n",
      "1:\tlearn: 0.6434910\ttotal: 16.7ms\tremaining: 1.65s\n",
      "2:\tlearn: 0.6242738\ttotal: 18ms\tremaining: 1.18s\n",
      "3:\tlearn: 0.6105454\ttotal: 19ms\tremaining: 933ms\n",
      "4:\tlearn: 0.5921193\ttotal: 20.4ms\tremaining: 794ms\n",
      "5:\tlearn: 0.5801625\ttotal: 21.5ms\tremaining: 695ms\n",
      "6:\tlearn: 0.5628821\ttotal: 22.6ms\tremaining: 623ms\n",
      "7:\tlearn: 0.5517693\ttotal: 23.7ms\tremaining: 568ms\n",
      "8:\tlearn: 0.5361405\ttotal: 24.9ms\tremaining: 528ms\n",
      "9:\tlearn: 0.5276726\ttotal: 26.2ms\tremaining: 497ms\n",
      "10:\tlearn: 0.5228155\ttotal: 27.5ms\tremaining: 473ms\n",
      "11:\tlearn: 0.5140078\ttotal: 28.9ms\tremaining: 453ms\n",
      "12:\tlearn: 0.5050585\ttotal: 30.2ms\tremaining: 435ms\n",
      "13:\tlearn: 0.4975609\ttotal: 31.4ms\tremaining: 418ms\n",
      "14:\tlearn: 0.4889197\ttotal: 32.7ms\tremaining: 403ms\n",
      "15:\tlearn: 0.4841886\ttotal: 34ms\tremaining: 391ms\n",
      "16:\tlearn: 0.4798831\ttotal: 35.4ms\tremaining: 381ms\n",
      "17:\tlearn: 0.4710092\ttotal: 36.5ms\tremaining: 369ms\n",
      "18:\tlearn: 0.4664067\ttotal: 37.8ms\tremaining: 360ms\n",
      "19:\tlearn: 0.4614224\ttotal: 39ms\tremaining: 351ms\n",
      "20:\tlearn: 0.4590326\ttotal: 40.1ms\tremaining: 342ms\n",
      "21:\tlearn: 0.4559062\ttotal: 41.3ms\tremaining: 334ms\n",
      "22:\tlearn: 0.4526720\ttotal: 42.4ms\tremaining: 326ms\n",
      "23:\tlearn: 0.4490278\ttotal: 43.7ms\tremaining: 320ms\n",
      "24:\tlearn: 0.4453544\ttotal: 45.3ms\tremaining: 317ms\n",
      "25:\tlearn: 0.4423643\ttotal: 47.1ms\tremaining: 315ms\n",
      "26:\tlearn: 0.4390944\ttotal: 48.6ms\tremaining: 311ms\n",
      "27:\tlearn: 0.4360196\ttotal: 49.8ms\tremaining: 306ms\n",
      "28:\tlearn: 0.4345247\ttotal: 51ms\tremaining: 301ms\n",
      "29:\tlearn: 0.4302504\ttotal: 52.3ms\tremaining: 296ms\n",
      "30:\tlearn: 0.4278275\ttotal: 54.7ms\tremaining: 298ms\n",
      "31:\tlearn: 0.4252715\ttotal: 56.6ms\tremaining: 297ms\n",
      "32:\tlearn: 0.4224253\ttotal: 58ms\tremaining: 293ms\n",
      "33:\tlearn: 0.4199747\ttotal: 59.2ms\tremaining: 289ms\n",
      "34:\tlearn: 0.4162903\ttotal: 60.3ms\tremaining: 284ms\n",
      "35:\tlearn: 0.4140088\ttotal: 61.6ms\tremaining: 280ms\n",
      "36:\tlearn: 0.4120724\ttotal: 63.3ms\tremaining: 279ms\n",
      "37:\tlearn: 0.4101765\ttotal: 65.1ms\tremaining: 277ms\n",
      "38:\tlearn: 0.4080080\ttotal: 66.6ms\tremaining: 275ms\n",
      "39:\tlearn: 0.4054586\ttotal: 67.9ms\tremaining: 271ms\n",
      "40:\tlearn: 0.4038831\ttotal: 69.1ms\tremaining: 268ms\n",
      "41:\tlearn: 0.4013555\ttotal: 70.1ms\tremaining: 264ms\n",
      "42:\tlearn: 0.3978078\ttotal: 71.1ms\tremaining: 260ms\n",
      "43:\tlearn: 0.3956441\ttotal: 72.2ms\tremaining: 256ms\n",
      "44:\tlearn: 0.3919743\ttotal: 73.2ms\tremaining: 252ms\n",
      "45:\tlearn: 0.3906984\ttotal: 74.3ms\tremaining: 249ms\n",
      "46:\tlearn: 0.3886447\ttotal: 75.3ms\tremaining: 245ms\n",
      "47:\tlearn: 0.3866564\ttotal: 76.2ms\tremaining: 241ms\n",
      "48:\tlearn: 0.3834512\ttotal: 77.2ms\tremaining: 238ms\n",
      "49:\tlearn: 0.3817208\ttotal: 78.3ms\tremaining: 235ms\n",
      "50:\tlearn: 0.3801871\ttotal: 79.5ms\tremaining: 232ms\n",
      "51:\tlearn: 0.3780735\ttotal: 80.7ms\tremaining: 230ms\n",
      "52:\tlearn: 0.3764288\ttotal: 81.8ms\tremaining: 227ms\n",
      "53:\tlearn: 0.3741817\ttotal: 82.9ms\tremaining: 224ms\n",
      "54:\tlearn: 0.3729834\ttotal: 83.9ms\tremaining: 221ms\n",
      "55:\tlearn: 0.3711119\ttotal: 85.1ms\tremaining: 219ms\n",
      "56:\tlearn: 0.3699076\ttotal: 86.8ms\tremaining: 218ms\n",
      "57:\tlearn: 0.3677819\ttotal: 88.2ms\tremaining: 216ms\n",
      "58:\tlearn: 0.3667274\ttotal: 89.3ms\tremaining: 213ms\n",
      "59:\tlearn: 0.3650573\ttotal: 90.5ms\tremaining: 211ms\n",
      "60:\tlearn: 0.3637585\ttotal: 91.6ms\tremaining: 209ms\n",
      "61:\tlearn: 0.3623673\ttotal: 92.8ms\tremaining: 207ms\n",
      "62:\tlearn: 0.3601008\ttotal: 94ms\tremaining: 204ms\n",
      "63:\tlearn: 0.3590925\ttotal: 95.2ms\tremaining: 202ms\n",
      "64:\tlearn: 0.3577064\ttotal: 96.2ms\tremaining: 200ms\n",
      "65:\tlearn: 0.3558705\ttotal: 97.3ms\tremaining: 198ms\n",
      "66:\tlearn: 0.3537864\ttotal: 98.4ms\tremaining: 195ms\n",
      "67:\tlearn: 0.3528630\ttotal: 99.7ms\tremaining: 193ms\n",
      "68:\tlearn: 0.3517424\ttotal: 101ms\tremaining: 192ms\n",
      "69:\tlearn: 0.3496880\ttotal: 103ms\tremaining: 191ms\n",
      "70:\tlearn: 0.3490269\ttotal: 104ms\tremaining: 189ms\n",
      "71:\tlearn: 0.3478097\ttotal: 105ms\tremaining: 187ms\n",
      "72:\tlearn: 0.3468778\ttotal: 107ms\tremaining: 186ms\n",
      "73:\tlearn: 0.3455768\ttotal: 108ms\tremaining: 185ms\n",
      "74:\tlearn: 0.3441704\ttotal: 110ms\tremaining: 184ms\n",
      "75:\tlearn: 0.3414396\ttotal: 112ms\tremaining: 183ms\n",
      "76:\tlearn: 0.3400181\ttotal: 115ms\tremaining: 183ms\n",
      "77:\tlearn: 0.3388153\ttotal: 117ms\tremaining: 183ms\n",
      "78:\tlearn: 0.3372159\ttotal: 119ms\tremaining: 183ms\n",
      "79:\tlearn: 0.3355242\ttotal: 121ms\tremaining: 181ms\n",
      "80:\tlearn: 0.3337069\ttotal: 122ms\tremaining: 179ms\n",
      "81:\tlearn: 0.3321197\ttotal: 123ms\tremaining: 177ms\n",
      "82:\tlearn: 0.3310392\ttotal: 125ms\tremaining: 177ms\n",
      "83:\tlearn: 0.3292496\ttotal: 127ms\tremaining: 175ms\n",
      "84:\tlearn: 0.3282303\ttotal: 127ms\tremaining: 172ms\n",
      "85:\tlearn: 0.3273367\ttotal: 128ms\tremaining: 170ms\n",
      "86:\tlearn: 0.3260111\ttotal: 129ms\tremaining: 168ms\n",
      "87:\tlearn: 0.3253013\ttotal: 130ms\tremaining: 166ms\n",
      "88:\tlearn: 0.3235194\ttotal: 131ms\tremaining: 164ms\n",
      "89:\tlearn: 0.3223564\ttotal: 132ms\tremaining: 162ms\n",
      "90:\tlearn: 0.3208093\ttotal: 133ms\tremaining: 159ms\n",
      "91:\tlearn: 0.3196015\ttotal: 134ms\tremaining: 157ms\n",
      "92:\tlearn: 0.3175811\ttotal: 135ms\tremaining: 155ms\n",
      "93:\tlearn: 0.3161367\ttotal: 136ms\tremaining: 153ms\n",
      "94:\tlearn: 0.3148126\ttotal: 137ms\tremaining: 151ms\n",
      "95:\tlearn: 0.3134220\ttotal: 138ms\tremaining: 149ms\n",
      "96:\tlearn: 0.3119934\ttotal: 139ms\tremaining: 147ms\n",
      "97:\tlearn: 0.3108645\ttotal: 140ms\tremaining: 146ms\n",
      "98:\tlearn: 0.3104689\ttotal: 141ms\tremaining: 144ms\n",
      "99:\tlearn: 0.3095731\ttotal: 142ms\tremaining: 142ms\n",
      "100:\tlearn: 0.3080392\ttotal: 143ms\tremaining: 140ms\n",
      "101:\tlearn: 0.3068831\ttotal: 144ms\tremaining: 139ms\n",
      "102:\tlearn: 0.3062281\ttotal: 146ms\tremaining: 137ms\n",
      "103:\tlearn: 0.3058803\ttotal: 147ms\tremaining: 135ms\n",
      "104:\tlearn: 0.3049310\ttotal: 148ms\tremaining: 134ms\n",
      "105:\tlearn: 0.3041327\ttotal: 149ms\tremaining: 132ms\n",
      "106:\tlearn: 0.3024421\ttotal: 150ms\tremaining: 130ms\n",
      "107:\tlearn: 0.3012426\ttotal: 151ms\tremaining: 129ms\n",
      "108:\tlearn: 0.3002960\ttotal: 152ms\tremaining: 127ms\n",
      "109:\tlearn: 0.2990579\ttotal: 153ms\tremaining: 125ms\n",
      "110:\tlearn: 0.2980880\ttotal: 155ms\tremaining: 124ms\n",
      "111:\tlearn: 0.2969979\ttotal: 156ms\tremaining: 123ms\n",
      "112:\tlearn: 0.2955682\ttotal: 157ms\tremaining: 121ms\n",
      "113:\tlearn: 0.2942101\ttotal: 158ms\tremaining: 119ms\n",
      "114:\tlearn: 0.2931256\ttotal: 159ms\tremaining: 118ms\n",
      "115:\tlearn: 0.2917528\ttotal: 160ms\tremaining: 116ms\n",
      "116:\tlearn: 0.2907630\ttotal: 161ms\tremaining: 115ms\n",
      "117:\tlearn: 0.2904451\ttotal: 162ms\tremaining: 113ms\n",
      "118:\tlearn: 0.2888123\ttotal: 163ms\tremaining: 111ms\n",
      "119:\tlearn: 0.2881395\ttotal: 164ms\tremaining: 110ms\n",
      "120:\tlearn: 0.2877115\ttotal: 166ms\tremaining: 108ms\n",
      "121:\tlearn: 0.2870757\ttotal: 167ms\tremaining: 107ms\n",
      "122:\tlearn: 0.2863276\ttotal: 168ms\tremaining: 105ms\n",
      "123:\tlearn: 0.2846359\ttotal: 169ms\tremaining: 103ms\n",
      "124:\tlearn: 0.2832765\ttotal: 170ms\tremaining: 102ms\n",
      "125:\tlearn: 0.2819940\ttotal: 171ms\tremaining: 100ms\n",
      "126:\tlearn: 0.2813909\ttotal: 172ms\tremaining: 98.8ms\n",
      "127:\tlearn: 0.2807734\ttotal: 173ms\tremaining: 97.3ms\n",
      "128:\tlearn: 0.2798772\ttotal: 174ms\tremaining: 95.8ms\n",
      "129:\tlearn: 0.2787381\ttotal: 175ms\tremaining: 94.3ms\n",
      "130:\tlearn: 0.2774807\ttotal: 176ms\tremaining: 92.8ms\n",
      "131:\tlearn: 0.2770525\ttotal: 177ms\tremaining: 91.2ms\n",
      "132:\tlearn: 0.2757005\ttotal: 178ms\tremaining: 89.7ms\n",
      "133:\tlearn: 0.2748723\ttotal: 179ms\tremaining: 88.2ms\n",
      "134:\tlearn: 0.2739233\ttotal: 180ms\tremaining: 86.7ms\n",
      "135:\tlearn: 0.2719090\ttotal: 181ms\tremaining: 85.2ms\n",
      "136:\tlearn: 0.2708044\ttotal: 182ms\tremaining: 83.7ms\n",
      "137:\tlearn: 0.2701560\ttotal: 183ms\tremaining: 82.3ms\n",
      "138:\tlearn: 0.2691067\ttotal: 185ms\tremaining: 81.1ms\n",
      "139:\tlearn: 0.2679572\ttotal: 186ms\tremaining: 79.7ms\n",
      "140:\tlearn: 0.2673006\ttotal: 188ms\tremaining: 78.5ms\n",
      "141:\tlearn: 0.2657839\ttotal: 189ms\tremaining: 77.2ms\n",
      "142:\tlearn: 0.2639263\ttotal: 190ms\tremaining: 75.8ms\n",
      "143:\tlearn: 0.2626615\ttotal: 191ms\tremaining: 74.4ms\n",
      "144:\tlearn: 0.2613081\ttotal: 192ms\tremaining: 73ms\n",
      "145:\tlearn: 0.2601614\ttotal: 194ms\tremaining: 71.7ms\n",
      "146:\tlearn: 0.2595490\ttotal: 195ms\tremaining: 70.4ms\n",
      "147:\tlearn: 0.2584117\ttotal: 197ms\tremaining: 69.2ms\n",
      "148:\tlearn: 0.2574990\ttotal: 198ms\tremaining: 67.9ms\n",
      "149:\tlearn: 0.2572619\ttotal: 199ms\tremaining: 66.5ms\n",
      "150:\tlearn: 0.2556671\ttotal: 201ms\tremaining: 65.2ms\n",
      "151:\tlearn: 0.2534120\ttotal: 202ms\tremaining: 63.8ms\n",
      "152:\tlearn: 0.2529160\ttotal: 203ms\tremaining: 62.5ms\n",
      "153:\tlearn: 0.2516919\ttotal: 205ms\tremaining: 61.2ms\n",
      "154:\tlearn: 0.2513668\ttotal: 206ms\tremaining: 59.9ms\n",
      "155:\tlearn: 0.2509946\ttotal: 208ms\tremaining: 58.5ms\n",
      "156:\tlearn: 0.2501869\ttotal: 209ms\tremaining: 57.2ms\n",
      "157:\tlearn: 0.2496219\ttotal: 210ms\tremaining: 55.9ms\n",
      "158:\tlearn: 0.2479656\ttotal: 211ms\tremaining: 54.5ms\n",
      "159:\tlearn: 0.2475563\ttotal: 213ms\tremaining: 53.2ms\n",
      "160:\tlearn: 0.2460974\ttotal: 214ms\tremaining: 51.8ms\n",
      "161:\tlearn: 0.2442469\ttotal: 215ms\tremaining: 50.4ms\n",
      "162:\tlearn: 0.2436924\ttotal: 216ms\tremaining: 49.1ms\n",
      "163:\tlearn: 0.2427271\ttotal: 217ms\tremaining: 47.7ms\n",
      "164:\tlearn: 0.2417286\ttotal: 219ms\tremaining: 46.4ms\n",
      "165:\tlearn: 0.2407540\ttotal: 220ms\tremaining: 45ms\n",
      "166:\tlearn: 0.2401100\ttotal: 221ms\tremaining: 43.6ms\n",
      "167:\tlearn: 0.2391599\ttotal: 221ms\tremaining: 42.2ms\n",
      "168:\tlearn: 0.2369021\ttotal: 222ms\tremaining: 40.8ms\n",
      "169:\tlearn: 0.2363448\ttotal: 223ms\tremaining: 39.4ms\n",
      "170:\tlearn: 0.2350275\ttotal: 224ms\tremaining: 38ms\n",
      "171:\tlearn: 0.2345399\ttotal: 225ms\tremaining: 36.6ms\n",
      "172:\tlearn: 0.2330070\ttotal: 226ms\tremaining: 35.3ms\n",
      "173:\tlearn: 0.2322325\ttotal: 227ms\tremaining: 33.9ms\n",
      "174:\tlearn: 0.2316639\ttotal: 228ms\tremaining: 32.6ms\n",
      "175:\tlearn: 0.2310970\ttotal: 229ms\tremaining: 31.2ms\n",
      "176:\tlearn: 0.2305501\ttotal: 230ms\tremaining: 29.9ms\n",
      "177:\tlearn: 0.2298040\ttotal: 231ms\tremaining: 28.5ms\n",
      "178:\tlearn: 0.2290027\ttotal: 232ms\tremaining: 27.2ms\n",
      "179:\tlearn: 0.2275952\ttotal: 232ms\tremaining: 25.8ms\n",
      "180:\tlearn: 0.2260005\ttotal: 233ms\tremaining: 24.5ms\n",
      "181:\tlearn: 0.2253032\ttotal: 234ms\tremaining: 23.2ms\n",
      "182:\tlearn: 0.2238669\ttotal: 235ms\tremaining: 21.9ms\n",
      "183:\tlearn: 0.2232034\ttotal: 236ms\tremaining: 20.5ms\n",
      "184:\tlearn: 0.2221651\ttotal: 237ms\tremaining: 19.2ms\n",
      "185:\tlearn: 0.2204109\ttotal: 238ms\tremaining: 17.9ms\n",
      "186:\tlearn: 0.2192659\ttotal: 239ms\tremaining: 16.6ms\n",
      "187:\tlearn: 0.2185600\ttotal: 240ms\tremaining: 15.3ms\n",
      "188:\tlearn: 0.2168132\ttotal: 241ms\tremaining: 14ms\n",
      "189:\tlearn: 0.2161853\ttotal: 242ms\tremaining: 12.7ms\n",
      "190:\tlearn: 0.2148261\ttotal: 243ms\tremaining: 11.5ms\n",
      "191:\tlearn: 0.2146336\ttotal: 244ms\tremaining: 10.2ms\n",
      "192:\tlearn: 0.2137867\ttotal: 245ms\tremaining: 8.9ms\n",
      "193:\tlearn: 0.2121001\ttotal: 247ms\tremaining: 7.62ms\n",
      "194:\tlearn: 0.2111078\ttotal: 248ms\tremaining: 6.35ms\n",
      "195:\tlearn: 0.2102499\ttotal: 249ms\tremaining: 5.08ms\n",
      "196:\tlearn: 0.2091593\ttotal: 250ms\tremaining: 3.81ms\n",
      "197:\tlearn: 0.2086118\ttotal: 252ms\tremaining: 2.54ms\n",
      "198:\tlearn: 0.2076601\ttotal: 253ms\tremaining: 1.27ms\n",
      "199:\tlearn: 0.2059709\ttotal: 254ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "catb = CatBoostClassifier(iterations = 200, \n",
    "                          learning_rate = 0.05, \n",
    "                          depth = 5)\n",
    "\n",
    "catb_tuned = catb.fit(X_train, y_train)\n",
    "y_pred = catb_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7816593886462883"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = catb_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tüm Modellerin Karşılaştırılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "KNeighborsClassifier:\n",
      "Accuracy: 74.2358%\n",
      "----------------------------\n",
      "LogisticRegression:\n",
      "Accuracy: 76.8559%\n",
      "----------------------------\n",
      "SVC:\n",
      "Accuracy: 75.5459%\n",
      "----------------------------\n",
      "GaussianNB:\n",
      "Accuracy: 77.2926%\n",
      "----------------------------\n",
      "MLPClassifier:\n",
      "Accuracy: 32.3144%\n",
      "----------------------------\n",
      "RandomForestClassifier:\n",
      "Accuracy: 76.8559%\n",
      "----------------------------\n",
      "GradientBoostingClassifier:\n",
      "Accuracy: 75.9825%\n",
      "----------------------------\n",
      "CatBoostClassifier:\n",
      "Accuracy: 78.1659%\n",
      "----------------------------\n",
      "LGBMClassifier:\n",
      "Accuracy: 76.8559%\n",
      "----------------------------\n",
      "XGBClassifier:\n",
      "Accuracy: 77.2926%\n"
     ]
    }
   ],
   "source": [
    "modeller = [\n",
    "    knn_tuned,\n",
    "    loj_model,\n",
    "    svc_tuned,\n",
    "    nb_model,\n",
    "    mlpc_tuned,\n",
    "    rf_tuned,\n",
    "    gbm_tuned,\n",
    "    catb_tuned,\n",
    "    lgbm_tuned,\n",
    "    xgb_tuned\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)\n",
    "    print(\"-\"*28)\n",
    "    print(isimler + \":\" )\n",
    "    print(\"Accuracy: {:.4%}\".format(dogruluk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sonuc = []\n",
    "\n",
    "sonuclar = pd.DataFrame(columns= [\"Modeller\",\"Accuracy\"])\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)\n",
    "    dogruluk = accuracy_score(y_test, y_pred)    \n",
    "    sonuc = pd.DataFrame([[isimler, dogruluk*100]], columns= [\"Modeller\",\"Accuracy\"])\n",
    "    sonuclar = sonuclar.append(sonuc)\n",
    "    \n",
    "    \n",
    "sns.barplot(x= 'Accuracy', y = 'Modeller', data=sonuclar, color=\"r\")\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Modellerin Doğruluk Oranları');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en iyi model CatBoost oldu ama arayüz oluşturma kısmında sorun çıkardığı için\n",
    "#ikinci en iyi model olan XGBC yi kullanmaya karar verdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
